@INPROCEEDINGS{8339087,
author={B. {Bush} and N. {Brunhart-Lupo} and B. {Bugbee} and V. {Krishnan} and K. {Potter} and K. {Gruchalla}},
booktitle={2017 IEEE Workshop on Data Systems for Interactive Analysis (DSIA)},
title={Coupling visualization, simulation, and deep learning for ensemble steering of complex energy models},
year={2017},
volume={},
number={},
pages={1-5},
abstract={We describe a new framework that allows users to explore and steer ensembles of energy systems simulations by coupling multiple energy models and interactive visualization through a dataflow API. Through the visual interface, users can interactively explore complex parameter spaces populated by hundreds, or thousands, of simulation runs and interactively spawn new simulations to “fill in” regions of interest in the parameter space. The computational and visualization capabilities reside within a general-purpose dataflow architecture for connecting producers of multidimensional timeseries data, such as energy simulations, with consumers of that data, whether they be visualizations, statistical analyses, or datastores. Fast computation and agile dataflow can enhance the engagement with energy simulations, allowing users to populate the parameter space in real time. However, many energy simulations are far too slow to provide an interactive response. To support interactive feedback, we are creating reduced-form simulations developed through machine learning techniques, which provide statistically sound estimates of the results of the full simulations at a fraction of the computational cost. These reduced-form simulations have response times on the order of seconds, suitable for real-time human-in-the-loop design and analysis. The approximation methods apply to a wide range of computational models, including supply-chain models, electric power grid simulations, and building models. Such reduced-form representations do not replace or re-implement existing simulations, but instead supplement them by enabling rapid scenario design and exploration for large ensembles of simulations. The improved understanding, facilitated by the reduced-form models, dataflow API, and visualization tools, allows researchers to better allocate computational resources to capture informative relationships within the system as well as provide a low-cost method for validating and quality-checking large-scale modeling efforts.},
keywords={application program interfaces;approximation theory;data flow computing;data visualisation;digital simulation;graphical user interfaces;interactive systems;learning (artificial intelligence);power aware computing;resource allocation;statistical analysis;time series;coupling visualization;ensemble steering;complex energy models;energy systems simulations;multiple energy models;interactive visualization;dataflow API;visual interface;complex parameter spaces;general-purpose dataflow architecture;energy simulations;interactive response;interactive feedback;reduced-form simulations;computational models;electric power grid simulations;reduced-form models;visualization tools;computational visualization capabilities;deep learning;multidimensional time series data;statistical analysis;data stores;agile dataflow;machine learning techniques;computational cost;real-time human-in-the-loop design;approximation methods;supply-chain models;building models;reduced-form representations;computational resource allocation;quality-checking large-scale modeling;Computational modeling;Analytical models;Servers;Data models;Data visualization;Simulation;Databases;Deep learning;immersive visualization;databases;multidimensional time-series;neural networks;ensemble visualization;energy system models},
doi={10.1109/DSIA.2017.8339087},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6914208,
author={J. {K} and R. {P} and B. {P} and S. {B}},
booktitle={2014 International Conference on Computer, Communications, and Control Technology (I4CT)},
title={Development of Android based on-line monitoring and control system for Renewable Energy Sources},
year={2014},
volume={},
number={},
pages={372-375},
abstract={This paper describes the development of an online monitoring and control system for distributed Renewable Energy Sources (RES) based on Android platform. This method utilizes the Bluetooth interface of Android Tablet/ Mobile phone as a communication link for data exchange with digital hardware of Power Conditioning Unit (PCU). The Low Cost Android tablet can replace the graphical LCD displays and Internet modem of RES Power Conditioning Unit (PCU) with enhanced graphical visualization and touch screen interface.},
keywords={air conditioning;Bluetooth;computerised monitoring;control engineering computing;data visualisation;electronic data interchange;graphical user interfaces;Internet;modems;notebook computers;power engineering computing;renewable energy sources;smart phones;Android based online monitoring development;control system development;renewable energy source;Bluetooth interface;mobile phone;communication link;data exchange;PCU digital hardware;Low Cost Android tablet;distributed RES Power Conditioning Unit;graphical visualization enhanced;touch screen interface;Androids;Humanoid robots;Monitoring;Internet;Power generation;Renewable energy sources;Hardware;RES- Renewable Energy Source;PCU- Power Conditioning Unit;SPV-Solar Photovoltaic;UART - Universal asynchronous receiver/transmitter;HMI- Human Machine Interface;LCD- Liquid Crystal Display;DSP- Digital Signal Processor},
doi={10.1109/I4CT.2014.6914208},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6676549,
author={M. {Masoodian} and B. {Endrass} and R. {Bühling} and P. {Ermolin} and E. {André}},
booktitle={2013 17th International Conference on Information Visualisation},
title={Time-Pie visualization: Providing Contextual Information for Energy Consumption Data},
year={2013},
volume={},
number={},
pages={102-107},
abstract={In recent years a growing number of information visualization systems have been developed to assist users with monitoring their energy consumption, with the hope of reducing energy use through more effective user-awareness. Most of these visualizations can be categorized into either some form of a time-series or pie chart, each with their own limitations. These visualization systems also often ignore incorporating contextual (e.g. weather, environmental) information which could assist users with better interpretation of their energy use information. In this paper we introduce the time-pie visualization technique, which combines the concepts of timeseries and pie charts, and allows the addition of contextual information to energy consumption data.},
keywords={data visualisation;power aware computing;time series;contextual information;energy consumption data;information visualization systems;energy consumption reduction;time-series;pie chart;time-pie visualization technique;Data visualization;Energy consumption;Prototypes;Buildings;Context;Meteorology;Sensors;Energy usage visualization;energy usage monitoring;energy usage management;time-line visualization;pie chart visualization;rose chart;time-pie visualization},
doi={10.1109/IV.2013.12},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{7272575,
author={M. {Masoodian} and B. {Lugrin} and R. {Bühling} and E. {André}},
booktitle={2015 19th International Conference on Information Visualisation},
title={Visualization Support for Comparing Energy Consumption Data},
year={2015},
volume={},
number={},
pages={28-34},
abstract={Providing effective feedback can empower users to change their behaviour and take the necessary actions to reduce their energy consumption. The types of feedback that allow comparison of energy usage seem to be particularly valuable. This paper introduces the time-stack visualization, which has been designed to support comparisons of individual and collective energy usage data. It also describes a user study conducted to compare the effectiveness of time-stack against a similar visualization called time-pie. The results show that although the two visualizations are generally comparable in their effectiveness, users rate time-stack more favourably.},
keywords={data visualisation;energy consumption;environmental science computing;visualization support;energy consumption data comparison;energy consumption reduction;user behavior;energy usage comparison;time-stack visualization;energy usage data;user study;time-pie visualization;Data visualization;Energy consumption;Prototypes;Clocks;Monitoring;Computers;Computer science;Energy usage visualization;energy usage monitoring;time-base visualizations;time-stack;time-pie},
doi={10.1109/iV.2015.17},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{7361163,
author={C. {Akasiadis} and K. {Panagidi} and N. {Panagiotou} and P. {Sernani} and A. {Morton} and I. A. {Vetsikas} and L. {Mavrouli} and K. {Goutsias}},
booktitle={2015 SAI Intelligent Systems Conference (IntelliSys)},
title={Incentives for rescheduling residential electricity consumption to promote renewable energy usage},
year={2015},
volume={},
number={},
pages={328-337},
abstract={Managing energy consumption and production is a challenging problem and proactive balancing between the amount of electricity produced and consumed is needed. In this work, we examine mechanisms that give incentives to consumers to efficiently reschedule their demand, thus balancing the overall energy production and consumption. Viewing the smart grid as a MAS, each agent represents a consumer; this agent takes into account its user's preferences and proposes an optimal energy consumption plan via a gamified GUI. To implement this we propose a distributed architecture through which we give the incentives (either economic, or social); we test a number of pricing mechanisms and we develop a very fast agent optimization strategy. We also present experiments both from software simulations on real data and pilot tests with human participants: the simulations allow to evaluate the mechanisms and agents, whilst the gamified tests are useful to assess the usability of the GUI and the usefulness of the agent suggestions. With human subjects, we evaluated which type of incentives is more compelling: economic or social. Results validate that by using our agent optimization approach the performance of the smart grid can be improved, and that specific mechanisms allow better utilization of renewable sources.},
keywords={digital simulation;energy consumption;graphical user interfaces;multi-agent systems;optimisation;power engineering computing;power generation scheduling;renewable energy sources;smart power grids;agent optimization approach;agent suggestions;software simulations;agent optimization strategy;pricing mechanisms;distributed architecture;gamified GUI;optimal energy consumption plan;MAS;smart grid;energy production;energy consumption;renewable energy usage;residential electricity consumption rescheduling incentives;Data visualization;Energy management;Games;Green products;Informatics;Telecommunications;Production;Demand-side Management;Serious Games;Multi-agent Systems},
doi={10.1109/IntelliSys.2015.7361163},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8107961,
author={M. {Masoodian} and I. {Buchwald} and S. {Luz} and E. {André}},
booktitle={2017 21st International Conference Information Visualisation (IV)},
title={Temporal Visualization of Energy Consumption Loads Using Time-Tone},
year={2017},
volume={},
number={},
pages={146-151},
abstract={Feedback plays an important role in assisting users to better understand their energy consumption behaviour. This is particularly true when users want to change their behaviour in order to reduce their energy consumption, and to manage their usage more effectively so as to avoid putting unnecessary load on energy providers. This paper presents the time-tone visualization, which aims to assist users by displaying variations in energy consumption by different categories of household devices over time, and their respective contributions to the total energy usage load. A user study conducted to compare time-tone against area-charts shows that although the two visualizations are comparable, time-tone is more effective for cases where there are large variations in energy usage loads.},
keywords={data visualisation;energy consumption;load management;temporal visualization;energy consumption loads;energy consumption behaviour;unnecessary load;energy providers;time-tone visualization;total energy usage load;household devices;Data visualization;Energy consumption;Brightness;Water heating;Image color analysis;Visualization;Prototypes;Energy usage visualizations;energy usage load;time-tone;area-charts;timelines;time-series;time-based data},
doi={10.1109/iV.2017.13},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{6344595,
author={J. {Zhu} and E. {Zhuang} and C. {Ivanov} and Z. {Yao}},
booktitle={2012 IEEE Power and Energy Society General Meeting},
title={A data-driven approach to interactive visualization of power systems},
year={2012},
volume={},
number={},
pages={1-1},
abstract={Summary form only given. Information visualization appears to be a promising technique for improving the business practices in today's electric power industry. The legacy power system visualization tools, however, restrict the visualization process to follow a limited number of pre-defined patterns created by human designers, thus hindering users' ability to discover. This paper proposes a data-driven approach to interactive visualization of power systems. The proposed approach relies on developing powerful data manipulation algorithms to create visualizations based on the characteristics of empirically or mathematically derived data. Based on this approach, a data-driven model exploratory tool has been developed to enable users to visualize the power system's physical/electrical configurations at various levels and from different perspectives. The conducted case studies have demonstrated that the data-driven approach could result in an interactive and user-driven power system visualization tool that fosters scientific understanding and insight, therefore unleashing the power of visualization.},
keywords={data visualisation;electricity supply industry;power engineering computing;data-driven approach;power system interactive visualization process;information visualization;legacy power system visualization tools;data manipulation algorithms;user-driven power system visualization tool;electric power industry;Power systems;Data visualization;Business;Industries;Humans;Algorithm design and analysis;Mathematical model},
doi={10.1109/PESGM.2012.6344595},
ISSN={1944-9925},
month={July},}
@INPROCEEDINGS{8849061,
author={T. {Cerquitelli} and E. {Di Corso} and S. {Proto} and A. {Capozzoli} and D. {Mazzarelli} and A. {Nasso} and E. {Baralis} and M. {Mellia} and S. {Casagrande} and M. {Tamburini}},
booktitle={2019 International Conference on Smart Energy Systems and Technologies (SEST)},
title={Visualising high-resolution energy maps through the exploratory analysis of energy performance certificates},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper presents a new data mining engine, named EXTREMA (EXploitation of Turin high Resolution Energy MAps), to automatically visualise high-resolution energy maps exploring interesting and human-readable knowledge items from large collections of EPCs. EXTREMA, developed in Python, generates geo-located maps to summarise the main relationships among variables affecting the energy efficiency of buildings at different spatial granularity levels. The visualised knowledge is discovered through a two-level data analytics methodology based on exploratory and unsupervised algorithms. First an unsupervised algorithm divides EPCs into homogeneous groups of buildings with similar thermo-physical characteristics. Each group is then locally characterised through interesting patterns to concisely represent each group. The experimental evaluation, performed on a real dataset collected in a major Italian city in North-West Italy, demonstrates the effectiveness of EXTREMA in extracting and graphically display on geo-located multivariate energy maps a manageable set of human-readable knowledge items.},
keywords={building management systems;data analysis;data mining;data visualisation;energy conservation;geophysical image processing;image resolution;high-resolution energy maps;energy performance certificates;data mining engine;human-readable knowledge items;geo-located maps;visualised knowledge;two-level data analytics methodology;geo-located multivariate energy maps;unsupervised algorithm;spatial granularity levels;EXTREMA;exploitation of Turin high resolution energy maps;visualisation;energy efficiency;buildings;thermo-physical characteristics;Buildings;Data visualization;Energy consumption;Energy resolution;Urban areas;Clustering algorithms;Engines;Energy-related data;visualisation techniques;geo-located maps;cluster analysis;pattern discovery},
doi={10.1109/SEST.2019.8849061},
ISSN={},
month={Sep.},}
@ARTICLE{8017597,
author={L. E. {Matzen} and M. J. {Haass} and K. M. {Divis} and Z. {Wang} and A. T. {Wilson}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations},
year={2018},
volume={24},
number={1},
pages={563-573},
abstract={Evaluating the effectiveness of data visualizations is a challenging undertaking and often relies on one-off studies that test a visualization in the context of one specific task. Researchers across the fields of data science, visualization, and human-computer interaction are calling for foundational tools and principles that could be applied to assessing the effectiveness of data visualizations in a more rapid and generalizable manner. One possibility for such a tool is a model of visual saliency for data visualizations. Visual saliency models are typically based on the properties of the human visual cortex and predict which areas of a scene have visual features (e.g. color, luminance, edges) that are likely to draw a viewer's attention. While these models can accurately predict where viewers will look in a natural scene, they typically do not perform well for abstract data visualizations. In this paper, we discuss the reasons for the poor performance of existing saliency models when applied to data visualizations. We introduce the Data Visualization Saliency (DVS) model, a saliency model tailored to address some of these weaknesses, and we test the performance of the DVS model and existing saliency models by comparing the saliency maps produced by the models to eye tracking data obtained from human viewers. Finally, we describe how modified saliency models could be used as general tools for assessing the effectiveness of visualizations, including the strengths and weaknesses of this approach.},
keywords={computer vision;data visualisation;feature extraction;image colour analysis;natural scenes;neurophysiology;object detection;saliency maps;DVS model;data visualization saliency model;human visual cortex;visual saliency models;modified saliency models;eye tracking data;abstract data visualizations;visual features;Data visualization;Visualization;Measurement;Data models;Brain modeling;Predictive models;Tools;Visual saliency;evaluation;eye tracking},
doi={10.1109/TVCG.2017.2743939},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{5613467,
author={S. {Gerber} and P. {Bremer} and V. {Pascucci} and R. {Whitaker}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Visual Exploration of High Dimensional Scalar Functions},
year={2010},
volume={16},
number={6},
pages={1271-1280},
abstract={An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.},
keywords={computational geometry;curve fitting;data visualisation;image processing;scientific information systems;topology;visual exploration;high dimensional scalar function;scientific data analysis;system behavior;energy landscape;optimization problem;image data analysis;biological parameter;medical parameter;data set visualization;topological technique;geometric technique;interactive visualization;parameter space segmentation;Morse-Smale complex;geometric representation;dimension reduction;geometric property;regression curve;climate simulation;global energy flux;chemical species;UCI;machine learning repository;Crystals;Manifolds;Approximation methods;Data visualization;Kernel;Geometry;Concrete;Morse theory;High-dimensional visualization;Morse-Smale complex;Brain;Computer Graphics;Computer Simulation;Data Display;Data Interpretation, Statistical;Humans;Magnetic Resonance Imaging},
doi={10.1109/TVCG.2010.213},
ISSN={1941-0506},
month={Nov},}
@INPROCEEDINGS{7431052,
author={A. {Kimura} and S. {Tanaka} and T. {Sasaki}},
booktitle={2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)},
title={Visualization software for multiple data in radiation simulations},
year={2014},
volume={},
number={},
pages={1-4},
abstract={Radiation simulations have been widely used in high energy physics, nuclear physics, accelerator physics, medical science, and space science. The simulations generate particle trajectories and physical quantities in detectors, equipment or a human body. Therefore, visualization system has to process and draw complex and huge data in such simulations. We have been developing visualization software for multiple data generated by radiation simulations. Techniques of the computer visualization are introduced in explaining such multiple and complex data. The visualization software is capable of drawing multiple data such as particle trajectories, physical quantities, detectors, equipment, and a human body data in a simulation. In order to draw them, it has functions of rendering various dimensional data simultaneously, which are point, line, plane, and volume data. It is standalone software for Windows, MacOS X, and Linux.},
keywords={data visualisation;digital simulation;Linux;MacOS X;Windows;dimensional data;human body data;equipment;detector;complex data;multiple data;computer visualization;visualization system;physical quantity;particle trajectory;space science;medical science;accelerator physics;nuclear physics;high energy physics;radiation simulation;visualization software;Data visualization;Software;Data models;DICOM;Computational modeling;Physics},
doi={10.1109/NSSMIC.2014.7431052},
ISSN={},
month={Nov},}
@ARTICLE{7534744,
author={R. J. {Crouser} and L. {Franklin} and A. {Endert} and K. {Cook}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems},
year={2017},
volume={23},
number={1},
pages={121-130},
abstract={Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity.},
keywords={data visualisation;human computer interaction;human factors;human effort;human-machine collaboration;machine computation;user tasks modeling;hybrid visual analytic systems;human oracle model;sensemaking;cybersecurity;Genomics;Bioinformatics;Biological cells;Visualization;Animals;Vegetation;Education;Theoretical models;human oracle;visual analytics;mixed initiative systems;semantic interaction;sensemaking},
doi={10.1109/TVCG.2016.2598460},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{6307237,
author={J. {Xing} and W. {Liu} and Q. {Liu} and Y. {Shi}},
booktitle={2012 Asia-Pacific Power and Energy Engineering Conference},
title={GDI and OpenGL-Based Implementation of Visualization for the Grid Maintenance Planning Support System},
year={2012},
volume={},
number={},
pages={1-4},
abstract={Intelligent Dispatching is an important part of the Smart Grid. As an important means of human-computer interaction, visualization does not only provide a new solution ideas and implementation methods for the Intelligent Dispatching, but also makes it more humane and friendly. This paper illustrates the functional design, implementation methods and program logic in terms of the visual implementation of grid maintenance planning support system in detail, with the Drawing Package program and the Power Flow Animation program as examples described and proven. The method discussed herein has a strong versatility and maintainability for the current needs of smart grid development.},
keywords={application program interfaces;computer animation;data visualisation;human computer interaction;load dispatching;load flow;maintenance engineering;power engineering computing;power system planning;smart power grids;GDI;OpenGL-based implementation;visualization;grid maintenance planning support system;intelligent dispatching;human-computer interaction;program logic;drawing package program;power flow animation program;smart grid development;graphics device interface;Maintenance engineering;Load flow;Animation;Visualization;Data visualization;Substations},
doi={10.1109/APPEEC.2012.6307237},
ISSN={2157-4847},
month={March},}
@INPROCEEDINGS{6060315,
author={R. {Takashide} and Y. {Chigusa} and S. {Takahira}},
booktitle={SICE Annual Conference 2011},
title={Approaching the measurement about human behavior and environmental behavior by "Guideware". ∼Application possibility of “Guideware” ∼ (Report 1)},
year={2011},
volume={},
number={},
pages={2084-2089},
abstract={This study explores influences and impacts of time, location and environmental information, to decision-making process in human behavior (at offices and houses), and examines the methodology to determine occurrence factors of such decision-makings. The study also reveals how to compile the analyzed data efficiently, how to visualize the results, and how to provide feedback of the results to the decision-making persons. Additionally, ICT in agricultural industry is also evaluated as one of the potential application of this methodology.},
keywords={behavioural sciences computing;computerised instrumentation;data analysis;data visualisation;decision making;environmental science computing;human computer interaction;human behavior measurement;environmental behavior measurement;Guideware;decision-making process;data analysis;result visualization;ICT;agricultural industry;Humans;Energy consumption;Sensors;Data visualization;Decision making;Buildings;Temperature measurement;Semantic WEB;Augmented reality;Environment assessment;DB;Guideware},
doi={},
ISSN={},
month={Sep.},}
@ARTICLE{8395068,
author={S. {Bruckner} and T. {Isenberg} and T. {Ropinski} and A. {Wiebel}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={A Model of Spatial Directness in Interactive Visualization},
year={2019},
volume={25},
number={8},
pages={2514-2528},
abstract={We discuss the concept of directness in the context of spatial interaction with visualization. In particular, we propose a model that allows practitioners to analyze and describe the spatial directness of interaction techniques, ultimately to be able to better understand interaction issues that may affect usability. To reach these goals, we distinguish between different types of directness. Each type of directness depends on a particular mapping between different spaces, for which we consider the data space, the visualization space, the output space, the user space, the manipulation space, and the interaction space. In addition to the introduction of the model itself, we also show how to apply it to several real-world interaction scenarios in visualization, and thus discuss the resulting types of spatial directness, without recommending either more direct or more indirect interaction techniques. In particular, we will demonstrate descriptive and evaluative usage of the proposed model, and also briefly discuss its generative usage.},
keywords={data visualisation;interactive systems;user interfaces;data space;visualization space;spatial directness model;direct interaction techniques;spatial interaction;interactive visualization;more indirect interaction techniques;interaction space;manipulation space;user space;output space;Data visualization;Three-dimensional displays;Visualization;Object oriented modeling;Two dimensional displays;Rendering (computer graphics);Computational modeling;Visualization;direct interaction;human-computer interaction (HCI)},
doi={10.1109/TVCG.2018.2848906},
ISSN={1941-0506},
month={Aug},}
@ARTICLE{6280549,
author={Y. {Yang} and X. {Guo} and J. {Vick} and L. G. {Torres} and T. F. {Campbell}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Physics-Based Deformable Tongue Visualization},
year={2013},
volume={19},
number={5},
pages={811-823},
abstract={In this paper, a physics-based framework is presented to visualize the human tongue deformation. The tongue is modeled with the Finite Element Method (FEM) and driven by the motion capture data gathered during speech production. Several novel deformation visualization techniques are presented for in-depth data analysis and exploration. To reveal the hidden semantic information of the tongue deformation, we present a novel physics-based volume segmentation algorithm. This is accomplished by decomposing the tongue model into segments based on its deformation pattern with the computation of deformation subspaces and fitting the target deformation locally at each segment. In addition, the strain energy is utilized to provide an intuitive low-dimensional visualization for the high-dimensional sequential motion. Energy-interpolation-based morphing is also equipped to effectively highlight the subtle differences of the 3D deformed shapes without any visual occlusion. Our experimental results and analysis demonstrate the effectiveness of this framework. The proposed methods, though originally designed for the exploration of the tongue deformation, are also valid for general deformation analysis of other shapes.},
keywords={data analysis;data visualisation;deformation;finite element analysis;image segmentation;interpolation;speech processing;physics-based deformable tongue visualization;physics-based framework;human tongue deformation visualization;finite element method;FEM;motion capture data;speech production;deformation visualization techniques;in-depth data analysis;hidden semantic information;physics-based volume segmentation algorithm;deformation subspace computation;local target deformation;strain energy;intuitive low-dimensional visualization;high-dimensional sequential motion;energy interpolation-based morphing;3D deformed shapes;visual occlusion;Tongue;Sensors;Speech;Production;Shape;Deformable models;Visualization;Deformable model;tongue;finite element method;modal analysis;Algorithms;Biophysics;Computer Graphics;Computer Simulation;Elastic Modulus;Humans;Imaging, Three-Dimensional;Models, Biological;Movement;Reproducibility of Results;Sensitivity and Specificity;Speech;Tongue;Tongue;User-Computer Interface},
doi={10.1109/TVCG.2012.174},
ISSN={1941-0506},
month={May},}
@INPROCEEDINGS{7961559,
author={V. {Ferrer} and A. {Perdomo} and H. R. {Ali} and C. {Fies} and J. {Quarles}},
booktitle={2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual Augmented Reality (KELVAR)},
title={Virtual humans for temperature visualization in a tangible augmented reality educational game},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Our primary objective is to enable effective game based learning approaches in tangible augmented reality. In game based learning there is often a tradeoff in motivation between the educational aspects and game aspects. For example, consider our previous work - a tangible augmented reality application for passive solar energy education (AR-SEE), in which users learn about the science behind architectural design by interacting with a tangible model house and an augmented reality-based visualization of energy transfer within the house. This research extends AR-SEE to begin to convert this educational simulation into an effective educational game by introducing gaming elements, such as interactive virtual humans. Although it is known that AR-SEE does enable learning, it is unknown how the addition of interactive virtual humans will affect user perception of temperature data and learning. In this paper, the goal was to compare user perception of two approaches to temperature data visualization in in tangible augmented reality on mobile phones: (1) the current particle-based visualization (i.e., based on the science of energy transfer) and (2) novel virtual human-based visualizations. The game was intended for high school students. However, as a preliminary study, we conducted a user study with 27 3rd and 4th year architecture students that compared these two visualization approaches and their impact on temperature estimation, motivation, and perceived learning effectiveness. In the future, we plan to integrate this game into high school curricula.},
keywords={augmented reality;computer aided instruction;computer games;data visualisation;educational courses;educational institutions;human factors;mobile computing;virtual humans;temperature visualization;tangible augmented reality educational game;educational aspects;game aspects;educational simulation;mobile phones;particle-based visualization;virtual human-based visualizations;high school curricula;Estimation;Education;Cameras;Measurement;Solar energy;Heating systems;Augmented reality;education;visualization},
doi={10.1109/KELVAR.2017.7961559},
ISSN={},
month={March},}
@ARTICLE{8281629,
author={T. {Blascheck} and L. M. {Vermeulen} and J. {Vermeulen} and C. {Perin} and W. {Willett} and T. {Ertl} and S. {Carpendale}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Exploration Strategies for Discovery of Interactivity in Visualizations},
year={2019},
volume={25},
number={2},
pages={1407-1420},
abstract={We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualization's functionality.},
keywords={audio recording;data visualisation;eye;human computer interaction;interactive systems;public administration;interactive visualization;public energy data;interaction logs;exploration strategies;general public;design directions;Data visualization;Tools;Visualization;Audio recording;Indexes;Government;Bars;Discovery;visualization;open data;evaluation;eye tracking;interaction logs;think-aloud},
doi={10.1109/TVCG.2018.2802520},
ISSN={1941-0506},
month={Feb},}
@ARTICLE{7539643,
author={X. {Tong} and C. {Li} and H. {Shen}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization},
year={2017},
volume={23},
number={1},
pages={891-900},
abstract={Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.},
keywords={data visualisation;interactive systems;solid modelling;GlyphLens;view-dependent occlusion management;interactive glyph visualization;multivariate visualization technique;visual channels;3D volumetric dataset;2D surface;slicing plane;feature surface;3D spatial structure;view-dependent interactive 3D lens;space deformation models;lens shape models;spatial distributions;user-interested region;context information;display-interaction techniques;Lenses;Three-dimensional displays;Context;Data visualization;Shape;Probes;Visualization;View-dependent visualization;focus + context techniques;manipulation and deformation;glyph-based techniques;human-computer interaction},
doi={10.1109/TVCG.2016.2599049},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{8260303,
author={A. {Khoshrou} and A. B. {Dorsman} and E. J. {Pauwels}},
booktitle={2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)},
title={SVD-based visualisation and approximation for time series data in smart energy systems},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Many time series in smart energy systems exhibit two different timescales. On the one hand there are patterns linked to daily human activities. On the other hand, there are relatively slow trends linked to seasonal variations. In this paper we interpret these time series as matrices, to be visualized as images. This approach has two advantages: First of all, interpreting such time series as images enables one to visually integrate across the image and makes it therefore easier to spot subtle or faint features. Second, the matrix interpretation also grants elucidation of the underlying structure using well-established matrix decomposition methods. We will illustrate both these aspects for data obtained from the German day-ahead market.},
keywords={data visualisation;matrix decomposition;power engineering computing;power markets;singular value decomposition;smart power grids;time series;time series data;smart energy systems;matrix interpretation;SVD-based visualisation;matrix decomposition methods;German day-ahead market;Time series analysis;Matrix decomposition;Data visualization;Electronic mail;Market research;Renewable energy sources;Power system stability;Data analysis;Data preprocessing;Renewable energy sources;Smart grids;Time series analysis},
doi={10.1109/ISGTEurope.2017.8260303},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6758771,
author={D. S. {Ebert} and T. {Ertl} and K. {Gaither}},
booktitle={2014 47th Hawaii International Conference on System Sciences},
title={Introduction to Visualization and Analytics for Decision Support, Operational Management, and Scientific Discovery Minitrack},
year={2014},
volume={},
number={},
pages={1353-1353},
abstract={The topic of this minitrack will have applications in a broad range of situations where human expertise must be brought to bear on problems characterized by massive datasets and data that are uncertain in fact, relevance, location in space and position in time. Examples include environmental science and technologies, natural resources and energy, health and related life sciences, safety and security (aircraft safety, law enforcement, antiterrorism, disaster relief) and business processes. This year we focused on extending the areas of use to include a broader range of analytic tasks such as science and technology, public health, business intelligence, financial analysis, and other domains where interactive visualization systems may be used to improve human decision making.},
keywords={data visualisation;decision support systems;interactive systems;decision support visualization;decision support analytics;operational management;scientific discovery;human expertise;massive datasets;environmental science;natural resources;energy;related life sciences;security;aircraft safety;law enforcement;antiterrorism;disaster relief;business processes;science and technology;public health;business intelligence;financial analysis;interactive visualization systems;human decision making;Visual analytics;Educational institutions;Safety;Data visualization;Decision making},
doi={10.1109/HICSS.2014.174},
ISSN={1530-1605},
month={Jan},}
@ARTICLE{7539391,
author={C. {Bryan} and G. {Guterman} and K. {Ma} and H. {Lewin} and D. {Larkin} and J. {Kim} and J. {Ma} and M. {Farré}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution},
year={2017},
volume={23},
number={1},
pages={711-720},
abstract={Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.},
keywords={bioinformatics;biomedical education;computer aided instruction;computer animation;data visualisation;DNA;educational institutions;further education;genomics;teaching;synteny explorer;interactive visualization application;genome evolution teaching;homologous DNA;karyogram based approach;color design;animation design;system usability testing;biology faculty;genomic facult;bioinformatics visualization;undergraduate-level genome evolution education;Genomics;Bioinformatics;Biological cells;Visualization;Animals;Vegetation;Education;Bioinformatic visualization;education;learning;genome evolution;chromosome;user study;Animals;Chromosome Mapping;Computer Graphics;Genomics;Humans;Image Processing, Computer-Assisted;Phylogeny;Synteny;User-Computer Interface},
doi={10.1109/TVCG.2016.2598789},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{5701846,
author={R. M. {Rasli} and R. M. {Rasli} and N. M. {Norwawi}},
booktitle={2010 Second International Conference on Computational Intelligence, Modelling and Simulation},
title={Implementation of Information Visualization in Reservoir Application},
year={2010},
volume={},
number={},
pages={205-210},
abstract={Reservoir provides many benefits to human life generally and public society specifically. It leads to the generalization of energy, supplying and irrigating water for human use, hence improving human daily basis activities and fulfilling human needs. Yet, everything has its own weaknesses. As for the reservoir situation, there is a possibility of the operation to be failed and will leads to the creation of flood that is very harmful for the area of the reservoir. This research had been conducted with the implementation of information visualization, data mining and case based reasoning techniques in order to help the process of generating visualization result in opening or closing the gate of the dam to channel out excessive water. As a conclusion, the process of visualizing numerical values is proven to be faster than the normal process. Using visualization, people tend to make fewer mistakes for a large quantity of data. However, for upcoming time-being, it is advised that some methods of calculating the similarity of these visualize cases is implemented since visualization alone is still not enough to provide precise results.},
keywords={case-based reasoning;dams;data mining;data visualisation;floods;health and safety;irrigation;reservoirs;information visualization;reservoir;water irrigation;human needs;data mining;case based reasoning techniques;dam;Data visualization;Reservoirs;Data mining;Delta modulation;Logic gates;Humans;Visualization;Information visualization;data mining;case based reasoning;reservoir;Timah Tasoh Dam},
doi={10.1109/CIMSiM.2010.81},
ISSN={2166-8531},
month={Sep.},}
@INPROCEEDINGS{8521625,
author={R. {Athira} and V. V. {Nair} and R. {Sunitha}},
booktitle={2018 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)},
title={Fault Detection and Visualization Technique for Hybrid Electric Vehicle Components},
year={2018},
volume={},
number={},
pages={165-169},
abstract={The aim of the paper is to efficiently distinguish the abnormalities in huge datasets by employing different mechanisms like visualization techniques and algorithms. These methods classify faulty data from available test data and represent it visually. In data visualization human interpretation is required to detect abnormalities while the algorithm classifies faulty and healthy data using rule-based algorithms. The parallel coordinates plot is developed in MATLAB. Fault diagnosis in Permanent Magnet Synchronous Motor (PMSM) was done by means of pattern recognition algorithm based on the Concordia transform. The algorithm is simulated in MATLAB with original vehicle test data. The proposed fault detection algorithm holds good for analysis of variable speed and variable torque drives.},
keywords={data visualisation;fault diagnosis;hybrid electric vehicles;knowledge based systems;motor drives;pattern classification;permanent magnet motors;power engineering computing;synchronous motors;torque;transforms;fault diagnosis;pattern recognition algorithm;MATLAB;fault detection algorithm;visualization technique;hybrid electric vehicle components;rule-based algorithms;parallel coordinates plot;permanent magnet synchronous motor;vehicle test data;faulty data classification;data visualization;Concordia transform;variable speed;variable torque drives;Transforms;Switches;Fault detection;Stators;Data visualization;Classification algorithms;Inverters;datavisualization;parallel-coordinates;PMSM;concordia transform},
doi={10.1109/ICPECTS.2018.8521625},
ISSN={},
month={Feb},}
@INPROCEEDINGS{7004342,
author={G. {Stavropoulos} and S. {Krinidis} and D. {Ioannidis} and K. {Moustakas} and D. {Tzovaras}},
booktitle={2014 IEEE International Conference on Big Data (Big Data)},
title={A building performance evaluation visualization system},
year={2014},
volume={},
number={},
pages={1077-1085},
abstract={A novel big data building performance evaluation knowledge processing and mining system utilizing visual analytics is going to be presented in this paper. A large dataset comprised of building information, energy consumption, environmental measurements, human presence and behavior and business processes is going to be exploited for the building performance evaluation. Building performance evaluation is one of the most important factors in engineering that leads to building renovation and construction with low energy consumption and gas emissions in conjunction with comfort, utility and durability. For this purpose, business processes occurring in the building are correlated with the energy consumption and the human flows in the spatiotemporal domain modeling the dynamic behavior of the building. These models lead to the extraction of useful semantic information and the detection of spatiotemporal patterns that are important for the evaluation of the building performance. Furthermore, a number of novel visual analytics techniques allow the end-users to process data in different temporal resolutions and with different temporal filters, assisting them to detect patterns that may be difficult to be detected otherwise. The proposed visual analytics techniques support design and energy management decisions by visualizing the building measurements regarding business and comfort aspects. To do so, the proposed system includes a variety of techniques and components, properly selected to offer quick identification of focal points and evaluation of the building performance. Considering the increasing interest and the green building goals of almost all world governments including EU, the suggested methodology and application could be rendered a very useful tool for the Architecture and Engineering Community working on Building Performance Simulation and Analysis, and all related communities in Architect, Engineering and Construction (AEC) industry.},
keywords={buildings (structures);data mining;data visualisation;design engineering;energy consumption;structural engineering computing;visualization system;big data building performance evaluation;knowledge mining system;visual analytics;building information;energy consumption;environmental measurement;building renovation;building construction;gas emission;durability;spatiotemporal domain modeling;semantic information;energy management;green building;Buildings;Energy consumption;Data visualization;Data mining;Energy measurement;Sensors;Business;Visual analytics;knowledge mining;building measurements;environmental measurements;business processes},
doi={10.1109/BigData.2014.7004342},
ISSN={},
month={Oct},}
@ARTICLE{9109317,
author={A. B. {Birchfield} and T. J. {Overbye}},
journal={IEEE Open Access Journal of Power and Energy},
title={Mosaic Packing to Visualize Large-Scale Electric Grid Data},
year={2020},
volume={7},
number={},
pages={212-221},
abstract={For large power systems, a continual challenge is to display wide-area data in a way that maximizes human users' situational awareness. This paper describes a new visualization technique that draws a mosaic of colored tiles to represent multiple data fields for electric grid objects, arranged to preserve geographic context. The key problem in creating these diagrams is packing the tiles onto the display space, minimizing the total displacement while forbidding overlaps. This paper formulates that problem and presents a horizontal-packing algorithm which is able to produce a feasible, quality solution at an interactive time scale. Illustrative examples are shown for using mosaics to monitor wide-area generator status and dispatch, bus voltages, and line and transformer limits. Mosaics can be customized in numerous ways to show different aspects of the system state, providing for human users a simultaneous sense of the wide-area summary, regional trends, and prominent outliers.},
keywords={data visualisation;power engineering computing;power grids;mosaic packing;wide-area summary;system state;generator dispatch;wide-area generator status;interactive time scale;quality solution;feasible solution;horizontal-packing algorithm;total displacement;display space;geographic context;electric grid objects;multiple data fields;colored tiles;visualization technique;human users;wide-area data;continual challenge;power systems;large-scale electric grid data;Data visualization;Power systems;Fuels;Open Access;Generators;Licenses;Image color analysis;Power system visualization;mosaic displays;wide-area data visualization;packing problem},
doi={10.1109/OAJPE.2020.3000464},
ISSN={2687-7910},
month={},}
@INPROCEEDINGS{6883045,
author={T. {Carção}},
booktitle={2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
title={Measuring and visualizing energy consumption within software code},
year={2014},
volume={},
number={},
pages={181-182},
abstract={The authors have begun to witness an exponential growth in the information and communication technologies (ICT) sector. While undoubtedly a milestone, all of this occurs at the expense of high energy costs needed to supply servers, data centers, and any use of computers. Associated with these high energy costs is the emission of greenhouse gases. These two issues have become major problems in society. The ICT sector contributes up to 8% of the overall energy consumption, with 50% of the energy costs of an organization being attributed to the IT departments.The paper discusses a tool which applies the proposed techniques on software code. This tool would guide the developer into programming more energy-aware software by alerting him/her of red smells, and offering green refactorings, all this in a simple visual layout to allow the software developer to become energy-aware. This application will also provide the ability to navigate between less energy efficient areas (packages, classes, modules, functions, methods, blocks and even lines), making its implementation more energy efficient.},
keywords={data visualisation;energy conservation;power aware computing;software engineering;energy consumption visualization;energy consumption measurement;software code;information and communication technologies;ICT sector growth;energy costs;greenhouse gas emission;energy consumption;energy-aware software;green refactorings;Software;Green products;Visualization;Energy consumption;Energy measurement;Hardware;Catalogs},
doi={10.1109/VLHCC.2014.6883045},
ISSN={1943-6106},
month={July},}
@INPROCEEDINGS{8823763,
author={D. A. B. {Hyde} and T. R. {Hall} and J. {Caers}},
booktitle={2018 IEEE Scientific Visualization Conference (SciVis)},
title={VRGE: An Immersive Visualization Application for the Geosciences},
year={2018},
volume={},
number={},
pages={1-5},
abstract={The rapid onset of inexpensive, portable virtual reality (VR) devices has created opportunities for scientific visualization tools that harness this new, immersive modality. Researchers in the geological sciences, in particular those focused on earth resources (energy, water, minerals), are faced with significant challenges in building and understanding increasingly complex geological models. In this paper, we address these joint opportunities by introducing the Virtual Reality Geomodeling Environment (VRGE): a scientific visualization tool leveraging the Oculus Rift VR system, specialized for users involved in geological modeling. VRGE offers a number of features for viewing and interacting with geological models in VR, including human-centric navigation and manipulation, implicit surface editing, visual conditioning, and uncertainty analysis. Moreover, we examine how the design of VRGE meets current needs of the earth resources industry, in the context of reviewing the state-of-the-art, conducting an expert survey, and discussing performance.},
keywords={data visualisation;geophysics computing;virtual reality;geological modeling;VRGE;visual conditioning;earth resources industry;immersive visualization application;scientific visualization tool;immersive modality;geological sciences;complex geological models;virtual reality geomodeling environment;virtual reality devices;surface editing;Oculus rift VR system;uncertainty analysis;human-centric navigation;Geology;Solid modeling;Three-dimensional displays;Data models;Uncertainty;Data visualization;Virtual reality;Virtual reality;scientific visualization;geological modeling;implicit surfaces},
doi={10.1109/SciVis.2018.8823763},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6945168,
author={A. {Foncubierta-Rodríguez} and A. {Widmer} and A. {Depeursinge} and H. {Müller}},
booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Enhanced visualization of pulmonary perfusion in 4D Dual Energy CT images},
year={2014},
volume={},
number={},
pages={6710-6713},
abstract={Pulmonary embolism (PE) affects up to 600,000 patients and contributes to at least 100,000 deaths every year in the United States alone. Diagnosis of PE can be difficult as most symptoms are unspecific. Computed Tomography (CT) angiography is the reference for diagnosing PE. CT angiography produces grayscale images with darker areas representing any mass filling defects, making the analysis of the images difficult. This article demonstrates a method using the combination of energy levels in Dual Energy CT images to highlight the presence of PE in the lung. The results show that pairing different energy levels from 40 to 140 keV can increase the contrast between well perfused areas and underperfused areas of the lung. In addition, the visualization used in the current study complies with the window/level settings usually employed by radiologists.},
keywords={computerised tomography;data visualisation;diseases;image enhancement;lung;medical image processing;radiologists;window/level settings;underperfused areas;well perfused areas;contrast;lung;energy levels;mass filling defects;darker areas;grayscale images;CT angiography;Computed Tomography angiography;PE diagnosis;pulmonary embolism;4D Dual Energy CT images;pulmonary perfusion;enhanced visualization;electron volt energy 40 keV to 140 keV;Energy states;Computed tomography;Lungs;Image color analysis;Indexes;Brain modeling;Materials;Angiography;Contrast Media;Four-Dimensional Computed Tomography;Humans;Lung;Perfusion;Pulmonary Embolism;Sensitivity and Specificity},
doi={10.1109/EMBC.2014.6945168},
ISSN={1558-4615},
month={Aug},}
@ARTICLE{7539331,
author={P. {Hermosilla} and J. {Estrada} and V. {Guallar} and T. {Ropinski} and À. {Vinacua} and P. {Vázquez}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Physics-Based Visual Characterization of Molecular Interaction Forces},
year={2017},
volume={23},
number={1},
pages={731-740},
abstract={Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.},
keywords={biotechnology;chemical engineering computing;data visualisation;design engineering;molecular dynamics method;Monte Carlo methods;pharmaceutical technology;physics-based visual characterization;molecular interaction forces;molecular simulations;biotechnology;enzyme engineering;automatic computational protocols;human comprehension;visualization algorithms;intermolecular contacts;molecular docking;energy functions;interaction forces;molecule-ligand distance;energy function;molecular dynamics;Monte Carlo simulations;time-dependent visualizations;particle resolutions;domain experts;enzyme design process;drug design process;Visualization;Three-dimensional displays;Computational modeling;Two dimensional displays;Proteins;Drugs;Data visualization;Molecular visualization;binding analysis},
doi={10.1109/TVCG.2016.2598825},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{6502550,
author={G. {Ghidini} and S. K. {Das} and V. {Gupta}},
booktitle={2012 IEEE 9th International Conference on Mobile Ad-Hoc and Sensor Systems (MASS 2012)},
title={Fuseviz: A framework for web-based data fusion and visualization in smart environments},
year={2012},
volume={},
number={},
pages={468-472},
abstract={Recent advances in technology and algorithms for smart environments have made it possible to collect and store large amounts of data about many aspects of human life and the surrounding environment with limited effort and cost. However, such data become useful to lay users with no background in data analysis only if they are presented in a fashion that supports intuitive interaction to spot the patterns and trends, thus transforming the data into valuable information. In this paper, we introduce FuseViz, a framework for Web-based fusion and visualization of data in smart environments. FuseViz addresses the challenges posed by large, live, heterogeneous, and dynamic data streams from autonomous data sources, and lay users, with two basic features: fusion and visualization. CouchDB, a schemaless database with a ReSTful API and MapReduce support, is used to fuse data streams from multiple sources, while Web-based visualization is implemented on top of D3, a JavaScript library for manipulation of data-driven documents. We demonstrate the capabilities of FuseViz with E2Home, a case study application for energy-efficient smart home environments. We show how the precise information provided by E2Home can help the user easily improve the home energy efficiency by more than 10%.},
keywords={application program interfaces;data visualisation;database management systems;home computing;Internet;Java;sensor fusion;FuseViz;Web-based data fusion;data visualization;smart environments;human life;dynamic data streams;autonomous data sources;CouchDB;schemaless database;ReSTful API;MapReduce support;JavaScript library;data-driven documents;energy-efficient smart home environments;E2Home;home energy efficiency;data visualization;data fusion;smart environments;MapReduce;CouchDB;D3},
doi={10.1109/MASS.2012.6502550},
ISSN={2155-6814},
month={Oct},}
@ARTICLE{9117084,
author={A. {Bares} and D. F. {Keefe} and F. {Samsel}},
journal={IEEE Computer Graphics and Applications},
title={Close Reading for Visualization Evaluation},
year={2020},
volume={40},
number={4},
pages={84-95},
abstract={Visualizations produced by collaborations between artists, scientists, and visualization experts lay claim to being not only more effective in delivering information but also more effective in their abilities to elicit qualities like human connection. However, as prior work in the visualization community has demonstrated, it is difficult to evaluate these claims because characteristics associated with human connection are not easily measured quantitatively. In this Visualization Viewpoints piece, we address this problem in the context of our work to develop methods of evaluating visualizations created by Sculpting Visualization, a multidisciplinary project that incorporates art and design theory and practice into the process of scientific visualization. We present the design and results of a study in which we used close reading, a formal methodology used by humanities scholars, as a way to test reactions and analyses from evaluation participants related to an image created using Sculpting Visualization. In addition to specific suggestions about how to improve future iterations of the visualization, we discuss key findings of the evaluation related to contextual information, visual perspective, and associations that individual viewers brought to bear on their experience with the visualization.},
keywords={art;data visualisation;Visualization Viewpoints piece;design theory;scientific visualization;humanities scholars;evaluation participants;visualization evaluation;visualization experts;visualization community;sculpting visualization;Visualization;Data visualization;Art;Tools;Vocabulary;Climate change;Task analysis},
doi={10.1109/MCG.2020.2993889},
ISSN={1558-1756},
month={July},}
@ARTICLE{6276243,
author={Y. {Jeon} and J. {Won} and S. {Yoon}},
journal={IEEE Transactions on Biomedical Engineering},
title={Massively Parallel Energy Space Exploration for Uncluttered Visualization of Vascular Structures},
year={2013},
volume={60},
number={1},
pages={240-244},
abstract={Images captured using computed tomography and magnetic resonance angiography are used in the examination of the abdominal aorta and its branches. The examination of all clinically relevant branches simultaneously in a single 2-D image without any misleading overlaps facilitates the diagnosis of vascular abnormalities. This problem is called uncluttered single-image visualization (USIV). We can solve the USIV problem by assigning energy-based scores to visualization candidates and then finding the candidate that optimizes the score; this approach is similar to the manner in which the protein side-chain placement problem has been solved. To obtain near-optimum images, we need to explore the energy space extensively, which is often time consuming. This paper describes a method for exploring the energy space in a massively parallel fashion using graphics processing units. According to our experiments, in which we used 30 images obtained from five patients, the proposed method can reduce the total visualization time substantially. We believe that the proposed method can make a significant contribution to the effective visualization of abdominal vascular structures and precise diagnosis of related abnormalities.},
keywords={biomedical MRI;computerised tomography;data visualisation;medical disorders;medical image processing;proteins;massively parallel energy space exploration;uncluttered visualization;vascular structure;computed tomography;magnetic resonance angiography;abdominal aorta;vascular abnormalities diagnosis;USIV problem;protein side chain placement problem;Graphics processing unit;Optimization;Visualization;Instruction sets;Message systems;Libraries;Measurement;Abdominal aorta;energy-space exploration;GPGPU;parallelization;single-image visualization;Algorithms;Aorta, Abdominal;Aorta, Abdominal;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Angiography;Models, Cardiovascular;Tomography, X-Ray Computed},
doi={10.1109/TBME.2012.2214386},
ISSN={1558-2531},
month={Jan},}
@INPROCEEDINGS{8609816,
author={J. C. {Lorenzana-Gerardo} and J. L. {Díaz-Reséndiz} and E. A. {Rivas-Araiza}},
booktitle={2018 IEEE International Conference on Automation/XXIII Congress of the Chilean Association of Automatic Control (ICA-ACCA)},
title={IoT based robust electrical energy monitoring system with Programmable Logic Controller},
year={2018},
volume={},
number={},
pages={1-6},
abstract={This paper develops an energy monitoring system with IoT integration. The platform used is based in a programmable logic controller (PLC) s7-1200 connected to a distributed power monitoring module through profinet interface. PLC is a robust and reliable solution for distributed power monitoring and enables IoT integration by using the embedded webserver functionality. In Spite of their excellent webserver capabilities, data management and human to machine interface (HMI) are limited. For this reason, a single board computer (SBC) is used in order to enhance their capabilities, providing data base management and improved data visualization. In this work, the practical aspects of both hardware and software are discussed. Results obtained by the platform are compared with a power quality analyzer.},
keywords={computerised monitoring;data acquisition;data visualisation;database management systems;file servers;Internet;Internet of Things;man-machine systems;microcomputers;power engineering computing;power supply quality;programmable controllers;IoT integration;data management;machine interface;data base management;data visualization;power quality analyzer;robust electrical energy monitoring system;programmable logic controller;profinet interface;embedded webserver;distributed power monitoring;human-to-machine interface;HMI;single board computer;Monitoring;Biomedical monitoring;Artificial intelligence;Meters;Software;Portals;Manuals;PLC;Intelligent Building;Energy Monitoring System;SCADA},
doi={10.1109/ICA-ACCA.2018.8609816},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8430362,
author={A. {Leoni} and V. {Stornelli} and G. {Ferri} and V. {Errico} and M. {Ricci} and A. {Pallotti} and G. {Saggio}},
booktitle={2018 14th Conference on Ph.D. Research in Microelectronics and Electronics (PRIME)},
title={A human body powered sensory glove system based on multisource energy harvester},
year={2018},
volume={},
number={},
pages={113-116},
abstract={In this work we present and evaluate a multi-source power management system, based on human body energy harvesting, to extend the battery lasting of an electronic sensory glove, used to measure flexion/extension, abduction/adduction movements of fingers of the hand. The system exploits heat of the human forearm and pressure impressed by the foot heel during walking, so to gather additional energy. The aim is to allow hours of energy-autonomy for the user working with the sensory glove. Such a glove is equipped with a number of flex sensors which furnish data from finger movements, acquired and pre-processed by a microcontroller, and wireless sent to a Personal Computer for analysis, visualization and storage purposes. The multi-source harvester is based on vibrational and thermic sources. Prototype discrete element boards were designed and tested for the microelectronics integration. Measurement results demonstrate how the overall system extends the battery lasting time up to 20%.},
keywords={body sensor networks;data gloves;energy harvesting;power engineering computing;human body powered sensory glove system;battery lasting time;thermic sources;vibrational sources;multisource harvester;visualization;finger movements;foot heel;human forearm;flexion/extension;electronic sensory glove;human body energy harvesting;multisource power management system;multisource energy harvester;Energy harvesting;power management;Sensory glove},
doi={10.1109/PRIME.2018.8430362},
ISSN={},
month={July},}
@INPROCEEDINGS{8390171,
author={P. {Grandhe} and S. R. {Edara} and V. {Devara}},
booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)},
title={Adaptive ROI search for 3D visualization of MRI medical images},
year={2017},
volume={},
number={},
pages={3785-3788},
abstract={To smooth the progress of high point study of medical image data in research and in clinical medical environment, a covering for the 3D toolkit is developed to overcome the drawback of searching mechanism in medical images. The main aim of this application is to develop a scalable search engine for the three dimensional medical images. User can choose a Region of Interest (ROI) and repeatedly detect the equivalent region among all the return images. Magnetic resonance imaging (MRI) is an extremely developed medical imaging method used to extract information about the human soft tissue structure. So we propose a new algorithm, namely Cluster Based Image Search and Retrieve-CBISR is randomly reduce searching time and provide accuracy result for MRI Images.},
keywords={biological tissues;biomedical MRI;data visualisation;image retrieval;image segmentation;medical image processing;search engines;stereo image processing;adaptive ROI search;MRI medical images;medical image data;clinical medical environment;magnetic resonance imaging;MRI Images;search engine;three dimensional medical images;3D visualization;cluster based image search;retrieve-CBISR;region of interest;3D toolkit;Magnetic resonance imaging;Biomedical imaging;Three-dimensional displays;Tumors;Data analysis;Image segmentation;Clustering algorithms;Cluster Based Image Search and Retrieve (CBISR);Medical Imaging;Image retrieval;Region of Interest (ROI)},
doi={10.1109/ICECDS.2017.8390171},
ISSN={},
month={Aug},}
@ARTICLE{7153545,
author={T. J. {Tsai} and A. {Stolcke} and M. {Slaney}},
journal={IEEE Transactions on Multimedia},
title={A Study of Multimodal Addressee Detection in Human-Human-Computer Interaction},
year={2015},
volume={17},
number={9},
pages={1550-1561},
abstract={The goal of addressee detection is to answer the question , “Are you talking to me?” When a dialogue system interacts with multiple users, it is crucial to detect when a user is speaking to the system as opposed to another person. We study this problem in a multimodal scenario, using lexical, acoustic, visual, dialogue state, and beamforming information. Using data from a multiparty dialogue system, we quantify the benefits of using multiple modalities over using a single modality. We also assess the relative importance of the various modalities, as well as of key individual features, in estimating the addressee. We find that energy-based acoustic features are by far the most important, that information from speech recognition and system state is useful as well, and that visual and beamforming features provide little additional benefit. While we find that head pose is affected by whom the speaker is addressing, it yields little nonredundant information due to the system acting as a situational attractor. Our findings would be relevant to multiparty, open-world dialogue systems in which the agent plays an active, conversational role, such as an interactive assistant deployed in a public, open space. For these scenarios , our study suggests that acoustic, lexical, and system-state information is an effective and practical combination of modalities to use for addressee detection. We also consider how our analyses might be affected by the ongoing development of more realistic, natural dialogue systems.},
keywords={array signal processing;audio user interfaces;human computer interaction;interactive systems;speaker recognition;multimodal addressee detection;human-human-computer interaction;multimodal scenario;lexical state;acoustic state;visual state;dialogue state;beamforming information;multiple modalities;energy-based acoustic features;speech recognition;visual features;beamforming features;head pose;multiparty open-world dialogue systems;active conversational role;interactive assistant;Computers;Face;Speech;Computational modeling;Feature extraction;Acoustics;Visualization;Addressee detection;beamforming;dialogue system;head pose;human-human-computer;multimodal;multiparty;prosody;speech recognition},
doi={10.1109/TMM.2015.2454332},
ISSN={1941-0077},
month={Sep.},}
@INPROCEEDINGS{8397404,
author={E. {Dubois} and F. {Pittarello}},
booktitle={2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)},
title={Designing the engaging energy-box: Bridging the gap between energy control systems and users' energy awareness},
year={2017},
volume={},
number={},
pages={1-6},
abstract={This work describes a design experience focused on the theme of eco-feedback, a technology complementary to traditional energy control systems and meant to obtain additional savings by increasing the awareness of the users about the factors that determine energy consumption. This experience, held during a multidisciplinary ideation workshop and involving students and researchers at the University of Toulouse, was focused on the conceptual design of an Energy-Box, conceived as an artefact (or a set of artefacts) for making people inhabiting the University campus aware of energy issues and leading them to more energy conscious lifestyles. Three different proposals stemmed from this experience, that were evaluated first by the participants to the workshop themselves and then, some months later, by 80 undergraduate students of the University of Venice working on the same themes. We extracted interesting lesson learned from this evaluation, that should be taken into account for the development of user's centred eco-feedback systems in public contexts.},
keywords={educational administrative data processing;energy conservation;energy consumption;human factors;user centred design;engaging energy-box;design experience;traditional energy control systems;energy consumption;multidisciplinary ideation workshop;University campus aware;energy conscious lifestyles;undergraduate students;user centred eco-feedback system;University of Venice;Energy consumption;Prototypes;Control systems;Monitoring;Buildings;Data visualization;Proposals;control system;eco-feedback;prototyping;sketching},
doi={10.1109/UIC-ATC.2017.8397404},
ISSN={},
month={Aug},}
@ARTICLE{8624523,
author={J. {Cai} and W. {Hao} and W. {Chen} and Y. {Guo} and S. {Tang} and R. {Wen} and L. {Pan} and J. {Fan}},
journal={IEEE Access},
title={The Effect of Light Distribution of LED Luminaire on Human Ocular Physiological Characteristics},
year={2019},
volume={7},
number={},
pages={28478-28486},
abstract={Light-emitting Diode (LED) has been considered as one of the new generation lighting sources with several merits such as high efficiency, high reliability, long lifespan, high-speed response, and energy saving. The optical performances of an LED luminaire, such as illuminance, luminance, correlated color temperature, and spectra power distribution, determine the lighting environment which can affect the human ocular physiological characteristics. To investigate the effect of optical performances on human vision, previous studies have assessed the subjective perception based on questionnaires. In this paper, we propose a novel method based on the aberrations and accommodations data from 150 human factor measurements on a total of 25 participants. The results show that: 1) optical performances of the LED luminaire have an influence on ocular physiological characteristics during the visual task duration, which can be quantized by the variations of physiological parameters; 2) the desk illuminance and light distribution curve are selected in this study as the optical parameters. The variations of ocular physiological characteristics reach the minimum values when the desk illuminance is 550 lux and the light distribution curve is large beam angle; and 3) ocular physiological characteristics are more sensitive to the light spatial distribution compared to the light quality. Thus, the proposed assessment method based on variations of ocular physiological characteristics in this paper is promising as one of the guidelines for the design and optimization of the LED luminaires.},
keywords={human factors;light emitting diodes;light sources;vision;optical performances;LED luminaire;spectra power distribution;lighting environment;human ocular physiological characteristics;human vision;physiological parameters;desk illuminance;light distribution curve;optical parameters;light spatial distribution;light quality;lighting sources;light-emitting diode;human factor measurements;correlated color temperature;Lighting;Physiology;Visualization;Atmospheric measurements;Particle measurements;Fatigue;Light emitting diodes;LED luminaire;optical performance;human vision;ocular physiological characteristics;lighting environment assessment},
doi={10.1109/ACCESS.2019.2893914},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7313335,
author={N. {Petrovska} and A. {Stevanovic}},
booktitle={2015 IEEE 18th International Conference on Intelligent Transportation Systems},
title={Traffic Congestion Analysis Visualisation Tool},
year={2015},
volume={},
number={},
pages={1489-1494},
abstract={The rapid growth of urban population and numbers of private cars in this modern era, results in increasingly urgent transportation problem in cities throughout the world. Road traffic congestion is an omnipresent problem, which leads to delays, time loss, human stress, energy consumption, environmental pollution e.c.t. In order to decrease traffic congestion, there is a need for simulating and optimizing traffic control and improving traffic management. There are different ways for traffic congestion monitoring and analysis such as using video monitoring and surveillance systems, or static and dynamic sensors which allow traffic management in real time. There are also other methods using non real time analysis where traf?c congestion can be extracted from historical patterns of traf?c congestion. The historical patterns can be gained from the stored travel time and speed data. The goal of enhancing driver convenience is achieved by providing applications based on road traffic condition that mainly identifies congestion status. This paper presents a web application which uses live traffic congestion data from Google Maps traffic layer for real time congestion calculation. A technique utilized for estimating the level of congestion is image processing. The main objective is to provide an automated and yet interactive visualization tool for congestion analysis in real time. The aim is reducing the traffic congestion on roads which will lead to decrease in the number of accidents. It can provide important data which can help road traffic management. Thus, it is mainly dedicated to traffic managers, operators and analysts. Nevertheless it can be implemented also by road users. Unlike most sensor based applications, it makes quantified congestion data available even in regions with limited traffic data information.},
keywords={data visualisation;delays;energy consumption;geographic information systems;interactive systems;pollution control;real-time systems;road traffic control;traffic congestion analysis visualisation tool;urban population;private cars;urgent transportation problem;road traffic congestion;delays;time loss;human stress;energy consumption;environmental pollution;traffic control;historical patterns;Google Maps traffic layer;real time congestion calculation;interactive visualization tool;road traffic management;Roads;Google;Data visualization;Real-time systems;Vehicles;Sensors;Image color analysis;Road Traffic Congestion;Google Maps Traffic Layer;Visualization;Image Processing},
doi={10.1109/ITSC.2015.243},
ISSN={2153-0017},
month={Sep.},}
@INPROCEEDINGS{8938274,
author={V. {Rao} and M. {Singh} and P. {Mohapatra}},
booktitle={2019 IEEE 1st International Conference on Energy, Systems and Information Processing (ICESIP)},
title={SmartAIR: Smart energy efficient framework for large network of air quality monitoring systems},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Live street-level air quality monitoring is important application of sensor networks. Such application reveals human exposure to hazardous air pollutants. It assists general public, army troops, environment agencies and the Government in decision-making every day. Live data visualization and data fusion plays crucial role in presenting pollution updates effectively for end-users. We propose efficient interactive, live data visualization in our application. Our application efficiently renders pollution data fast in under 10ms. Users will be instantly aware of pollution levels in their desired location. Continuous data-logging at data centers from large-scale of sensor networks poses major challenges. We use policy based network management technique to reduce unwanted data-logging requests. We implement novel policies in identifying and rejecting numerous unwanted requests at data centers. Each data-logging involves computationally expensive database operations and with our policy specification we were able to cut down expensive operations significantly ( ≥ 83% reduction, especially in denser regions like traffic congested roads). Finally, we implement Lazy load scheme to make our application more energy efficient. With this scheme we save data and battery in end-users device over longer periods of time. We conducted several real-life trials and we observed negligible mobile data consumption ( ≤ 1MB for 1 - hour). Similarly, we observed negligible power consumption ( ≤ 4 % in 1- hour run) in end-users device. Our implementation of novel policies and schemes provide real-life benefits to data centers and end-users. Our end-users experience better, faster and lively pollution updates. Our data centers experience relatively lesser network load and less computation overheads on scaling up.},
keywords={air pollution control;computer centres;data visualisation;energy conservation;environmental monitoring (geophysics);environmental science computing;power consumption;road traffic;sensor fusion;telecommunication network management;telecommunication power management;wireless sensor networks;smart energy efficient framework;air quality monitoring systems;live street-level air quality monitoring;sensor networks;hazardous air pollutants;data fusion;efficient interactive data visualization;live data visualization;pollution data;pollution levels;continuous data-logging;data centers;policy based network management technique;unwanted data-logging requests;battery;end-users device;negligible mobile data consumption;lively pollution updates;relatively lesser network load;time 10.0 ms;memory size 1.0 MByte;Data visualization;Monitoring;Databases;Air pollution;Servers;Google;Sensor Networks;Large scale;Lazy load},
doi={10.1109/ICESIP46348.2019.8938274},
ISSN={},
month={July},}
@INPROCEEDINGS{6557837,
author={M. J. {Stokmaier} and A. G. {Class} and T. {Schulenberg}},
booktitle={2013 IEEE Congress on Evolutionary Computation},
title={A hard optimisation test function with symbolic solution visualisation for fast interpretation by the human eye},
year={2013},
volume={},
number={},
pages={2251-2258},
abstract={We propose a class of test problems for evaluating the performance of global function optimisers based on finding an optimal spatial distribution of nonidentical particles interacting with two different potential fields. Because of the possibility of intuitive solution visualisation it can be of particular benefit during development of optimisation algorithms. An ensemble of N particles is constrained to a low-dimensional space and each particle contributes in two ways to the total potential energy: by its position on a hilly track and through repulsive neighbour potentials. The task of minimising the ensemble's total potential energy corresponds to searching an N-dimensional space with many local minima separated through higher and lower barriers; hence, it can serve as a performance measure for evolutionary algorithms (EA). The search difficulty is scalable through the number of particles and the hilliness of the track. In particular, if the particles are made nonidentical by giving them different masses or charges, the search will become very challenging because of the introduced combinatorial aspect and the “curse of dimensionality”. Among many similarly challenging optimisation problems this test function class has the advantage that solution candidates can be plotted in ways which allow humans to estimate not only relative objective function values but also DNA vector relations upon a quick glance. For the EA developer this allows a fast feedback cycle between a modification to the EA and the observed change in optimisation history behaviour. This makes experimentation with EA elements at a fundamental level easier. Furthermore, this class of real-domain search offers a wide range of difficulty and complexity levels and can be split up into a two-objective optimisation.},
keywords={data visualisation;evolutionary computation;minimisation;search problems;hard optimisation test function;symbolic solution visualisation;fast interpretation;human eye;performance evaluation;global function optimisers;optimal spatial distribution;spatial nonidentical particle distribution;potential fields;optimisation algorithms;low-dimensional space;ensemble total potential energy minimisation;N-dimensional space search;local minima;performance measure;evolutionary algorithms;curse of dimensionality;fast feedback cycle;DNA vector relations;EA modification;real-domain search;two-objective optimisation;Optimization;Visualization;DNA;Linear programming;Vectors;Search problems;Lenses},
doi={10.1109/CEC.2013.6557837},
ISSN={1941-0026},
month={June},}
@INPROCEEDINGS{8711230,
author={T. {Luo} and K. {Chen} and M. {Liu} and K. {Sun} and J. {Xu} and Z. {Pan}},
booktitle={2018 International Conference on Virtual Reality and Visualization (ICVRV)},
title={Design and Implementation of Interactive VR Campus Roaming System},
year={2018},
volume={},
number={},
pages={122-123},
abstract={Virtual reality technology can be widely used in all aspects of virtual, and there are multiple successful cases. Jinan University was used as a research object in this project. The customers' natural requirements of spatial authenticity were analyzed in term of the natural guidance theory model, safety, comfort, motivation, and interaction efficiency in the VR campus experience. The Unity3D platform and the latest natural human-computer interaction technology were employed during the creation. By using the HTC Vive helmets and handles, we can collect human body data and scene motion data to drive virtual roaming actions, which can manipulate human motion behavior and allow virtual players to roam across land, water, and air, pick up rubbish to increase campus environmental protection values, make shots, play football, swim, and fight against negative campus energy with weapons. Tests have shown that the system is easy to use and widely praised by users.},
keywords={human computer interaction;solid modelling;virtual reality;human body data;scene motion data;virtual roaming actions;human motion behavior;virtual players;campus environmental protection values;negative campus energy;interactive VR campus roaming system;virtual reality technology;multiple successful cases;Jinan University;customers;spatial authenticity;natural guidance theory model;interaction efficiency;VR campus experience;Unity3D platform;natural human-computer interaction technology;Virtual reality;Visualization;virtual reality;real-time roaming;texture mapping;natural orientation;somatosensory interaction},
doi={10.1109/ICVRV.2018.00036},
ISSN={2375-141X},
month={Oct},}
@INPROCEEDINGS{7299363,
author={R. {Richer} and T. {Maiwald} and C. {Pasluosta} and B. {Hensel} and B. M. {Eskofier}},
booktitle={2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN)},
title={Novel human computer interaction principles for cardiac feedback using google glass and Android wear},
year={2015},
volume={},
number={},
pages={1-6},
abstract={This work presents a system for unobtrusive cardiac feedback in daily life. It addresses the whole pipeline from data acquisition over data processing to data visualization including wearable integration. ECG signals are recorded with a novel ECG sensor supporting Bluetooth Low Energy, which is able to transmit raw ECG data as well as estimated heart rate. ECG signals are processed in real-time on a mobile device to automatically classify the user's heart beats. A novel application for Android-based mobile devices was developed for data visualization. It offers several modes for cardiac feedback, from measuring the current heart rate to continuously monitoring the user's heart status. It also allows to store acquired data in an internal database as well as in the Google Fit platform. Further, the application provides extensions for wearables like Google Glass and smartwatches running on Android Wear. Hardware performance evaluation was performed by comparing the course of heart rate between the novel ECG sensor and a commercial ECG sensor. The mean absolute error between the two sensors was 4.83 bpm with a standard deviation of 4.46 bpm, and a Pearson correlation of 0.922. A qualitative evaluation was performed for the Android application with special emphasis on the daily usability and the wearable integration. When the Google Glass was integrated, the subjects rated the application as 2.8/5 (0 = Bad, 5 = Excellent), whereas when the application was integrated with a smartwatch the rating increased to 4.2/5.},
keywords={bioelectric potentials;Bluetooth;body sensor networks;data acquisition;data visualisation;electrocardiography;human computer interaction;medical signal detection;medical signal processing;signal classification;smart phones;statistical analysis;telemedicine;Pearson correlation;ECG sensor;hardware performance evaluation;smartwatches;Android-based mobile devices;automatic heart beat classification;real-time ECG signal processing;heart rate estimation;Bluetooth;wearable integration;data visualization;data processing;data acquisition;unobtrusive cardiac feedback;Android wear;Google glass;human computer interaction principles;Google;Electrocardiography;Glass;Biomedical monitoring;Androids;Humanoid robots;Heart rate;Body Sensor Networks;Electrocardiography;Wearable Computing;Android Application;Human Computer Interaction},
doi={10.1109/BSN.2015.7299363},
ISSN={2376-8894},
month={June},}
@INPROCEEDINGS{6981650,
author={T. {Sugiura} and S. {Nakatsuka} and J. {Yu} and Y. {Takeuchi} and M. {Imai}},
booktitle={2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings},
title={An efficient data compression method for artificial vision systems and its low energy implementation using ASIP technology},
year={2014},
volume={},
number={},
pages={81-84},
abstract={This paper proposes an efficient data compression method for artificial vision systems based on visual cortex stimulation. These systems require wireless communication between inside and outside of human body, which consumes large amount of energy for data transmission. In order to reduce the energy consumption, efficient and less power consuming data compression method is required. The proposed method takes advantage of the appearance frequency of stimulation data pattern. Experimental results show that the proposed compression method achieves more than 81% of data compression rate, and energy reduction ratios by an application specific instruction-set processor implementation is 85% in compression and 36% in decompression compared to its base processor, respectively.},
keywords={biomedical communication;computer vision;data compression;energy consumption;neurophysiology;ASIP technology;efficient data compression method;artificial vision systems;visual cortex stimulation;wireless communication;human body;data transmission;energy consumption;power consuming data compression method;data pattern;energy reduction ratios;specific instruction-set processor;Visualization;Data compression;Machine vision;Encoding;Registers;Energy consumption;Retina},
doi={10.1109/BioCAS.2014.6981650},
ISSN={2163-4025},
month={Oct},}
@INPROCEEDINGS{8227573,
author={C. {Snyder} and J. B. {Christen} and H. M. {Ross}},
booktitle={2017 IEEE Healthcare Innovations and Point of Care Technologies (HI-POCT)},
title={Human factors engineering for mobile health applications},
year={2017},
volume={},
number={},
pages={14-17},
abstract={Childhood asthma has effectively doubled since 1980 and currently affects about 8% of the U.S. childhood population. Efficiently analyzing quality of air data, which would ultimately improve the information available to parents with children suffering from asthma, is crucial to reduce the likelihood of a serious attack. In order to accomplish this task, the use of low-cost, wearable, environmental sensors contribute to construct a live “air-care” pollution map. Creating an alpha prototype application to gauge how well participants interact with and interpret healthcare information utilizing a “Wizard of Oz” paradigm becomes an important component in the research.},
keywords={air pollution;data analysis;diseases;health care;human factors;medical information systems;mobile computing;paediatrics;human factors engineering;mobile health applications;childhood asthma;childhood population;wearable sensors;environmental sensors;live air-care pollution map;alpha prototype application;healthcare information;air quality data analysis;Wizard of Oz paradigm;Respiratory system;Pediatrics;Gases;Sensors;Visualization;Image color analysis;Prototypes},
doi={10.1109/HIC.2017.8227573},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8699216,
author={P. {Knierim} and F. {Kiss} and A. {Schmidt}},
booktitle={2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
title={Look Inside: Understanding Thermal Flux Through Augmented Reality},
year={2018},
volume={},
number={},
pages={170-171},
abstract={The transition from high school to university is an exciting time for students including many new challenges. Particularly in the field of science, technology, engineering, and mathematics, the university dropout rate may reach up to 40%. The studies of physics rely on many abstract concepts and quantities that are not directly visible like energy or heat. We developed a mixed reality application for education, which augments the thermal conduction of metal by overlaying a representation of temperature as false-color visualization directly onto the object. This real-time augmentation avoids attention split and overcomes the perception gap by amplifying the human eye. Augmented and Virtual Reality environments allow students to perform experiments that were impossible to conduct for security or financial reasons. With the application, we try to foster a deeper understanding of the learning material and higher engagement during the studies.},
keywords={augmented reality;computer aided instruction;data visualisation;engineering education;physics computing;thermal flux;high school;university dropout rate;mixed reality application;false-color visualization;real-time augmentation;attention split;perception gap;augmented reality environment;virtual reality environment;science technology engineering mathematics field;learning material;Augmented reality;Data visualization;Physics;Prototypes;Heating systems;Real-time systems;H.5.m [Information Interfaces and Presentation]: Miscellaneous},
doi={10.1109/ISMAR-Adjunct.2018.00059},
ISSN={},
month={Oct},}
@ARTICLE{7536106,
author={A. {Dasgupta} and J. {Lee} and R. {Wilson} and R. A. {Lafrance} and N. {Cramer} and K. {Cook} and S. {Payne}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Familiarity Vs Trust: A Comparative Study of Domain Scientists' Trust in Visual Analytics and Conventional Analysis Methods},
year={2017},
volume={23},
number={1},
pages={271-280},
abstract={Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.},
keywords={data analysis;data mining;data visualisation;statistics;trusted computing;domain scientist trust;visual analytics;conventional analysis;interactive visualization;statistics;data mining;data-driven discovery;mixed-initiative systems;evidence gathering;decision-making;transparent analysis process;trust-augmented design;Visual analytics;Data visualization;Biology;Uncertainty;Data analysis;Bioinformatics;trust;transparency;familiarity;uncertainty;biological data analysis},
doi={10.1109/TVCG.2016.2598544},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{8390704,
author={C. {Lu}},
journal={IEEE Transactions on Human-Machine Systems},
title={IoT-Enabled Adaptive Context-Aware and Playful Cyber-Physical System for Everyday Energy Savings},
year={2018},
volume={48},
number={4},
pages={380-391},
abstract={Home energy savings via eco-feedback is often considered a serious, tedious, or even distracting task due to the need for frequent human intervention. In addition, most existing eco-feedback systems focus on providing energy usage information and ignore the users' contexts. This may render the systems incapable of capturing the users' changes when proenvironmental behaviors have been encouraged. To address this, our study leverages Internet of Things (IoT) enabled technologies to realize an adaptive, context-aware, and playful cyber-physical system (CPS) for everyday energy savings with the hope of facilitating collaboration between a person and a smart energy-saving (ES) system to the greatest extent possible. To leverage the benefits inherent in a CPS, bidirectionally interactive information visualization integrated with pet-raising gamification was incorporated into the adaptive CPS. This synchronized the information from the user's physical environment with its counterpart in the pet's virtual environment. In order to provide flexible services, all IoT devices were agentized to form reconfigurable agents. In our experimental evaluation, this bidirectional mapping empowered users to flexibly control remote appliances anywhere and anytime in a more natural way, which enabled users to embed interactions with the ES CPS into their daily routine. Furthermore, improvements to system adaptability (33% in precision; 21% in recall) along with the reconfigurable ES services (additionally saving energy about 16.21%) show the potential of the CPS to enhance the users' experience and prolong the users' engagement in everyday energy savings.},
keywords={behavioural sciences computing;computer games;data visualisation;domestic appliances;home automation;Internet;Internet of Things;home energy savings;energy usage information;smart energy-saving system;bidirectionally interactive information visualization;adaptive CPS;ES CPS;system adaptability;IoT-enabled adaptive context-aware;cyber-physical system;Internet of Things enabled technologies;flexibly control remote appliances;user experience;user engagement;pet-raising gamification;Sensors;Internet of Things;Adaptive systems;Cyber-physical systems;Visualization;Biological system modeling;Actuators;Adaptation;context-awareness;cyber-physical system (CPS);energy savings;gamification-based eco-automation (mixed reality);Internet of Things (IoT)},
doi={10.1109/THMS.2018.2844119},
ISSN={2168-2305},
month={Aug},}
@ARTICLE{8369345,
author={J. {Sreevalsan-Nair} and A. {Jindal} and B. {Kumari}},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={Contour Extraction in Buildings in Airborne LiDAR Point Clouds Using Multiscale Local Geometric Descriptors and Visual Analytics},
year={2018},
volume={11},
number={7},
pages={2320-2335},
abstract={Topographic Light Detection and Ranging (LiDAR) captures geometric information of the topography of a geographical region, often using airborne platforms. The research and practice of analysis of point clouds acquired using LiDAR is more recent in comparison to that of LiDAR imagery. Point clouds are unstructured datasets, where its geometric or structural classification labels the constituent points as belonging to line-, surface-, or point-type features. We focus on line-type features in the LiDAR point clouds of urban residential areas, which enables extraction of building outlines. We use a multiscale local geometric descriptor (LGD), computed using tensor voting and gradient energy tensor to enhance specific line-type features, e.g., gable roofs. Given that LGDs are positive-semidefinite second-order tensors, we propose a tensor-based data analytic workflow for extraction of boundaries in building roofs using the LGD. We use the tensor representation of the LGD to extract “tensorlines,” which are then postprocessed for extracting feature lines of the building roofs. Our proposed workflow provides the flexibility to the human-in-the-loop for exploration of point clouds for roof boundary tracing for selected buildings. We demonstrate the workflow for a two-plane gable roof.},
keywords={airborne radar;data visualisation;feature extraction;geophysical image processing;optical radar;topography (Earth);geometric information;topographic light detection and ranging;LiDAR imagery;airborne platforms;airborne LiDAR point clouds;contour extraction;feature lines;building roofs;tensor-based data analytic workflow;specific line-type features;gradient energy tensor;tensor voting;LGD;multiscale local geometric descriptor;building outlines;point-type features;structural classification;geometric classification;Three-dimensional displays;Laser radar;Feature extraction;Buildings;Tensile stress;Data visualization;Data mining;Contour extraction;gradient energy tensor;LiDAR point clouds;structure tensor;tensor voting;tensorlines},
doi={10.1109/JSTARS.2018.2833801},
ISSN={2151-1535},
month={July},}
@INPROCEEDINGS{5937383,
author={E. {Noyes} and L. {Deligiannidis}},
booktitle={2011 4th International Conference on Human System Interactions, HSI 2011},
title={Emergent: A knowledge discovery tool for understanding emerging industry structure},
year={2011},
volume={},
number={},
pages={305-310},
abstract={This paper presents a visual analytics tool to understand the emergence and structure of the nanotechnology industry. According to the U.S. National Science Foundation (NSF), the global nanotechnology industry is expected to grow to $1 trillion in 2010 and drive dramatic innovation and wealth creation in industries as diverse as energy, computing and biotechnology. Nanotech entrepreneurs, analysts and investors alike need tools to understand the emerging structure of the industry because firm competitive positions in the industry impact ventures' survival, growth and profitability. Particularly, nanotech ventures compete from different initial “strategic footprints” in the industry which ease or complicate entry into new growth businesses. In fact, the emergence of the nanotechnology industry is the story of interweaving with-and penetration into-different adjoining industries. Exploiting the world's largest database on consumer-focused nanotechnology products, this paper demonstrates a visual analytics tool, Emergent, that can show the emerging structure of the industry and ventures' varying strategic footprints within this forming multi-industry terrain. The tool is interactive, scalable, and adaptable to relational data from other industries. Business applications of Emergent include industry analysis, strategic planning and entrepreneurial opportunity identification.},
keywords={data mining;data visualisation;nanotechnology;strategic planning;knowledge discovery tool;emerging industry structure understanding;visual analytics tool;nanotechnology industry;strategic footprints;Emergent;strategic planning;entrepreneurial opportunity identification;Industries;Nanotechnology;Commercialization;Business;Visualization;Automotive engineering;Data visualization;information visualization;network visualization;visual analytics;entrepreneurship;industry evolution;innovation},
doi={10.1109/HSI.2011.5937383},
ISSN={2158-2254},
month={May},}
@INPROCEEDINGS{6307688,
author={X. {Zhang} and Q. {Zhu} and Z. {Zhang} and Z. {Zhu}},
booktitle={2012 Asia-Pacific Power and Energy Engineering Conference},
title={Study on the Coordinated Multi-View Technology of EMS},
year={2012},
volume={},
number={},
pages={1-4},
abstract={Multi-view technology, especially multi-screen display is widely used in Human-Computer Interface (HCI) of Energy Management System (EMS). This paper analyzes the necessity of multi-view in EMS through the presentation method and the functions. On this condition, the typical coordination patterns of multi-view in EMS are introduced. Moreover, the coordination pattern of the correlated multi-screen display and the coordinated multi-view is proposed and studied. The coordination pattern is instrumental in improving EMS interactive capabilities. The multi-screen based on adaptive mechanism is also disused.},
keywords={brain-computer interfaces;energy management systems;power engineering computing;screens (display);coordinated multiview technology;EMS;human-computer interface;HCI;energy management system;coordination pattern;adaptive mechanism-based multiscreen display;Collaboration;Energy management;Human computer interaction;Data visualization;Power systems;Monitoring;Visualization},
doi={10.1109/APPEEC.2012.6307688},
ISSN={2157-4847},
month={March},}
@INPROCEEDINGS{7273415,
author={P. {Khawsa-Ard} and C. {Aswakul}},
booktitle={2015 IEEE 39th Annual Computer Software and Applications Conference},
title={IEEE1888 Interactive Display as a Service (IDaaS): Example in Building Energy Management System},
year={2015},
volume={3},
number={},
pages={517-522},
abstract={In this paper, a new architecture of Interactive Display as a Service or IDaaS has been introduced and implemented as the application component in the open framework of IEEE1888 standard. The purpose is to integrate the interactive visualisation with natural human gesture controls and the back-end cloud enabled by the IEEE1888 data storage component and IEEE1888 FETCH/WRITE methods. The IDaaS architecture utilises Processing language as the interactive visualisation software platform and Microsoft Kinect as the gesture sensor. Measures of IDaaS effectiveness have been defined, namely, the number of hand swipes made by control users, the canvas numbers selected by control users, and the accumulated number of users waking up the IDaaS display. As an example proof of concept, IDaaS system has been deployed for the building energy management system scenario. Five canvases have been developed for the IDaaS display, namely, EE health pad, energy game, EE information and alarm & alert as well as a photo collection display implemented as a screen saver. Reported results herein highlight possible usage of IDaaS effectiveness measures to compare installation locations and displaying canvases quantitatively. And hence IDaaS is expectedly useful for interactive public data dissemination hot spots to raise people awareness on common issues of societal concern or for information advertising purposes.},
keywords={building management systems;cloud computing;data visualisation;display devices;gesture recognition;image segmentation;information dissemination;interactive systems;IEEE1888 interactive display as a service;building energy management system;application component;natural human gesture controls;back-end cloud;IEEE1888 data storage component;IEEE1888 FETCH-WRITE methods;processing language;interactive visualisation software platform;Microsoft Kinect;gesture sensor;IDaaS display;EE health pad;energy game;EE information;photo collection display;screen saver;installation locations;displaying canvases;interactive public data dissemination hot spots;people awareness;societal concern;information advertising purposes;Floors;Games;Computer architecture;Data visualization;Standards;Skeleton;Interactive Display as a Service;IEEE1888;building energy management system;gesture sensor},
doi={10.1109/COMPSAC.2015.262},
ISSN={0730-3157},
month={July},}
@ARTICLE{6226392,
author={L. {Zheng} and Y. {Wu} and K. {Ma}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Perceptually-Based Depth-Ordering Enhancement for Direct Volume Rendering},
year={2013},
volume={19},
number={3},
pages={446-459},
abstract={Visualizing complex volume data usually renders selected parts of the volume semitransparently to see inner structures of the volume or provide a context. This presents a challenge for volume rendering methods to produce images with unambiguous depth-ordering perception. Existing methods use visual cues such as halos and shadows to enhance depth perception. Along with other limitations, these methods introduce redundant information and require additional overhead. This paper presents a new approach to enhancing depth-ordering perception of volume rendered images without using additional visual cues. We set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception as well as the faithfulness of the information revealed. Guided by the function, we use a conjugate gradient method to iteratively and judiciously enhance the results. Our method can complement existing systems for enhancing volume rendering results. The experimental results demonstrate the usefulness and effectiveness of our approach.},
keywords={conjugate gradient methods;data visualisation;rendering (computer graphics);perceptually based depth ordering enhancement;direct volume rendering;visualizing complex volume data;energy function;volume rendered images;quantitative perception models;transparency perception;conjugate gradient method;Rendering (computer graphics);Junctions;Image color analysis;Transfer functions;Visualization;Optimization;Solid modeling;Volume rendering;depth ordering;depth perception;transparency;visualization;Algorithms;Computer Graphics;Depth Perception;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;User-Computer Interface},
doi={10.1109/TVCG.2012.144},
ISSN={1941-0506},
month={March},}
@INPROCEEDINGS{7061028,
author={ {Jeungmin Oh} and U. {Lee}},
booktitle={2015 Eighth International Conference on Mobile Computing and Ubiquitous Networking (ICMU)},
title={Exploring UX issues in Quantified Self technologies},
year={2015},
volume={},
number={},
pages={53-59},
abstract={The Quantified Self is a movement that promotes the use of technology for self-tracking various kinds of personal information, such as physical activities and energy consumption. In this paper, we study the user reviews of quantified self tools, as reported on a quantified self community website. We perform a content analysis to categorize tracking tools, and to explore user experience (UX) issues related to quantified self technologies. From this analysis, we find various tracking categories, including body state (e.g., physical and physiological), psychological state and traits, activities (e.g., exercise, eating, sleep), social interactions, and environmental and property states. Furthermore, we find the key UX issues associated with quantified self technologies, which include data controllability, data integration, data accuracy, data visualization, input complexity, sharing/privacy, design/aesthetics, and engagement. The UX issues reported in this paper have significant implications for the design of quantified self technologies.},
keywords={behavioural sciences computing;data integration;data visualisation;human computer interaction;information analysis;mobile computing;wearable computers;Web sites;input complexity;data visualization;data accuracy;data integration;data controllability;Quantified Self community Web site;Quantified Self tool;user experience;UX;Data visualization;Google;Communities;Data integration;Mood;Twitter},
doi={10.1109/ICMU.2015.7061028},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8638195,
author={A. R. {Ajayan} and F. {Al-Doghman} and Z. {Chaczko}},
booktitle={2018 26th International Conference on Systems Engineering (ICSEng)},
title={Visualizing Multimodal Big Data Anomaly Patterns in Higher-Order Feature Spaces},
year={2018},
volume={},
number={},
pages={1-9},
abstract={The world today, as we know it, is profuse with information about humans and objects. Datasets generated by cyber-physical systems are orders of magnitude larger than their current information processing capabilities. Tapping into these big data flows to uncover much deeper perceptions into the functioning, operational logic and smartness levels attainable has been investigated for quite a while. Knowledge Discovery & Representation capabilities across mutiple modalities holds much scope in this direction, with regards to their information holding potential. This paper investigates the applicability of an arithmetic tool Tensor Decompositions and Factorizations in this scenario. Higher order datasets are decomposed for Anomaly Pattern capture which encases intelligence along multiple modes of data flow. Preliminary investigations based on data derived from Smart Grid Smart City Project are compliant with our hypothesis. The results proved that Abnormal patterns detected in decomposed Tensor factors encompass deep information energy content from Big Data as efficiently as other Pattern Extraction and Knowledge Discovery frameworks, while salvaging time and resources.},
keywords={Big Data;cyber-physical systems;data analysis;data mining;data visualisation;feature extraction;knowledge representation;matrix decomposition;tensors;higher-order feature spaces;objects;cyber-physical systems;tensor decompositions;pattern extraction;knowledge discovery;knowledge representation;multimodal Big Data anomaly pattern visualization;anomaly pattern capture;Big Data;Data visualization;Data mining;Market research;Feature extraction;Ecosystems;Multimodality;Big Data Processing;Knowledge Representations;Intelligent systems;Multimodal Big Data;Spatio-Temporal dependencies;Feature annotations.},
doi={10.1109/ICSENG.2018.8638195},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7058084,
author={A. {Ridi} and C. {Gisler} and J. {Hennebert}},
booktitle={2014 International Conference on Data Science and Advanced Analytics (DSAA)},
title={Appliance and state recognition using Hidden Markov Models},
year={2014},
volume={},
number={},
pages={270-276},
abstract={We asset about the analysis of electrical appliance consumption signatures for the identification task. We apply Hidden Markov Models to appliance signatures for the identification of their category and of the most probable sequence of states. The electrical signatures are measured at low frequency (10-1 Hz) and are sourced from a specific database. We follow two predefined protocols for providing comparable results. Recovering information on the actual appliance state permits to potentially adopt energy saving measures, as switching off stand-by appliances or, generally speaking, changing their state. Moreover, in most of the cases appliance states are related to user activities: the user interaction usually involves a transition of the appliance state. Information about the state transition could be useful in Smart Home / Building Systems to reduce energy consumption and increase human comfort.We report the results of the classification tasks in terms of confusion matrices and accuracy rates. Finally, we present our application for a real-time data visualization and the recognition of the appliance category with its actual state.},
keywords={data visualisation;domestic appliances;energy conservation;hidden Markov models;home automation;state recognition;hidden Markov models;appliance recognition;electrical appliance consumption signatures;identification task;electrical signatures;energy saving measures;stand-by appliances;appliance states;user activities;user interaction;smart home-building systems;energy consumption reduction;human comfort;confusion matrices;real-time data visualization;appliance category recognition;Home appliances;Hidden Markov models;Protocols;Accuracy;Computational modeling;Databases;Monitoring;Intrusive Load Monitoring (ILM);Appliance Identification;Appliance State Recognition},
doi={10.1109/DSAA.2014.7058084},
ISSN={},
month={Oct},}
@ARTICLE{8805443,
author={J. {Zhao} and M. {Karimzadeh} and L. S. {Snyder} and C. {Surakitbanharn} and Z. C. {Qian} and D. S. {Ebert}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={MetricsVis: A Visual Analytics System for Evaluating Employee Performance in Public Safety Agencies},
year={2020},
volume={26},
number={1},
pages={1193-1203},
abstract={Evaluating employee performance in organizations with varying workloads and tasks is challenging. Specifically, it is important to understand how quantitative measurements of employee achievements relate to supervisor expectations, what the main drivers of good performance are, and how to combine these complex and flexible performance evaluation metrics into an accurate portrayal of organizational performance in order to identify shortcomings and improve overall productivity. To facilitate this process, we summarize common organizational performance analyses into four visual exploration task categories. Additionally, we develop MetricsVis, a visual analytics system composed of multiple coordinated views to support the dynamic evaluation and comparison of individual, team, and organizational performance in public safety organizations. MetricsVis provides four primary visual components to expedite performance evaluation: (1) a priority adjustment view to support direct manipulation on evaluation metrics; (2) a reorderable performance matrix to demonstrate the details of individual employees; (3) a group performance view that highlights aggregate performance and individual contributions for each group; and (4) a projection view illustrating employees with similar specialties to facilitate shift assignments and training. We demonstrate the usability of our framework with two case studies from medium-sized law enforcement agencies and highlight its broader applicability to other domains.},
keywords={business data processing;data analysis;data visualisation;human resource management;organisational aspects;personnel;organizational performance analyses;dynamic evaluation;multiple coordinated views;visual exploration task categories;flexible performance evaluation metrics;complex performance evaluation metrics;employee achievements;public safety agencies;employee performance;visual analytics system;group performance view;individual employees;reorderable performance matrix;priority adjustment view;MetricsVis;public safety organizations;Organizations;Task analysis;Data visualization;Performance evaluation;Visual analytics;Organizational performance analysis;multi-dimensional data;hierarchical relationships;visual analytics},
doi={10.1109/TVCG.2019.2934603},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{7865902,
author={C. {Ahlstrom} and K. {Kircher}},
journal={IEEE Transactions on Intelligent Transportation Systems},
title={A Generalized Method to Extract Visual Time-Sharing Sequences From Naturalistic Driving Data},
year={2017},
volume={18},
number={11},
pages={2929-2938},
abstract={Indicators based on visual time-sharing have been used to investigate drivers' visual behaviour during additional task execution. However, visual time-sharing analyses have been restricted to additional tasks with well-defined temporal start and end points and a dedicated visual target area. We introduce a method to automatically extract visual time-sharing sequences directly from eye tracking data. This facilitates investigations of systems, providing continuous information without well-defined start and end points. Furthermore, it becomes possible to investigate time-sharing behavior with other types of glance targets such as the mirrors. Time-sharing sequences are here extracted based on between-glance durations. If glances to a particular target are separated by less than a time-based threshold value, we assume that they belong to the same information intake event. Our results indicate that a 4-s threshold is appropriate. Examples derived from 12 drivers (about 100 hours of eye tracking data), collected in an on-road investigation of an in-vehicle information system, are provided to illustrate sequence-based analyses. This includes the possibility to investigate human-machine interface designs based on the number of glances in the extracted sequences, and to increase the legibility of transition matrices by deriving them from time-sharing sequences instead of single glances. More object-oriented glance behavior analyses, based on additional sensor and information fusion, are identified as the next future step. This would enable automated extraction of time-sharing sequences not only for targets fixed in the vehicle's coordinate system, but also for environmental and traffic targets that move independently of the driver's vehicle.},
keywords={data visualisation;driver information systems;feature extraction;human computer interaction;road traffic;traffic engineering computing;user interfaces;time-based threshold value;eye tracking data;glance behavior analyses;visual time-sharing sequence extraction;driver visual behaviour;naturalistic driving data;in-vehicle information system;human-machine interface designs;transition matrices;Visualization;Vehicles;Gaze tracking;Roads;Data mining;Mirrors;Uncertainty;Driver behaviour;glance analysis;visual time-sharing},
doi={10.1109/TITS.2017.2658945},
ISSN={1558-0016},
month={Nov},}
@INPROCEEDINGS{6945175,
author={M. {Mueller-Holtz} and H. {Seker} and G. {Smith}},
booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Wavelet denoising and reconstruction of a microneedle embedded in human skin ex-vivo using terahertz pulsed reflectance},
year={2014},
volume={},
number={},
pages={6740-6743},
abstract={Biological tissue can show promising features in the terahertz region of the electro-magnetic spectrum but face the problem that the signal to noise ratio can be poor due to the low energy output from the measurement instrument coupled with the high absorbance of water in biological tissue. Wavelet denoising and reconstruction are known to be suitable digital signal processing filters for reflected terahertz energy when appropriate thresholds, scales and mother-wavelets are chosen. In this article, we therefore describe a Wavelet transform-based method for denoising reflections of THz energy from ex-vivo human skin with an embedded microneedle. The wavelet reconstruction was then successfully used to identify the microneedle from the reflected waveform. This technique is potentially useful to enhance in-depth analysis and visualisation of underlying skin layers, lesions and penetration depth for targeted drug delivery.},
keywords={data visualisation;drug delivery systems;image denoising;image reconstruction;medical image processing;needles;skin;terahertz wave imaging;wavelet transforms;targeted drug delivery;penetration depth;lesions;skin layer visualisation;in-depth analysis;reflected waveform;embedded microneedle;ex-vivo human skin;THz energy;reflection denoising;wavelet transform-based method;mother-wavelets;reflected terahertz energy;digital signal processing filters;wavelet reconstruction;water;measurement instrument;low energy output;signal to noise ratio;electro-magnetic spectrum;terahertz region;biological tissue;terahertz pulsed reflectance;wavelet denoising;Algorithms;Histological Techniques;Humans;Signal Processing, Computer-Assisted;Signal-To-Noise Ratio;Skin;Wavelet Analysis},
doi={10.1109/EMBC.2014.6945175},
ISSN={1558-4615},
month={Aug},}
@INPROCEEDINGS{7591800,
author={X. {Li} and H. {Huang} and Y. {Sun}},
booktitle={2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
title={TriboWalk: Triboelectric dual functional wireless system for gait monitoring and energy harvesting},
year={2016},
volume={},
number={},
pages={4796-4799},
abstract={In this paper, we report the design and validation of a novel wearable wireless system, TriboWalk, for gait monitoring and motion energy harvesting based on triboelectrification. Gait analysis is an important diagnostic method for medical rehabilitation. The TriboWalk system is capable of gait monitoring and analysis by capturing gait timing parameters and ground contact force (GCF) pattern based on four tribo-elements on each shoe sole. The tribo-elements are removable and easily placed on different shoes. A visualization tool is also developed for data analysis. The tribo-elements can generate high output voltage over 20 V during random and low frequency motion, acting as good motion energy harvesters. The experiments were conducted with normal and fast walking speed. The results showed that the TriboWalk system can provide dual functions of gait monitoring and energy harvesting, enabling remote monitoring of patients in daily life at very low cost.},
keywords={biomedical communication;biomedical equipment;data analysis;data visualisation;energy harvesting;gait analysis;medical computing;patient monitoring;triboelectricity;wearable computers;wireless sensor networks;Zigbee;triboelectric dual functional wireless system;gait monitoring;TriboWalk wearable wireless system;motion energy harvesting;gait timing parameters;ground contact force pattern;triboelements;visualization tool;data analysis;high-output voltage;Legged locomotion;Foot;Monitoring;Energy harvesting;Wireless communication;Sensors;Wireless sensor networks;Gait Monitoring;Wireless Sensor Network;Motion Energy Harvesting;Wearable Device;Calibration;Equipment Design;Foot;Gait;Humans;Mechanical Phenomena;Motion;Remote Consultation;Shoes;Signal Processing, Computer-Assisted;Walking},
doi={10.1109/EMBC.2016.7591800},
ISSN={1558-4615},
month={Aug},}
@INPROCEEDINGS{8589560,
author={P. {Hirani} and S. {Balivada} and R. {Chauhan} and G. {Shaikh} and L. {Murthy} and A. {Balhara} and R. C. {Ponduru} and H. {Sharma} and S. {Chary} and G. B. {Subramanyam} and S. {Randhawa} and T. {Dutta} and H. P. {Gupta} and A. {Gupta} and A. {Haldar} and A. {Sarkar} and I. {Khan} and S. {Guha}},
booktitle={2018 IEEE SENSORS},
title={Using Cyber Physical Systems to Map Water Quality Over Large Water Bodies},
year={2018},
volume={},
number={},
pages={1-4},
abstract={The world faces a grave water risk that affects all aspects of human life and ecology with implications for food security, energy production, industrial activity and human health. India is particularly affected as it has 16% of the world's population but access to less than 4% of global freshwater resources. In this study, we use mobile (moving) sensors to spatially and temporally map river water quality based on in-situ data gathered in some of India's major rivers. Data visualizations generated are intended to pinpoint sources of pollution, ensure regulatory compliance and examine health of the water body. We show that such cyber physical sensing techniques can be a powerful and more practical (or cost-effective) way to dynamically monitor, predict and regulate the quality of large bodies of water.},
keywords={data visualisation;ecology;hydrological techniques;rivers;water quality;cyber physical systems;water body;grave water risk;human life;ecology;food security;energy production;industrial activity;human health;India;global freshwater resources;map river water quality;data visualizations;cyber physical sensing techniques;Rivers;Water pollution;Water resources;Sensors;Monitoring;Pollution measurement;Heatmaps;Water quality;Internet of Things(IoT)},
doi={10.1109/ICSENS.2018.8589560},
ISSN={2168-9229},
month={Oct},}
@ARTICLE{6064960,
author={M. {Haidacher} and S. {Bruckner} and E. {Groller}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Volume Analysis Using Multimodal Surface Similarity},
year={2011},
volume={17},
number={12},
pages={1969-1978},
abstract={The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.},
keywords={computerised tomography;data visualisation;pattern classification;volume analysis;multimodal surface similarity;classification space;information theoretic measure;isosurface similarity;multimodal classification;data value combinations;dual energy computed tomography;industrial manufacturing;Isosurfaces;Histograms;Computed tomography;Transfer functions;Mutual information;Multimodal data;volume visualization;surface similarity.;Angiography;Brain;Brain;Computer Graphics;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Tomography, X-Ray Computed},
doi={10.1109/TVCG.2011.258},
ISSN={1941-0506},
month={Dec},}
@INPROCEEDINGS{8949613,
author={A. {Fensel}},
booktitle={2019 International Conference on Computer, Control, Informatics and its Applications (IC3INA)},
title={Keynote: Building Smart Cities with Knowledge Graphs},
year={2019},
volume={},
number={},
pages={1-1},
abstract={Smart city systems are increasingly built with data analytics and machine learning techniques, basing on massive data sets. They have a heavy impact on human behavior and quality of life, and thus need to deliver a controllable and sufficiently transparent experience for the users.The aim of my work is to make smart city systems more interoperable and explainable, involving data visualization and communication techniques, sensor data processing, as well as the associated intelligent data value chain production and consumption. Here, the data and the information are shared employing Knowledge Graphs, that are becoming a key enabler for large-scale processing of massive collections of interrelated facts. Examples include the Google Knowledge Graph with dozens of billion facts, dataCommons, DBPedia, YAGO, and Knowledge Vault, a very large scale probabilistic knowledge graph created with information extraction methods for unstructured or semi-structured information. Specifically, Knowledge Graphs provide the means of development of the newest methods for data management, data fusion, data merging, and graph and network optimization and modeling, serving as a source of high quality data and a base for information integration.In particular, Knowledge Graphs help to infer new relationships out of existing facts, giving context and meaning to the content, and can be used in applications. For example, the data generated by a computer vision system could be semantically represented and shared across numerous systems, taking into account the needs and requirements of these systems, as well as the context, provenance, licensing and consent aspects of the generated data. I demonstrate Knowledge Graphs-based methods in advanced smart city applications from the domains such as automation and construction of buildings, energy efficiency, tourism, transport.},
keywords={buildings (structures);data analysis;data mining;data visualisation;graph theory;inference mechanisms;knowledge based systems;learning (artificial intelligence);probability;sensor fusion;smart cities;town and country planning;smart city systems;data analytics;machine learning techniques;data visualization;communication techniques;sensor data processing;Google knowledge graph;Knowledge Vault;information extraction methods;data management;data fusion;network optimization;graph optimization;computer vision system;advanced smart city applications;knowledge graphs-based methods;probabilistic knowledge graph;intelligent data value chain production;building automation;DBPedia;dataCommons;YAGO;Smart cities;Semantic technology;Computer science;Google;Europe;Informatics},
doi={10.1109/IC3INA48034.2019.8949613},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6344510,
author={J. {Lung} and S. {Easterbrook}},
booktitle={2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
title={Augmenting flow diagrams created by end-user programs},
year={2012},
volume={},
number={},
pages={175-178},
abstract={Flow and causal loop diagrams can be used by content creators to illustrate how variables in a system impact one another. Such diagrams are used in educational settings to illustrate concepts like food cycles in an ecosystem and energy flows in climate models. We demonstrate how our tool, InfloGraphic, can produce interactive diagrams either by augmenting existing static diagrams produced using common tools users may already be familiar and have available such as the Gimp or Adobe Photoshop or by using a preexisting image or web page. Content consumers can use these interactive diagrams to visualize how changes to one part of a system can ripple through a system.},
keywords={data visualisation;flowcharting;interactive systems;personal computing;Web sites;flow diagram augmentation;end-user programs;causal loop diagrams;educational settings;food cycles;ecosystem;energy flows;climate models;InfloGraphic tool;interactive diagrams;static diagram augmentation;Gimp;Adobe Photoshop;Web page;content consumers;data visualisation;static image;HTML;Libraries;Mathematical model;Earth;Visualization;Browsers;Software},
doi={10.1109/VLHCC.2012.6344510},
ISSN={1943-6106},
month={Sep.},}
@INPROCEEDINGS{9076555,
author={A. K. {Singh} and S. {Mittal} and P. {Malhotra} and Y. V. {Srivastava}},
booktitle={2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC)},
title={Clustering Evaluation by Davies-Bouldin Index(DBI) in Cereal data using K-Means},
year={2020},
volume={},
number={},
pages={306-310},
abstract={Cereals grains have been used as a principle ingredient of human diet for hundreds of years. Indian cereal crops provide vital nutrients and energy to the human diet. The motivation behind this research paper is to distribute the research discoveries of applying K-Means clustering, on a cereal dataset and to differentiate the outcomes found on the number of bunches to identify whether the ideal or best number of groups to be 3 or 5. This speculation is achieved by applying distinctive clustering tests (likewise reordered in the paper), and visualizations. The aforementioned resolution by doing exploratory analysis, at that point modeled fitting followed by result testing, driving us to a definite end. The language utilized for our exploration is R.},
keywords={crops;data visualisation;food products;pattern clustering;production engineering computing;vital nutrients;human diet;k-means clustering;cereal dataset;clustering evaluation;cereals grains;clustering tests;Indian cereal crops;Davies-Bouldin index;visualizations;Clustering;K-Means;Cereals;DBI},
doi={10.1109/ICCMC48092.2020.ICCMC-00057},
ISSN={},
month={March},}
@INPROCEEDINGS{6295878,
author={S. {Iaconesi} and O. {Persico}},
booktitle={2012 16th International Conference on Information Visualisation},
title={VersuS, The Digital Lives of Cities Transforms into Usable Interconnective Intelligence},
year={2012},
volume={},
number={},
pages={602-606},
abstract={While we perform our daily tasks we reinterpret space and personalize it, according to tactics which reveal significant information about ourselves. We are now able to fill and stratify space/time with digital information layers, completely wrapping cities in a membrane of information and of opportunities for interaction and communication. Mobile devices, smartphones, wearables, digital tags, near field communication devices, location based services and mixed/augmented reality have turned the world into an essentially read/write, ubiquitous publishing surface. The usage of mobile devices and ubiquitous technologies alters the understanding of place. The scenario described in this paper sees urban spaces progressively filling with multiple layers of real-time, ubiquitous, digital information, creating usage cases in which urban narratives are read in different ways, highlighting how cities express points of view on the environment, culture, economy, transports, energy and politics. The research presented in this paper analyses multiple opportunities to capture, understand and visualize the real-time digital lives of cities, from a variety of points of view and objectives, dedicated to the needs of administrations, citizens and organizations, and to the possibility to transform these representations into a form of disseminated, ubiquitous, interconnective intelligence.},
keywords={augmented reality;cultural aspects;data visualisation;environmental factors;politics;social aspects of automation;social networking (online);town and country planning;ubiquitous computing;VersuS;usable interconnective intelligence;space reinterpretation;digital information layers;space-time stratification;mobile devices;smartphones;digital tags;near field communication devices;wearable devices;location based services;mixed reality;augmented reality;urban spaces;digital information;environmental aspects;culture;economy;energy aspects;politics;real-time digital lives visualization;digital cities;administration needs;organizations;disseminated intelligence;ubiquitous intelligence;social networks;urban planning;citizenship;Cities and towns;Visualization;Real time systems;Presses;Humans;Educational institutions;Mobile handsets;social networks;ubiquitous technologies;real-time information;urban contexts;urban planning;citizenship},
doi={10.1109/IV.2012.101},
ISSN={2375-0138},
month={July},}
@ARTICLE{8454905,
author={J. {Wang} and L. {Gou} and H. {Shen} and H. {Yang}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks},
year={2019},
volume={25},
number={1},
pages={288-298},
abstract={Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.},
keywords={computer games;data visualisation;learning (artificial intelligence);neural nets;DQNViz;deep Q-Network;deep reinforcement learning model;intelligent agent;optimal actions;professional human players;superhuman performance;sophisticated behaviors;DQN agent;visual analytics system;blind training process;experience space;DQN models;Atari games;deep learning experts;breakout game;reward patterns;action space;model training process;Training;Games;Visual analytics;Data visualization;Analytical models;Learning (artificial intelligence);Machine learning;Deep Q-Network (DQN);reinforcement learning;model interpretation;visual analytics},
doi={10.1109/TVCG.2018.2864504},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{7040668,
author={A. {Valerio Netto}},
journal={IEEE Latin America Transactions},
title={Planning of network system for the distribution and transmission areas of electric energy},
year={2015},
volume={13},
number={1},
pages={345-352},
abstract={In this project, we developed a computational system based on a framework of geo-referenced data that uses Google Maps technology. The focus is on improving the modeling of information for viewing and embedding technology, human-computer interface (HCI) which includes visualization environments synchronized. The first environment allows you to have the vision of the network elements in the form of electrical single line diagram, representing a consolidated technique in the field of electricity. The second environment called GIS is a map-based navigation with Google Maps that allows the physical location of where it is represented the elements present in the electrical line diagram. This integrated system is capable of supporting the planning of network expansion works in the areas of distribution and transmission of electricity.},
keywords={geographic information systems;human computer interaction;power distribution planning;power engineering computing;power transmission planning;synchronisation;network system;distribution areas;transmission areas;electric energy;computational system;georeferenced data;Google Maps technology;embedding technology;human-computer interface;HCI;electrical single line diagram;GIS;map-based navigation;network expansion works;Software;Google;Visualization;Unified modeling language;Planning;Computational modeling;Electricity;distribution;GIS;google maps;planning;system of decision making;transmission;visualization system},
doi={10.1109/TLA.2015.7040668},
ISSN={1548-0992},
month={Jan},}
@INPROCEEDINGS{7169375,
author={G. {C} and C. {J} and D. S. {V} and D. {S}},
booktitle={2015 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON)},
title={A full-reference stereoscopic image quality metric based on binocular energy and regression analysis},
year={2015},
volume={},
number={},
pages={1-5},
abstract={The recent developments of 3D media technology have brought to life numerous applications of interactive entertainment such as 3D cinema, 3DTV and gaming. However, due to the data intensive nature of 3D visual content, a number of research challenges have emerged. In order to optimise the end-to-end content life-cycle, from capture to processing and delivery, Quality of Experience (QoE) has become a major driving factor. This paper presents a human-centric approach to quality estimation of 3D visual content. A fullreference quality assessment method for stereoscopic images is proposed. It is based on a Human Visual System (HVS) model to estimate subjective scores of registered stereoscopic images subjected to compression losses. The model has been trained with four publicly available registered stereoscopic image databases and a fixed relationship between subjective scores and the model has been determined. The high correlation of the relationship over a large number of stimuli has proven its consistency over the state-of-the-art.},
keywords={computer vision;entertainment;image registration;man-machine systems;quality of experience;regression analysis;stereo image processing;compression loss;human visual system;registered stereoscopic image;full-reference quality assessment method;3D visual content quality estimation;human centric approach;QoE;quality of experience;interactive entertainment application;3D media technology;regression analysis;binocular energy;full-reference stereoscopic image quality metric;Measurement;Stereo image processing;Three-dimensional displays;Visualization;Analytical models;Image quality;Quality assessment;Human Visual System;Binocular vision;Stereoscopic image quality metric},
doi={10.1109/3DTV.2015.7169375},
ISSN={2161-203X},
month={July},}
@ARTICLE{8049349,
author={D. {Liu} and A. K. {Khambampati} and J. {Du}},
journal={IEEE Transactions on Medical Imaging},
title={A Parametric Level Set Method for Electrical Impedance Tomography},
year={2018},
volume={37},
number={2},
pages={451-460},
abstract={This paper presents an image reconstruction method based on parametric level set (PLS) method using electrical impedance tomography. The conductivity to be reconstructed was assumed to be piecewise constant and the geometry of the anomaly was represented by a shape-based PLS function, which we represent using Gaussian radial basis functions (GRBF). The representation of the PLS function significantly reduces the number of unknowns, and circumvents many difficulties that are associated with traditional level set (TLS) methods, such as regularization, re-initialization and use of signed distance function. PLS reconstruction results shown in this article are some of the first ones using experimental EIT data. The performance of the PLS method was tested with water tank data for two-phase visualization and with simulations which demonstrate the most popular biomedical application of EIT: lung imaging. In addition, robustness studies of the PLS method w.r.t width of the Gaussian function and GRBF centers were performed on simulated lung imaging data. The experimental and simulation results show that PLS method has significant improvement in image quality compared with the TLS reconstruction.},
keywords={computerised tomography;electric impedance imaging;image reconstruction;least squares approximations;lung;medical image processing;radial basis function networks;experimental EIT data;two-phase visualization;lung imaging;GRBF centers;simulated lung imaging data;Gaussian function;PLS reconstruction results;signed distance function;Gaussian radial basis functions;PLS function;image reconstruction method;electrical impedance tomography;parametric level set method;TLS reconstruction;PLS method;Tomography;Image reconstruction;Level set;Conductivity;Inverse problems;Lungs;Shape;Electrical impedance tomography;parametric level set method;lung imaging;inverse problems;Computer Simulation;Electric Impedance;Humans;Image Processing, Computer-Assisted;Lung;Thorax;Tomography},
doi={10.1109/TMI.2017.2756078},
ISSN={1558-254X},
month={Feb},}
@ARTICLE{8752446,
author={D. {Seebacher} and M. {Miller} and T. {Polk} and J. {Fuchs} and D. A. {Keim}},
journal={IEEE Computer Graphics and Applications},
title={Visual Analytics of Volunteered Geographic Information: Detection and Investigation of Urban Heat Islands},
year={2019},
volume={39},
number={5},
pages={83-95},
abstract={Urban heat islands are local areas where the temperature is much higher than in the vicinity and are a modern phenomenon that occurs mainly in highly developed areas, such as large cities. This effect has a negative impact on energy management in buildings, and also has a direct impact on human health, especially for elderly people. With the advent of volunteered geographic information from private weather station networks, more high-resolution data are now available within cities to better analyze this effect. However, such datasets are large and have heterogeneous characteristics requiring visual-interactive applications to support further analysis. We use machine learning methods to predict urban heat islands occurrences and utilize temporal and spatio-temporal visualizations to contextualize the emergence of urban heat islands to comprehend the influencing causes and their effects. Subsequently, we demonstrate the analysis capabilities of our application by presenting two use cases.},
keywords={atmospheric temperature;data analysis;data visualisation;geographic information systems;geriatrics;learning (artificial intelligence);urban heat islands occurrences;spatio-temporal visualizations;visual analytics;volunteered geographic information;private weather station networks;high-resolution data;visual-interactive applications;machine learning methods;Thermal pollution;Urban areas;Data visualization;Meteorology;Buildings;Heating systems;Visualization},
doi={10.1109/MCG.2019.2926242},
ISSN={1558-1756},
month={Sep.},}
@ARTICLE{9094630,
author={J. {Zhou} and T. {Xu} and S. {Ren} and K. {Guo}},
journal={IEEE Access},
title={Two-Stage Spatial Mapping for Multimodal Data Fusion in Mobile Crowd Sensing},
year={2020},
volume={8},
number={},
pages={96727-96737},
abstract={Human-driven Edge Computing (HEC) integrates the elements of humans, devices, Internet and information, and mobile crowd sensing become an important means of data collection. In HEC, the data collected from large-scale sensing usually includes a variety of modalities. These different modality data contain unique information and attributes, which can be complementary. Combining data from many different modalities will get more information. However, current deep learning is usually only for bimodal data. In order for artificial intelligence to make further breakthroughs in understanding our real world, it needs to be able to process data in different modalities together. The key step is to be able to map these different modalities data into the same space. In order to process multimodal data better, we propose a fusion and classification method for multimodal data. First, a multimodal data space is constructed, and data of different modalities are mapped into the multimodal data space to obtain a unified representation of different modalities data. Then, through bilinear pooling, the representations of different modality are fused, and the fused vectors are used in the classification task. Through the experimental verification on the multi-modal data set, it proves that the multi-modal fusion representation is effective, and the classification effect is more accurate than the single-modal data.},
keywords={learning (artificial intelligence);mobile computing;neural nets;pattern classification;sensor fusion;multimodal fusion representation;single-modal data;multimodal data fusion;mobile crowd sensing;bimodal data;multimodal data space;two-stage spatial mapping;human-driven edge computing;artificial intelligence;classification method;bilinear pooling;Sensors;Fuses;Semantics;Correlation;Visualization;Neural networks;Edge computing;Multimodal data;unified representation;mobile crowd sensing;human-driven edge computing},
doi={10.1109/ACCESS.2020.2995268},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7566767,
author={P. {Swami} and T. {Gandhi} and B. K. {Panigrahi} and M. {Bhatia} and S. {Anand}},
booktitle={2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN)},
title={Locating ictal activities over human scalp with automated detection using EEG signals},
year={2016},
volume={},
number={},
pages={600-604},
abstract={Epilepsy is one of the most common brain disorder which affects more than sixty-five million people worldwide. Its diagnosis is usually performed using electroencephalography technique. Since, electroencephalogram (EEG) signals are highly susceptible to artifacts, epilepsy diagnosis is often challenging task. In addition, locating the origin of seizure patterns is even more tedious due to the non-linear nature of EEG signals. Therefore, automated seizure detection systems are highly important to overcome the said challenges. In this study, we have designed a procedure which integrates the seizure detection and localization process with ceiling level of efficiency. Here, we evaluated the energy and standard features using `coiflets' wavelet packets. Then, the feature matrix was reduced by applying fast correlation based filter. Application of 5-Nearest Neighbour classifier resulted in mean accuracy of 99.3515±0.2518 % taking only 0.152±0.0344 seconds for execution. Later, independent component analysis over the ictal segments was applied and subsequently topographic scalps maps were plotted. The results successfully implied automated detection and visualization of ictal activities over the human scalp.},
keywords={correlation methods;data visualisation;electroencephalography;filtering theory;independent component analysis;matrix algebra;medical signal detection;medical signal processing;signal classification;wavelet transforms;ictal activities localization;human scalp;EEG signals;brain disorder;electroencephalography technique;electroencephalogram signals;epilepsy diagnosis;automated seizure detection systems;seizure localization process;efficiency ceiling level;coiflets wavelet packets;feature matrix;fast correlation based filter;5-nearest neighbour classifier;independent component analysis;topographic scalps maps;ictal activities visualization;Electroencephalography;Epilepsy;Brain models;Feature extraction;Standards;Electrodes;Electroencephalogram (EEG);Ictal activities;topographic maps;k-Nearest Neighbor (k-NN) classifier},
doi={10.1109/SPIN.2016.7566767},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8210574,
author={A. {Petropoulos} and D. {Sikeridis} and T. {Antonakopoulos}},
booktitle={2017 IEEE 7th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
title={SPoMo: IMU-based real-time sitting posture monitoring},
year={2017},
volume={},
number={},
pages={5-9},
abstract={Improper sitting posture can lead to a number of serious health disorders connected to the musculoskeletal system. Especially nowadays sitting periods at work or at home are increasing, and therefore consistent stance monitoring can help users improve their sitting habits and avoid related complications. In this work, we present SPoMo a real-time, practical, wearable system that automatically tracks the user's sitting posture, through wireless sensors attached to his back. Our prototype is based on Inertial Measurement Units (IMUs) that monitor the angle deviation from the optimal position. We have also developed a cloud-assisted mobile application able to continuously visualize the user's stance, archive his performance over time and provide insight for future development of proper posture. We focus on presenting SPoMo functionality and experimentally evaluate its performance. Our results prove our system to be accurate and therefore a good every-day solution that helps the consumer to avoid chronic improper posture.},
keywords={cloud computing;data visualisation;diseases;feature extraction;health care;human computer interaction;medical computing;medical disorders;mobile computing;sensor fusion;sitting habits;health disorders;SPoMo functionality;user stance visualization;ergonomic suggestions;data stream fusion;data extraction;consistent stance monitoring;musculoskeletal system;real-time sitting posture monitoring;chronic improper posture;cloud-assisted mobile application;Inertial Measurement Units;wireless sensors;wearable system;Sensors;Accelerometers;Monitoring;Gyroscopes;Quaternions;Back;Calibration;Sitting posture monitoring;Wearables;Bluetooth Low Energy;IMU},
doi={10.1109/ICCE-Berlin.2017.8210574},
ISSN={2166-6822},
month={Sep.},}
@INPROCEEDINGS{7047970,
author={S. {Mann}},
booktitle={2014 IEEE Games Media Entertainment},
title={“SELF-HII”: Strength + endurance + longevity through gameplay with humanistic intelligence by Fieldary Human Information Interaction},
year={2014},
volume={},
number={},
pages={1-8},
abstract={In 1995 Gershon founded the field of HII (Human Information Interaction). I build upon his seminal work by creating a new multiscale framework for (1) sensing, and (2) being sensed by, any measurable or generable classical or quantum scalar, vector, spinor, or tensor field, such as being able to sense and be sensed by water, sound, light (real or virtual) - and in some cases even being able to sense sensing itself (i.e. the sightfield of a camera-visualizing vision and seeing sight itself). I call this FHII (Fieldary Human Information Interaction) and apply it to physical fitness by way of serious games. Physical fitness training normally builds strength or endurance. Strength usually deals with a short-term (short time period), and is somewhat related to power, as measured in Watts (Joules per second). Endurance usually deals with a longer-term, and is more closely related to energy, as measured in Joules (Watt seconds). I argue that the time-scale of endurance is really only medium-term, when considering an average human lifespan. Therefore I present a third category of physical fitness I call Longevity, along with a new quantity I call "actergy" ("total action"). Actergy has units of Joule seconds, the same units as Plank's constant, angular momentum, and action. These three units: (1) Joules per second, (2) Joules, and (3) Joule seconds, suggest (1) Differential, (2) Proportional, and (3) Integral, forms of kinesology. Their three related forms of fitness training: Strength + Endurance + Longevity (SEL), can operate within the Fieldary Human Information Interaction space. I present a unified framework for this: SEL-FHII ("O Φ", pronounced "sel Φ ", i.e. either "selfeye" or "selfie") training that combines all three time scales (differential, proportional, and integral) with ideas in HI (Humanistic Intelligence). Combining wearable computing and IoT (Internet of Things), we can contextualize the otherwise disparate fields of/in Serious Games, SELFHII, Sonelization, Entertainment, and Media, across these multiple scales, as a form of urban design, whether at the environmental scale of countries, cities, and streets, or the invironmental scale of Digital Eye Glass and the individual body (e.g. clothing as a building built for a single occupant). In particular, thinking beyond traditional gaming consoles, we can achieve longevity through gameplay at the intersection of cyberspace and the real world.},
keywords={computer games;data visualisation;human computer interaction;Internet of Things;wearable computing;media;entertainment;sonelization;IoT;Internet of Things;Joule seconds;Joules;Watt seconds;Joules per second;serious games;FHII;camera-visualizing vision;Digital Eye Glass;Watts;Fieldary Human Information Interaction;humanistic intelligence;SELF-HII},
doi={10.1109/GEM.2014.7047970},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7377217,
author={R. {Janzen} and S. {Mann}},
booktitle={2015 IEEE Games Entertainment Media Conference (GEM)},
title={Sensory flux from the eye: Biological sensing-of-sensing (veillametrics) for 3D augmented-reality environments},
year={2015},
volume={},
number={},
pages={1-9},
abstract={We measure and visualize the ability-to-see, from the human eye, as that ability-to-see propagates through space. "Biological veillance flux" is a metric of sensory precision emitted from the eyes and falling on objects, with much greater detail than merely tracking the center of the eye's field of view. This work makes it possible to "see sight" and "measure sight" as the "sight" travels through three-dimensional space. In earlier work we measured veillance flux from electronic sensors and cameras. Now, we examine biological veillance flux. The result is a method to detect radiation of information-bearing optical sensitivity, as opposed to radiation of ordinary light energy in the opposite direction. These measurements can be used as an augmented-reality visualization of human sight. They can serve as an interactive score tracking how much a target is seen. Additionally, they could serve as a data-rich metric of visual precision directed by human eyes toward control panels in industrial applications, or as a metric of visual precision directed by human eyes towards printed material or digital media, for advertising, arts or entertainment applications. Extramissive optics, as a new field of research, is thus expanded into the biological realm.},
keywords={augmented reality;cameras;data visualisation;sensory flux;biological sensing-of-sensing;veillametrics;3D augmented-reality environment;biological veillance flux;human eye;electronic sensors;cameras;information-bearing optical sensitivity;ordinary light energy radiation;augmented-reality visualization;Cameras;Three-dimensional displays;Optical sensors;Visualization;Extraterrestrial measurements},
doi={10.1109/GEM.2015.7377217},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7045792,
author={S. {Boddhu} and R. {Flagg} and P. {Grzebala} and R. {Bodduluri} and R. {Williams}},
booktitle={NAECON 2014 - IEEE National Aerospace and Electronics Conference},
title={A generic sensor fusion architecture for enhancing situational awareness},
year={2014},
volume={},
number={},
pages={143-148},
abstract={The advancements of mobile technology and its widespread availability have redefined many computing paradigms including Human-centric sensing. Human-centric sensing has already been successfully implemented as integrated network architecture component in many operational intelligent systems in various industry areas such as defense, healthcare, energy or disaster management. The process of integration of Human-centric sensing into the system can be lengthy and complicated because of disparate data formats, modality and connectivity interfaces. Extending an existing system by new, and possibly future, sensors may result in low-level integration issues. There is a need for a generic architecture that will be able to dynamically accommodate new sensors and to provide fusion of all sensed data. In this paper, we extend our previous work of developing an architecture that supports seamless integration and development of platforms to enhance situational awareness in the context of Human-centric sensing.},
keywords={human factors;intelligent sensors;mobile computing;sensor fusion;mobile technology;human-centric sensing;generic sensor fusion architecture;situational awareness enhancement;operational intelligent system;data fusion;Sensors;Computer architecture;Collaboration;Real-time systems;Data visualization;Software;Surveillance;event collaboration architecture;sensor fusion;situational awareness;mongodb},
doi={10.1109/NAECON.2014.7045792},
ISSN={2379-2027},
month={June},}
@INPROCEEDINGS{6017803,
author={A. {Kongthon} and C. {Haruechaiyasak} and C. {Sangkeettrakarn} and P. {Palingoon} and W. {Wunnasri}},
booktitle={2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET)},
title={HotelOpinion: An opinion mining system on hotel reviews in Thailand},
year={2011},
volume={},
number={},
pages={1-6},
abstract={This paper reports on the extension of our previous work on feature-based opinion mining for Thai language. In this paper, we present an approach for automatically constructing two main lexicons: features and polar words based on syntactic pattern analysis. The evaluation is performed with a case study on hotel reviews. The experimental results show that our approach is effective in performing its task. To illustrate the potential application, we implement a system called HotelOpinion for summarizing the hotel reviews written in the Thai language. Our system can also generate a comparison between hotels based upon the user's preferred features and then present the results in a user-friendly visualization. Results from our system can be used to determine public perceptions regarding selected hotels in order to allow the business to improve their customer intimacy and satisfaction.},
keywords={data mining;hotel industry;natural language processing;reviews;opinion mining system;hotel reviews;Thailand;polar words;syntactic pattern analysis;HotelOpinion;Thai language;customer intimacy;customer satisfaction;Feature extraction;Pattern analysis;Data mining;Syntactics;Companies;User-generated content;Cities and towns},
doi={},
ISSN={2159-5100},
month={July},}
@INPROCEEDINGS{7942694,
author={ {Minh Nghia Le} and H. {Inuzuka} and T. {Nakanishi} and {Quang Vy Nguyen} and Y. {Morita} and M. {Sakai}},
booktitle={2017 3rd International Conference on Control, Automation and Robotics (ICCAR)},
title={Graphical simulator for teaching robot with parallel wire type teaching device},
year={2017},
volume={},
number={},
pages={233-236},
abstract={In order to enable operators to teach the desired motion to a robot directly and easily, we are developing a parallel wire type device (PAWTED) which is attached to an end-effector of a robot. However, practical experiments and researching so far shows that there still exists a problem of singular points in which the robot moves fast unstably and out of limitation range in energy aspect. Therefore, we have to analyze movement of a robot in both teaching and playing-back modes as well as the pulling forces and moments which are felt by operators during process of teaching. This paper presents two simulators to simulate those problems. One is used to analyze movement of a 6-dof serial manipulator in both modes. The other one is used to analyze the forces and moments in teaching mode. The movements of the robot and the PAWTED are visualized graphically using Open Graphics Library (OpenGL). These simulators will be combined and used to design control algorithms of avoidance of singular postures.},
keywords={control engineering computing;data visualisation;digital simulation;end effectors;human-robot interaction;teaching;graphical simulator;teaching robot;parallel wire type teaching device;PAWTED;end-effector;teaching mode;playing-back mode;pulling forces;6-DoF serial manipulator;graphical visualization;Open Graphics Library;OpenGL;singular posture avoidance;Robots;Graphics;Wires;Computational modeling;Standards;Manuals;teaching robot;parallel wire;stewart platform;OpenGL;C++;Simulation},
doi={10.1109/ICCAR.2017.7942694},
ISSN={},
month={April},}
@INPROCEEDINGS{9121446,
author={D. {Li} and Y. {Gong} and S. {Shen} and M. {Zhang}},
booktitle={2020 Asia Energy and Electrical Engineering Symposium (AEEES)},
title={Research and Design of Power Equipment Operation and Maintenance System Based on Big Data Technology},
year={2020},
volume={},
number={},
pages={323-327},
abstract={With the passage of time, especially the arrival of the information age, the impact of electricity in human society is more and more huge. Not only production and scientific research rely on electricity, but also people's daily life, work and various activities depend on electricity. Therefore, the power security work becomes particularly important, and the power equipment substation is an important part of the power grid. The inspection and operation and maintenance of power equipment is the basic way to ensure the safety and normal work of power equipment. The traditional planned operation and maintenance method of power equipment can significantly reduce the failure rate of power equipment, but there are problems such as insufficient or excessive maintenance, blind maintenance and so on. In order to improve the efficiency of power equipment maintenance, this paper designs a set of power equipment maintenance system based on big data analysis technology of power operation and maintenance. According to a large number of operation data of power system accumulated by power equipment, including various equipment status monitoring, maintenance and other data, the system can diagnose, optimize and predict the operation of the whole power grid equipment through key technology of big data analysis, which can reduce the maintenance cost, improve the actual effect of maintenance, improve the intelligent level of operation and maintenance of power equipment, and provide guarantee for the safe, reliable, economic and efficient operation of the network.},
keywords={Big Data;data analysis;electrical safety;failure analysis;inspection;maintenance engineering;power apparatus;power engineering computing;power grids;power system reliability;power system security;substations;power security;power equipment substation;power equipment maintenance system;power grid equipment;failure analysis;big data analysis;power equipment;operation and maintenance;big data technology;visualization technology},
doi={10.1109/AEEES48850.2020.9121446},
ISSN={},
month={May},}
@ARTICLE{8565958,
author={M. {Koyuncu} and A. {Yazici} and M. {Civelek} and A. {Cosar} and M. {Sert}},
journal={IEEE Sensors Journal},
title={Visual and Auditory Data Fusion for Energy-Efficient and Improved Object Recognition in Wireless Multimedia Sensor Networks},
year={2019},
volume={19},
number={5},
pages={1839-1849},
abstract={Automatic threat classification without human intervention is a popular research topic in wireless multimedia sensor networks (WMSNs) especially within the context of surveillance applications. This paper explores the effect of fusing audio-visual multimedia and scalar data collected by the sensor nodes in a WMSN for the purpose of energy-efficient and accurate object detection and classification. In order to do that, we implemented a wireless multimedia sensor node with video and audio capturing and processing capabilities in addition to traditional/ordinary scalar sensors. The multimedia sensors are kept in sleep mode in order to save energy until they are activated by the scalar sensors which are always active. The object recognition results obtained from video and audio applications are fused to increase the object recognition performance of the sensor node. Final results are forwarded to the sink in text format, and this greatly reduces the size of data transmitted in network. Performance test results of the implemented prototype system show that the fusing audio data with visual data improves automatic object recognition capability of a sensor node significantly. Since auditory data requires less processing power compared to visual data, the overhead of processing the auditory data is not high, and it helps to extend network lifetime of WMSNs.},
keywords={data visualisation;multimedia systems;object detection;object recognition;sensor fusion;wireless sensor networks;wireless multimedia sensor networks;automatic threat classification;fusing audio-visual multimedia;wireless multimedia sensor node;multimedia sensors;audio applications;object detection;visual data fusion;auditory data fusion;automatic object recognition;Sensors;Wireless sensor networks;Streaming media;Visualization;Cameras;Wireless communication;Image coding;Wireless multimedia sensor;object detection;visual and auditory data fusion;WMSN},
doi={10.1109/JSEN.2018.2885281},
ISSN={1558-1748},
month={March},}
@ARTICLE{6541974,
author={H. {Lu} and X. {Shao} and Y. {Xiao}},
journal={IEEE Transactions on Image Processing},
title={Pose Estimation With Segmentation Consistency},
year={2013},
volume={22},
number={10},
pages={4040-4048},
abstract={In this paper, we propose a novel method that treats pose estimation as a problem with the constraints of human segmentation consistency from single images. Different from the previous paper, we integrate pose estimation and object segmentation into a joint optimization. With the support of segmentation consistency, we can obtain more reliable pose results. Through analyzing the energy function of pose estimation and human segmentation, we convert the pose estimation into a binary optimization problem that has the same formation as segmentation. The top-down pose shape cues, bottom-up visual cues, and the consistency constraints that penalize the mismatching of pose and human foreground are incorporated into our final objective function. Qualitative and quantitative experimental results demonstrate the merits of our method in pose estimation on Ramanan benchmark and Buffy data sets.},
keywords={image segmentation;integer programming;linear programming;pose estimation;pose estimation;human segmentation consistency;object segmentation;joint optimization;energy function;binary optimization problem;top-down pose shape cues;bottom-up visual cues;consistency constraints;Ramanan benchmark;Buffy data sets;Image segmentation;Pose estimation;Optimization;Shape;Detectors;Motion segmentation;Visualization;Human Segmentation;Pose Estimation;Segmentation Consistency;Integer Linear Program;Databases, Factual;Extremities;Head;Humans;Image Processing, Computer-Assisted;Posture;Torso},
doi={10.1109/TIP.2013.2268975},
ISSN={1941-0042},
month={Oct},}
@INPROCEEDINGS{8798180,
author={O. {Ergün} and Ş. {Akın} and İ. G. {Dino} and E. {Surer}},
booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
title={Architectural Design in Virtual Reality and Mixed Reality Environments: A Comparative Analysis},
year={2019},
volume={},
number={},
pages={914-915},
abstract={Virtual reality (VR) provides a completely digital world of interaction which enables the users to modify, edit, and transform digital elements in a responsive way. Mixed reality (MR), which is the result of blending the digital world and the physical world together, brings new advancements and challenges to human, computer and environment interactions. This paper focuses on adapting the already-existing methods and tools in architecture to both VR and MR environments under sustainable architectural design domain. For this purpose, we benefit from the semantically enriched data platforms of Building information modelling (BIM) tools, the performance calculation functions of building energy simulation tools while transcending these data into VR and MR environments. In this way, we were able to merge these diverse data for the virtual design activity. Nine participants have already tested the initial prototype of MR-based only interaction environment in our previous study [1]. According to the feedbacks, the user interface and interaction mechanisms were updated and the environment was made accessible also in VR. These updates made four types of interactions possible in MR and VR: 1) MR environment using HoloLens with gestures, 2) MR environment using HoloLens with a clicker, 3) VR environment using HTC Vive with two controllers, and 4) HoloLens emulator with a mouse. All these interaction cases were tested by 21 architecture students in an in-house workshop. In this workshop, we collected data on presence, usability, and technology acceptance of these cases. Our results show that interaction in a VR environment is the most natural interaction type and the participants were eager to use both MR and VR environments instead of an emulator. To our best of knowledge, this is the first comparative study of a BIM-based architectural design medium in both VR and MR environments.},
keywords={architectural CAD;augmented reality;building management systems;buildings (structures);virtual reality;physical world;sustainable architectural design domain;semantically enriched data platforms;performance calculation functions;building energy simulation tools;virtual design activity;interaction environment;user interface;HoloLens;VR environment;natural interaction type;BIM-based architectural design medium;mixed reality environments;building information modelling tools;architecture students;Virtual reality;Solid modeling;Tools;Buildings;Usability;Data models;Data visualization;Mixed Reality;Virtual Reality;Building Information Modelling;J [Computer Applications]: J.6. Computer-Aided Engineering},
doi={10.1109/VR.2019.8798180},
ISSN={2642-5254},
month={March},}
@INPROCEEDINGS{7532868,
author={M. S. {Gide} and S. F. {Dodge} and L. J. {Karam}},
booktitle={2016 IEEE International Conference on Image Processing (ICIP)},
title={Visual attention quality database for benchmarking performance evaluation metrics},
year={2016},
volume={},
number={},
pages={2792-2796},
abstract={With the increased focus on visual attention (VA) in the last decade, a large number of computational visual saliency methods have been developed. These models are evaluated by using performance evaluation metrics that measure how well a predicted map matches eye-tracking data obtained from human observers. Though there are a number of existing performance evaluation metrics, there is no clear consensus on which evaluation metric is the best. This work proposes a subjective study that uses ratings from human observers to evaluate saliency maps computed by existing VA models based on comparing the maps visually with ground-truth maps obtained from eye-tracking data. The subjective ratings are correlated with the scores obtained from existing as well as a proposed objective VA performance evaluation metric using several correlation measures. The correlation results show that the proposed objective VA metric outperforms the existing metrics.},
keywords={computer vision;gaze tracking;image enhancement;visual databases;visual attention quality database;VA quality database;performance evaluation metric;visual saliency method;eye-tracking data;human observer;human visual system;HVS;Visualization;Correlation;Databases;Benchmark testing;Performance evaluation;Gold;Visual Attention;Subjective Study;VA Performance Metrics;VA Models},
doi={10.1109/ICIP.2016.7532868},
ISSN={2381-8549},
month={Sep.},}
@INPROCEEDINGS{5584709,
author={S. {Inoue} and J. {Dai} and M. {Shiba} and S. {Aoki} and H. {Tsuji}},
booktitle={International Conference on Fuzzy Systems},
title={Knowledge management approach for saving home energy consumption},
year={2010},
volume={},
number={},
pages={1-6},
abstract={In order to save home energy consumption, this paper proposes an indirect control method. “Indirect” in this paper means that the system notifies users to control their life style and usage of home equipments. The basic idea is as follows: (1) Collect home energy consumption data with personal property including their life style by Web-based questionnaire, (2) Notify consumers their status of energy consumption in the same category homes when they disclose their consumed energy data, (3) Advise action for saving energy if one consumes energy much. This paper introduces how to implement the idea in a knowledge management system and discusses the issues to implement the idea. The feasibility test has also shown the possibility of the proposed method.},
keywords={building management systems;energy consumption;home automation;intelligent control;Internet;knowledge management;load flow control;power aware computing;power engineering computing;home energy consumption;Web-based questionnaire;knowledge management system;indirect energy load control method;Energy consumption;Knowledge management;Humans;Internet;Probabilistic logic;Data visualization;Dispersion},
doi={10.1109/FUZZY.2010.5584709},
ISSN={1098-7584},
month={July},}
@INPROCEEDINGS{7298934,
author={R. {Anirudh} and P. {Turaga} and J. {Su} and A. {Srivastava}},
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Elastic functional coding of human actions: From vector-fields to latent variables},
year={2015},
volume={},
number={},
pages={3147-3155},
abstract={Human activities observed from visual sensors often give rise to a sequence of smoothly varying features. In many cases, the space of features can be formally defined as a manifold, where the action becomes a trajectory on the manifold. Such trajectories are high dimensional in addition to being non-linear, which can severely limit computations on them. We also argue that by their nature, human actions themselves lie on a much lower dimensional manifold compared to the high dimensional feature space. Learning an accurate low dimensional embedding for actions could have a huge impact in the areas of efficient search and retrieval, visualization, learning, and recognition. Traditional manifold learning addresses this problem for static points in ℝn, but its extension to trajectories on Riemannian manifolds is non-trivial and has remained unexplored. The challenge arises due to the inherent non-linearity, and temporal variability that can significantly distort the distance metric between trajectories. To address these issues we use the transport square-root velocity function (TSRVF) space, a recently proposed representation that provides a metric which has favorable theoretical properties such as invariance to group action. We propose to learn the low dimensional embedding with a manifold functional variant of principal component analysis (mfPCA). We show that mf-PCA effectively models the manifold trajectories in several applications such as action recognition, clustering and diverse sequence sampling while reducing the dimensionality by a factor of ~ 250×. The mfPCA features can also be reconstructed back to the original manifold to allow for easy visualization of the latent variable space.},
keywords={data reduction;functions;image motion analysis;image recognition;image sequences;principal component analysis;human actions elastic functional coding;transport square-root velocity function;TSRVF space;low dimensional embedding;manifold functional principal component analysis;mfPCA;dimensionality reduction;statistics;action sequences;action recognition;Manifolds;Trajectory;Shape;Measurement;Principal component analysis;Visualization;Joints},
doi={10.1109/CVPR.2015.7298934},
ISSN={1063-6919},
month={June},}
@ARTICLE{7930375,
author={J. {Baek} and H. {Jeon} and G. {Kim} and S. {Han}},
journal={IEEE Access},
title={Visualizing Quaternion Multiplication},
year={2017},
volume={5},
number={},
pages={8948-8955},
abstract={Quaternion rotation is a powerful tool for rotating vectors in 3-D; as a result, it has been used in various engineering fields, such as navigations, robotics, and computer graphics. However, understanding it geometrically remains challenging, because it requires visualizing 4-D spaces, which makes exploiting its physical meaning intractable. In this paper, we provide a new geometric interpretation of quaternion multiplication using a movable 3-D space model, which is useful for describing quaternion algebra in a visual way. By interpreting the axis for the scalar part of quaternion as a 1-D translation axis of 3-D vector space, we visualize quaternion multiplication and describe it as a combined effect of translation, scaling, and rotation of a 3-D vector space. We then present how quaternion rotation formulas and the derivative of quaternions can be formulated and described under the proposed approach.},
keywords={data visualisation;mathematics computing;number theory;vectors;quaternion multiplication visualization;quaternion rotation;rotating vectors;4D space visualization;geometric interpretation;movable 3D space model;quaternion algebra;1D translation axis;3D vector space translation;3D vector space scaling;3D vector space rotation;quaternion rotation formulas;Quaternions;Visualization;Space vehicles;Algebra;Robots;Computational modeling;4-dimensional spaces;geometry;scaling;quaternion rotation},
doi={10.1109/ACCESS.2017.2705196},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8279979,
author={D. {Arena} and D. {Kiritsis} and C. {Ziogou} and S. {Voutetakis}},
booktitle={2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)},
title={Semantics-driven knowledge representation for decision support and status awareness at process plant floors},
year={2017},
volume={},
number={},
pages={902-908},
abstract={The aim of this work is to demonstrate the potential of introducing ontologies for an appropriate visual status signaling at industrial process units. The need for safe operation and maintenance, either preventive or condition-based, drives the proposed approach, which supports operators and technical team utilizing knowledge from the workers, combined with reasoning techniques. As a consequence, the traditional Human Machine Interfaces (HMIs) are able to provide appropriate information to the workers about the status of a plant's subsystems. As far as the overall proposed approach is concerned, the adoption of semantics in this framework is not to say that all of the data integration issues and increasingly less distributed ontologies, are solved. Here, semantics modelling and semantics-driven (or semantic rules-based) analysis methods are exploited to conceptualize a semantically-enriched platform, and test it in terms of feasibility at a chemical pilot plant of CERTH/CPERI, showing some interesting preliminary results.},
keywords={data integration;decision support systems;human computer interaction;knowledge representation;ontologies (artificial intelligence);preventive maintenance;Human Machine Interfaces;data integration;Semantics-driven knowledge representation;visual status signaling;distributed ontologies;semantically-enriched platform;semantic rules;reasoning techniques;preventive condition;maintenance;safe operation;industrial process units;process plant floors;status awareness;decision support;Semantics;Ontologies;Maintenance engineering;Topology;Data mining;Floors;Monitoring;Ontologies;Industrial Semantics;Information Visualisation;Smart Plant Floor},
doi={10.1109/ICE.2017.8279979},
ISSN={},
month={June},}
@ARTICLE{9102991,
author={M. F. {Hashmi} and B. K. K. {Ashish} and A. G. {Keskar} and N. D. {Bokde} and J. H. {Yoon} and Z. W. {Geem}},
journal={IEEE Access},
title={An Exploratory Analysis on Visual Counterfeits Using Conv-LSTM Hybrid Architecture},
year={2020},
volume={8},
number={},
pages={101293-101308},
abstract={In recent years, with the advancements in the Deep Learning realm, it has been easy to create and generate synthetically the face swaps from GANs and other tools, which are very realistic, leaving few traces which are unclassifiable by human eyes. These are known as `DeepFakes' and most of them are anchored in video formats. Such realistic fake videos and images are used to create a ruckus and affect the quality of public discourse on sensitive issues; defaming one's profile, political distress, blackmailing and many more fake cyber terrorisms are envisioned. This work proposes a microscopic-typo comparison of video frames. This temporal-detection pipeline compares very minute visual traces on the faces of real and fake frames using Convolutional Neural Network (CNN) and stores the abnormal features for training. A total of 512 facial landmarks were extracted and compared. Parameters such as eye-blinking lip-synch; eyebrows movement, and position, are few main deciding factors that classify into real or counterfeit visual data. The Recurrent Neural Network (RNN) pipeline learns based on these features-fed inputs and then evaluates the visual data. The model was trained with the network of videos consisting of their real and fake, collected from multiple websites. The proposed algorithm and designed network set a new benchmark for detecting the visual counterfeits and show how this system can achieve competitive results on any fake generated video or image.},
keywords={face recognition;feature extraction;image classification;image motion analysis;learning (artificial intelligence);recurrent neural nets;video signal processing;visual counterfeits;fake generated video;exploratory analysis;conv-LSTM hybrid architecture;synthetically the face swaps;GAN;human eyes;DeepFakes;video formats;realistic fake videos;public discourse;sensitive issues;political distress;blackmailing cyber terrorisms;microscopic-typo comparison;video frames;temporal-detection pipeline;minute visual traces;fake frames;abnormal features;eye-blinking lip-synch;eyebrow movement;counterfeit visual data;feature-fed inputs;recurrent neural network pipeline;facial landmarks;fake cyber terrorisms;Face;Training;Visualization;Decoding;Gallium nitride;Machine learning;Recurrent neural networks;DeepFakes;generative adversarial network (GANs);facial landmarks;convolutional neural networks (CNN);recurrent neural network (RNN);visual counterfeits},
doi={10.1109/ACCESS.2020.2998330},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8340693,
author={E. M. {Stewart} and P. {Top} and M. {Chertkov} and D. {Deka} and S. {Backhaus} and A. {Lokhov} and C. {Roberts} and V. {Hendrix} and S. {Peisert} and A. {Florita} and T. J. {King} and M. J. {Reno}},
booktitle={2017 IEEE International Conference on Smart Grid Communications (SmartGridComm)},
title={Integrated multi-scale data analytics and machine learning for the distribution grid},
year={2017},
volume={},
number={},
pages={423-429},
abstract={We consider the field of machine learning and where it is both useful, and not useful, for the distribution grid and buildings interface. While analytics, in general, is a growing field of interest, and often seen as the golden goose in the burgeoning distribution grid industry, its application is often limited by communications infrastructure, or lack of a focused technical application. Overall, the linkage of analytics to purposeful application in the grid space has been limited. In this paper we consider the field of machine learning as a subset of analytical techniques, and discuss its ability and limitations to enable the future distribution grid. To that end, we also consider the potential for mixing distributed and centralized analytics and the pros and cons of these approaches. There is an exponentially expanding volume of measured data being generated on the distribution grid, which, with appropriate application of analytics, may be transformed into intelligible, actionable information that can be provided to the right actors - such as grid and building operators, at the appropriate time to enhance grid or building resilience, efficiency, and operations against various metrics or goals - such as total carbon reduction or other economic benefit to customers. While some basic analysis into these data streams can provide a wealth of information, computational and human boundaries on performing the analysis are becoming significant, with more data and multi-objective concerns. Efficient applications of analysis and the machine learning field are being considered in the loop. This paper describes benefits and limits of present machine-learning applications for use on the grid and presents a series of case studies that illustrate the potential benefits of developing advanced local multi-variate analytics machine-learning-based applications.},
keywords={data analysis;data visualisation;learning (artificial intelligence);power distribution;power engineering computing;power grids;integrated multiscale data analytics;machine-learning applications;multivariate analytics;distribution grid industry;Machine learning;Buildings;Reliability;Machine learning algorithms;Conferences;Smart grids;Analytics;Machine Learning;Distribution Grid;DER;validation;verification;prediction;incipient failure},
doi={10.1109/SmartGridComm.2017.8340693},
ISSN={},
month={Oct},}
@ARTICLE{7466117,
author={R. {Anirudh} and P. {Turaga} and J. {Su} and A. {Srivastava}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Elastic Functional Coding of Riemannian Trajectories},
year={2017},
volume={39},
number={5},
pages={922-936},
abstract={Visual observations of dynamic phenomena, such as human actions, are often represented as sequences of smoothly-varying features. In cases where the feature spaces can be structured as Riemannian manifolds, the corresponding representations become trajectories on manifolds. Analysis of these trajectories is challenging due to non-linearity of underlying spaces and high-dimensionality of trajectories. In vision problems, given the nature of physical systems involved, these phenomena are better characterized on a low-dimensional manifold compared to the space of Riemannian trajectories. For instance, if one does not impose physical constraints of the human body, in data involving human action analysis, the resulting representation space will have highly redundant features. Learning an effective, low-dimensional embedding for action representations will have a huge impact in the areas of search and retrieval, visualization, learning, and recognition. Traditional manifold learning addresses this problem for static points in the euclidean space, but its extension to Riemannian trajectories is non-trivial and remains unexplored. The difficulty lies in inherent non-linearity of the domain and temporal variability of actions that can distort any traditional metric between trajectories. To overcome these issues, we use the framework based on transported square-root velocity fields (TSRVF); this framework has several desirable properties, including a rate-invariant metric and vector space representations. We propose to learn an embedding such that each action trajectory is mapped to a single point in a low-dimensional euclidean space, and the trajectories that differ only in temporal rates map to the same point. We utilize the TSRVF representation, and accompanying statistical summaries of Riemannian trajectories, to extend existing coding methods such as PCA, KSVD and Label Consistent KSVD to Riemannian trajectories or more generally to Riemannian functions. We show that such coding efficiently captures trajectories in applications such as action recognition, stroke rehabilitation, visual speech recognition, clustering and diverse sequence sampling. Using this framework, we obtain state-of-the-art recognition results, while reducing the dimensionality/ complexity by a factor of 100-250x. Since these mappings and codes are invertible, they can also be used to interactively-visualize Riemannian trajectories and synthesize actions.},
keywords={computer vision;image coding;vector space representations;rate invariant metric;TSRVF;transported square-root velocity fields;temporal variability;action representations;human action analysis;physical constraints;Riemannian manifolds;smoothly-varying features;visual observations;Riemannian trajectories;elastic functional coding;Trajectory;Manifolds;Encoding;Visualization;Measurement;Speech recognition;Principal component analysis;Riemannian geometry;activity recognition;dimensionality reduction;visualization},
doi={10.1109/TPAMI.2016.2564409},
ISSN={1939-3539},
month={May},}
@INPROCEEDINGS{6610415,
author={A. {Foncubierta-Rodríguez} and Ó. A. {Jiménez del Toro} and A. {Platon} and P. {Poletti} and H. {Müller} and A. {Depeursinge}},
booktitle={2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
title={Benefits of texture analysis of dual energy CT for Computer-Aided pulmonary embolism detection},
year={2013},
volume={},
number={},
pages={3973-3976},
abstract={Pulmonary embolism is an avoidable cause of death if treated immediately but delays in diagnosis and treatment lead to an increased risk. Computer-assisted image analysis of both unenhanced and contrast-enhanced computed tomography (CT) have proven useful for diagnosis of pulmonary embolism. Dual energy CT provides additional information over the standard single energy scan by generating four-dimensional (4D) data, in our case with 11 energy levels in 3D. In this paper a 4D texture analysis method capable of detecting pulmonary embolism in dual energy CT is presented. The method uses wavelet-based visual words together with an automatic geodesic-based region of interest detection algorithm to characterize the texture properties of each lung lobe. Results show an increase in performance with respect to the single energy CT analysis, as well as an accuracy gain compared to preliminary work on a small dataset.},
keywords={computer aided analysis;computerised tomography;diseases;image texture;lung;medical image processing;wavelet transforms;dual energy CT;computer-aided pulmonary embolism detection;computer-assisted image analysis;contrast-enhanced computed tomography;pulmonary embolism diagnosis;standard single energy scan;four-dimensional data;energy levels;4D texture analysis method;wavelet-based visual words;automatic geodesic-based region of interest detection algorithm;lung lobe;single energy CT analysis;Visualization;Computed tomography;Energy states;Lungs;Accuracy;Three-dimensional displays;Radiology;Texture analysis;pulmonary embolism;dual energy CT;visual words;4D image analysis;Algorithms;Humans;Lung;Pulmonary Embolism;Radiographic Image Interpretation, Computer-Assisted;Tomography, X-Ray Computed;Wavelet Analysis},
doi={10.1109/EMBC.2013.6610415},
ISSN={1558-4615},
month={July},}
@ARTICLE{8723476,
author={G. {Zhang} and K. {Li} and D. {Gu} and X. {Wang} and X. {Yang} and K. {Zhu} and G. {Liang}},
journal={IEEE Access},
title={Visualizing Knowledge Evolution and Hotspots of Rural Environment and Health: A Systematic Review and Research Direction},
year={2019},
volume={7},
number={},
pages={72538-72550},
abstract={With global warming, energy scarcity, water shortages, and air, soil, and water pollution, the situation of environments in countries around the world is getting more and more serious and in some countries, rural environmental issues are more prominent. Health problems in rural areas also cannot be ignored, chronic diseases and infectious diseases have become the greatest threat to human life, while good environment and human health are the foundation of social and economic sustainable development. This paper adopts the bibliometrics method to conduct a visual analysis of 6,971 studies in the field of the rural environment and health published on the Web of Science between 2000 and 2017, including time knowledge map analysis, space knowledge map analysis, knowledge base analysis, and research focus analysis. This paper reveals the development status of research in the field of rural environment and health, analyzes, and discusses the research hotspots and future development trends in this field, and provides important knowledge support for researchers to carry out follow-up research.},
keywords={data visualisation;diseases;environmental science computing;global warming;health care;knowledge based systems;sustainable development;water pollution;knowledge evolution visualization;research hotspots;knowledge base analysis;space knowledge map analysis;visual analysis;economic sustainable development;social development;human health;infectious diseases;chronic diseases;health problems;water pollution;water shortages;energy scarcity;global warming;rural environment;Bibliometrics;Market research;Knowledge engineering;Visualization;Water pollution;Diseases;Knowledge based systems;Rural;health;environment;pollution;bibliometric analysis},
doi={10.1109/ACCESS.2019.2919549},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8327022,
author={C. {Xie} and X. {Fu} and S. {Song}},
booktitle={2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
title={Perception-Oriented 3D Rendering Approximation for Modern Graphics Processors},
year={2018},
volume={},
number={},
pages={362-374},
abstract={Anisotropic filtering enabled by modern rasterization-based GPUs provides users with extremely authentic visualization experience, but significantly limits the performance and energy efficiency of 3D rendering process due to its large texture data requirement. To improve 3D rendering efficiency, we build a bridge between anisotropic filtering process and human visual system by analyzing users' perception on image quality. We discover that anisotropic filtering does not impact user perceived image quality on every pixel. This motives us to approximate the anisotropic filtering process for non-perceivable pixels in order to improve the overall 3D rendering performance without damaging user experience. To achieve this goal, we propose a perceptionoriented runtime approximation model for 3D rendering by leveraging the inner-relationship between anisotropic and isotropic filtering. We also provide a low-cost texture unit design for enabling this approximation. Extensive evaluation on modern 3D games demonstrates that, under a conservative tuning point, our design achieves a significant average speedup of 17% for the overall 3D rendering along with 11% total GPU energy reduction, without visible image quality loss from users' perception. It also reduces the texture filtering latency by an average of 29%. Additionally, it creates a unique perception-based tuning space for performance-quality tradeoffs on graphics processors.},
keywords={approximation theory;computer games;computer graphics;graphics processing units;human factors;image texture;rendering (computer graphics);visual perception;isotropic filtering;low-cost texture unit design;modern 3D games;perception-oriented 3D rendering approximation;texture data requirement;3D rendering efficiency;anisotropic filtering process;human visual system;3D rendering performance;user experience;image quality loss;modern graphics processors;authentic visualization experience;perception-oriented runtime approximation model;Three-dimensional displays;Rendering (computer graphics);Image quality;Image color analysis;Computer architecture;Runtime;Graphics processing units;GPU;Approximate Computing;3D Rendering;User-Oriented Study},
doi={10.1109/HPCA.2018.00039},
ISSN={2378-203X},
month={Feb},}
@INPROCEEDINGS{7286304,
author={B. {Falahati} and A. {Kargarian}},
booktitle={2015 IEEE Power Energy Society General Meeting},
title={Power system reliability enhancement considering smart monitoring},
year={2015},
volume={},
number={},
pages={1-5},
abstract={With improvements in smart sensing and digital instrumentation technologies, small, low-cost sensors have been installed in power networks, thus providing new opportunities for smart monitoring. Smart monitoring consists of analog/digital sensors, measurement units, control devices, and protective relays inside a digital communication network working together to gather local information about the power grid, to be recorded in the servers and to demonstrate human machine interfaces (HMI). To keep a power system operating reliably, it is necessary to continuously monitor and indicate crucial points of the power network. This paper introduces various aspects of power system monitoring and indication and proposes a mathematic model to numerically assess the positive effects of smart monitoring on the power system's reliability. Based on the Markov model, the formulation used to calculate the updated failure and repair rates of the power equipment is extracted.},
keywords={computerised monitoring;digital instrumentation;human computer interaction;Markov processes;power apparatus;power engineering computing;power system measurement;power system reliability;power system reliability enhancement;smart monitoring;smart sensing;digital instrumentation technology;power network;human machine interface;power system monitoring;mathematical model;Markov model;failure rate calculation;repair rate estimation;power equipment;Monitoring;Power system reliability;Maintenance engineering;Reliability;Markov processes;Substations;Smart grid;power system reliability;monitoring;visualization;data manipulation;indication;Markov chain},
doi={10.1109/PESGM.2015.7286304},
ISSN={1932-5517},
month={July},}
@ARTICLE{7571172,
author={C. {Spampinato} and S. {Palazzo} and D. {Giordano}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Gamifying Video Object Segmentation},
year={2017},
volume={39},
number={10},
pages={1942-1958},
abstract={Video object segmentation can be considered as one of the most challenging computer vision problems. Indeed, so far, no existing solution is able to effectively deal with the peculiarities of real-world videos, especially in cases of articulated motion and object occlusions; limitations that appear more evident when we compare the performance of automated methods with the human one. However, manually segmenting objects in videos is largely impractical as it requires a lot of time and concentration. To address this problem, in this paper we propose an interactive video object segmentation method, which exploits, on one hand, the capability of humans to identify correctly objects in visual scenes, and on the other hand, the collective human brainpower to solve challenging and large-scale tasks. In particular, our method relies on a game with a purpose to collect human inputs on object locations, followed by an accurate segmentation phase achieved by optimizing an energy function encoding spatial and temporal constraints between object regions as well as human-provided location priors. Performance analysis carried out on complex video benchmarks, and exploiting data provided by over 60 users, demonstrated that our method shows a better trade-off between annotation times and segmentation accuracy than interactive video annotation and automated video object segmentation approaches.},
keywords={computer games;computer vision;image segmentation;interactive systems;video signal processing;interactive video annotation;collective human brainpower;visual scenes;computer vision;video object segmentation;gamification;Games;Object segmentation;Visualization;Motion segmentation;Data mining;Computers;Computer vision;Interactive video annotation;games with a purpose;human in the loop;spatio-temporal superpixel segmentation},
doi={10.1109/TPAMI.2016.2610973},
ISSN={1939-3539},
month={Oct},}
@ARTICLE{6209406,
author={L. {Ma} and S. {Li} and K. N. {Ngan}},
journal={IEEE Transactions on Circuits and Systems for Video Technology},
title={Reduced-Reference Video Quality Assessment of Compressed Video Sequences},
year={2012},
volume={22},
number={10},
pages={1441-1456},
abstract={In this paper, a novel reduced-reference (RR) video quality assessment (VQA) is proposed by exploiting the spatial information loss and the temporal statistical characteristics of the interframe histogram. From the spatial perspective, an energy variation descriptor (EVD) is proposed to measure the energy change of each individual encoded frame, which results from the quantization process. Besides depicting the energy change, EVD can further simulate the texture masking property of the human visual system (HVS). From the temporal perspective, the generalized Gaussian density (GGD) function is employed to capture the natural statistics of the interframe histogram distribution. The city-block distance (CBD) is used to calculate the histogram distance between the original video sequence and the encoded one. For simplicity, the difference image between adjacent frames is employed to characterize the temporal interframe relationship. By combining the spatial EVD together with the temporal CBD, an efficient RR VQA is developed. Evaluation on the subjective quality video database demonstrates that the proposed method outperforms the representative RR video quality metric and the full-reference VQAs, such as peak signal-to-noise ratio and structure similarity index in matching subjective ratings. This means that the proposed metric is more consistent with the HVS perception. Furthermore, as only a small number of RR features are extracted for representing the original video sequence (each frame requires only one parameter for describing EVD and three parameters for recording GGD), the RR features can be embedded into the video sequences or transmitted through the ancillary data channel, which can be used in the video quality monitoring system.},
keywords={data compression;encoding;Gaussian processes;image matching;image representation;image sequences;video coding;reduced-reference video quality assessment;compressed video sequences;RR VQA;spatial information loss;temporal statistical characteristics;energy variation descriptor;EVD;individual encoded frame;quantization process;human visual system;HVS;generalized Gaussian density function;GGD function;natural statistics;interframe histogram distribution;city-block distance;CBD;adjacent frames;temporal interframe relationship;subjective quality video database;representative RR video quality metric;full-reference VQA;signal-to-noise ratio;structure similarity index;subjective rating matching;HVS perception;video sequence representation;ancillary data channel;video quality monitoring system;Feature extraction;Measurement;Video sequences;Discrete cosine transforms;Visualization;Histograms;Quantization;Energy variation descriptor (EVD);generalized Gaussian density (GGD);human visual system (HVS);reduced-reference (RR);video quality assessment (VQA)},
doi={10.1109/TCSVT.2012.2202049},
ISSN={1558-2205},
month={Oct},}
@INPROCEEDINGS{8577080,
author={F. {Morawitz}},
booktitle={2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments (SIVE)},
title={Quantum: An art-science case study on sonification and sound design in virtual reality},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Molecular sonification is the transformation of chemical data into sound and has been used to gain insight into chemical systems and for the creation of contemporary music compositions. The combination of sonification with a virtual reality environment offers potential benefits such as providing a visual frame of reference, an increased sense of immersion, nuanced spatial information through binaural audio cues and ease of interactivity. To explore how strategies developed in sonification research and contemporary electroacoustic music composition can be adapted to virtual reality, the art-science installation 'Quantum' was created. The multi-media work consists of computer-generated molecules in a virtual space producing sound created via the sonification of nuclear magnetic resonance data. Upon user interaction with different molecules, the overall composition and complexity of the sound world develop. The binaural sound material can migrate back and forth from the molecules to the non-binaural background composition and, depending on user input, develop in terms of timbre, spectral complexity, and gestural content. `Quantum' is an exploration of the combination of sonification and virtual reality and offers first points of discussion that can be elaborated upon in future artworks, games or educational content.},
keywords={art;audio signal processing;audio user interfaces;chemistry computing;human computer interaction;multimedia computing;music;nuclear magnetic resonance;virtual reality;nuclear magnetic resonance data;user interaction;sound world;binaural sound material;nonbinaural background composition;art-science case study;sound design;molecular sonification;chemical data;chemical systems;contemporary music compositions;virtual reality environment;binaural audio cues;sonification research;contemporary electroacoustic music composition;computer-generated molecules;virtual space;Quantum;art-science installation;multimedia work;Sonification;Energy states;Visualization;Nuclear magnetic resonance;Virtual reality;Chemicals;Sonification;Molecular Sonification;Virtual Reality},
doi={10.1109/SIVE.2018.8577080},
ISSN={},
month={March},}
@INPROCEEDINGS{9069763,
author={H. Y. {El Sayed} and M. {Al-Kady} and Y. {Siddik}},
booktitle={2019 International Conference on Smart Applications, Communications and Networking (SmartNets)},
title={Management of Smart Water Treatment Plant using IoT Cloud Services},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Water Treatment Plant (WTP) is an important infrastructure to ensure human health and the environment. In its development, aspects of environmental safety and health are of great importance. Smart WTP is a water station that is managed using software-based tools such as data analytics, visualization, and predictive analytics. WTP smart management system is developed to manage Big Data information flows from many sensors and smart devices that allow for real-time responses and connectivity to Internet of Things (IoT) Cloud platforms services. The performance of the Smart WTP operations should be consistently evaluated to ensure that the plant is operating efficiently, thus minimizing energy costs and improving water purity and quality conservation parameters. Our proposed solution is based on sensors monitoring and Big Data analysis of Smart Water Treatment Plant (SWTP) using IoT hardware devices that have an internet connection to an IoT Cloud platform. The Cloud platform such as Thing Speak has the capability to analyze, visualize and react based on the Big Data analytics to send risk alarms and operate risk management plans to overcome the failure scenarios and minimize the downtime operation of the Smart WTP.},
keywords={Big Data;cloud computing;data analysis;Internet;Internet of Things;public utilities;risk management;water treatment;IoT cloud services;human health;environmental safety;water station;software-based tools;WTP smart management system;Big Data information;smart devices;Smart WTP operations;energy costs;improving water purity;quality conservation parameters;IoT hardware devices;Big Data analytics;risk management;smart water treatment plant;Internet of Things cloud platforms services;internet connection;Cloud computing;Internet of Things;Intelligent sensors;Big Data;Monitoring;Hardware;Internet of Things (IoT);Artificial Intelligence (AI);Cloud Platforms;Big Data;Big Data Analytics;Water Treatment Plant;Risk Management},
doi={10.1109/SmartNets48225.2019.9069763},
ISSN={},
month={Dec},}

@INPROCEEDINGS{8339087,
author={B. {Bush} and N. {Brunhart-Lupo} and B. {Bugbee} and V. {Krishnan} and K. {Potter} and K. {Gruchalla}},
booktitle={2017 IEEE Workshop on Data Systems for Interactive Analysis (DSIA)},
title={Coupling visualization, simulation, and deep learning for ensemble steering of complex energy models},
year={2017},
volume={},
number={},
pages={1-5},
abstract={We describe a new framework that allows users to explore and steer ensembles of energy systems simulations by coupling multiple energy models and interactive visualization through a dataflow API. Through the visual interface, users can interactively explore complex parameter spaces populated by hundreds, or thousands, of simulation runs and interactively spawn new simulations to “fill in” regions of interest in the parameter space. The computational and visualization capabilities reside within a general-purpose dataflow architecture for connecting producers of multidimensional timeseries data, such as energy simulations, with consumers of that data, whether they be visualizations, statistical analyses, or datastores. Fast computation and agile dataflow can enhance the engagement with energy simulations, allowing users to populate the parameter space in real time. However, many energy simulations are far too slow to provide an interactive response. To support interactive feedback, we are creating reduced-form simulations developed through machine learning techniques, which provide statistically sound estimates of the results of the full simulations at a fraction of the computational cost. These reduced-form simulations have response times on the order of seconds, suitable for real-time human-in-the-loop design and analysis. The approximation methods apply to a wide range of computational models, including supply-chain models, electric power grid simulations, and building models. Such reduced-form representations do not replace or re-implement existing simulations, but instead supplement them by enabling rapid scenario design and exploration for large ensembles of simulations. The improved understanding, facilitated by the reduced-form models, dataflow API, and visualization tools, allows researchers to better allocate computational resources to capture informative relationships within the system as well as provide a low-cost method for validating and quality-checking large-scale modeling efforts.},
keywords={application program interfaces;approximation theory;data flow computing;data visualisation;digital simulation;graphical user interfaces;interactive systems;learning (artificial intelligence);power aware computing;resource allocation;statistical analysis;time series;coupling visualization;ensemble steering;complex energy models;energy systems simulations;multiple energy models;interactive visualization;dataflow API;visual interface;complex parameter spaces;general-purpose dataflow architecture;energy simulations;interactive response;interactive feedback;reduced-form simulations;computational models;electric power grid simulations;reduced-form models;visualization tools;computational visualization capabilities;deep learning;multidimensional time series data;statistical analysis;data stores;agile dataflow;machine learning techniques;computational cost;real-time human-in-the-loop design;approximation methods;supply-chain models;building models;reduced-form representations;computational resource allocation;quality-checking large-scale modeling;Computational modeling;Analytical models;Servers;Data models;Data visualization;Simulation;Databases;Deep learning;immersive visualization;databases;multidimensional time-series;neural networks;ensemble visualization;energy system models},
doi={10.1109/DSIA.2017.8339087},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6914208,
author={J. {K} and R. {P} and B. {P} and S. {B}},
booktitle={2014 International Conference on Computer, Communications, and Control Technology (I4CT)},
title={Development of Android based on-line monitoring and control system for Renewable Energy Sources},
year={2014},
volume={},
number={},
pages={372-375},
abstract={This paper describes the development of an online monitoring and control system for distributed Renewable Energy Sources (RES) based on Android platform. This method utilizes the Bluetooth interface of Android Tablet/ Mobile phone as a communication link for data exchange with digital hardware of Power Conditioning Unit (PCU). The Low Cost Android tablet can replace the graphical LCD displays and Internet modem of RES Power Conditioning Unit (PCU) with enhanced graphical visualization and touch screen interface.},
keywords={air conditioning;Bluetooth;computerised monitoring;control engineering computing;data visualisation;electronic data interchange;graphical user interfaces;Internet;modems;notebook computers;power engineering computing;renewable energy sources;smart phones;Android based online monitoring development;control system development;renewable energy source;Bluetooth interface;mobile phone;communication link;data exchange;PCU digital hardware;Low Cost Android tablet;distributed RES Power Conditioning Unit;graphical visualization enhanced;touch screen interface;Androids;Humanoid robots;Monitoring;Internet;Power generation;Renewable energy sources;Hardware;RES- Renewable Energy Source;PCU- Power Conditioning Unit;SPV-Solar Photovoltaic;UART - Universal asynchronous receiver/transmitter;HMI- Human Machine Interface;LCD- Liquid Crystal Display;DSP- Digital Signal Processor},
doi={10.1109/I4CT.2014.6914208},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6676549,
author={M. {Masoodian} and B. {Endrass} and R. {Bühling} and P. {Ermolin} and E. {André}},
booktitle={2013 17th International Conference on Information Visualisation},
title={Time-Pie visualization: Providing Contextual Information for Energy Consumption Data},
year={2013},
volume={},
number={},
pages={102-107},
abstract={In recent years a growing number of information visualization systems have been developed to assist users with monitoring their energy consumption, with the hope of reducing energy use through more effective user-awareness. Most of these visualizations can be categorized into either some form of a time-series or pie chart, each with their own limitations. These visualization systems also often ignore incorporating contextual (e.g. weather, environmental) information which could assist users with better interpretation of their energy use information. In this paper we introduce the time-pie visualization technique, which combines the concepts of timeseries and pie charts, and allows the addition of contextual information to energy consumption data.},
keywords={data visualisation;power aware computing;time series;contextual information;energy consumption data;information visualization systems;energy consumption reduction;time-series;pie chart;time-pie visualization technique;Data visualization;Energy consumption;Prototypes;Buildings;Context;Meteorology;Sensors;Energy usage visualization;energy usage monitoring;energy usage management;time-line visualization;pie chart visualization;rose chart;time-pie visualization},
doi={10.1109/IV.2013.12},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{7272575,
author={M. {Masoodian} and B. {Lugrin} and R. {Bühling} and E. {André}},
booktitle={2015 19th International Conference on Information Visualisation},
title={Visualization Support for Comparing Energy Consumption Data},
year={2015},
volume={},
number={},
pages={28-34},
abstract={Providing effective feedback can empower users to change their behaviour and take the necessary actions to reduce their energy consumption. The types of feedback that allow comparison of energy usage seem to be particularly valuable. This paper introduces the time-stack visualization, which has been designed to support comparisons of individual and collective energy usage data. It also describes a user study conducted to compare the effectiveness of time-stack against a similar visualization called time-pie. The results show that although the two visualizations are generally comparable in their effectiveness, users rate time-stack more favourably.},
keywords={data visualisation;energy consumption;environmental science computing;visualization support;energy consumption data comparison;energy consumption reduction;user behavior;energy usage comparison;time-stack visualization;energy usage data;user study;time-pie visualization;Data visualization;Energy consumption;Prototypes;Clocks;Monitoring;Computers;Computer science;Energy usage visualization;energy usage monitoring;time-base visualizations;time-stack;time-pie},
doi={10.1109/iV.2015.17},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{7361163,
author={C. {Akasiadis} and K. {Panagidi} and N. {Panagiotou} and P. {Sernani} and A. {Morton} and I. A. {Vetsikas} and L. {Mavrouli} and K. {Goutsias}},
booktitle={2015 SAI Intelligent Systems Conference (IntelliSys)},
title={Incentives for rescheduling residential electricity consumption to promote renewable energy usage},
year={2015},
volume={},
number={},
pages={328-337},
abstract={Managing energy consumption and production is a challenging problem and proactive balancing between the amount of electricity produced and consumed is needed. In this work, we examine mechanisms that give incentives to consumers to efficiently reschedule their demand, thus balancing the overall energy production and consumption. Viewing the smart grid as a MAS, each agent represents a consumer; this agent takes into account its user's preferences and proposes an optimal energy consumption plan via a gamified GUI. To implement this we propose a distributed architecture through which we give the incentives (either economic, or social); we test a number of pricing mechanisms and we develop a very fast agent optimization strategy. We also present experiments both from software simulations on real data and pilot tests with human participants: the simulations allow to evaluate the mechanisms and agents, whilst the gamified tests are useful to assess the usability of the GUI and the usefulness of the agent suggestions. With human subjects, we evaluated which type of incentives is more compelling: economic or social. Results validate that by using our agent optimization approach the performance of the smart grid can be improved, and that specific mechanisms allow better utilization of renewable sources.},
keywords={digital simulation;energy consumption;graphical user interfaces;multi-agent systems;optimisation;power engineering computing;power generation scheduling;renewable energy sources;smart power grids;agent optimization approach;agent suggestions;software simulations;agent optimization strategy;pricing mechanisms;distributed architecture;gamified GUI;optimal energy consumption plan;MAS;smart grid;energy production;energy consumption;renewable energy usage;residential electricity consumption rescheduling incentives;Data visualization;Energy management;Games;Green products;Informatics;Telecommunications;Production;Demand-side Management;Serious Games;Multi-agent Systems},
doi={10.1109/IntelliSys.2015.7361163},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8107961,
author={M. {Masoodian} and I. {Buchwald} and S. {Luz} and E. {André}},
booktitle={2017 21st International Conference Information Visualisation (IV)},
title={Temporal Visualization of Energy Consumption Loads Using Time-Tone},
year={2017},
volume={},
number={},
pages={146-151},
abstract={Feedback plays an important role in assisting users to better understand their energy consumption behaviour. This is particularly true when users want to change their behaviour in order to reduce their energy consumption, and to manage their usage more effectively so as to avoid putting unnecessary load on energy providers. This paper presents the time-tone visualization, which aims to assist users by displaying variations in energy consumption by different categories of household devices over time, and their respective contributions to the total energy usage load. A user study conducted to compare time-tone against area-charts shows that although the two visualizations are comparable, time-tone is more effective for cases where there are large variations in energy usage loads.},
keywords={data visualisation;energy consumption;load management;temporal visualization;energy consumption loads;energy consumption behaviour;unnecessary load;energy providers;time-tone visualization;total energy usage load;household devices;Data visualization;Energy consumption;Brightness;Water heating;Image color analysis;Visualization;Prototypes;Energy usage visualizations;energy usage load;time-tone;area-charts;timelines;time-series;time-based data},
doi={10.1109/iV.2017.13},
ISSN={2375-0138},
month={July},}
@INPROCEEDINGS{6344595,
author={J. {Zhu} and E. {Zhuang} and C. {Ivanov} and Z. {Yao}},
booktitle={2012 IEEE Power and Energy Society General Meeting},
title={A data-driven approach to interactive visualization of power systems},
year={2012},
volume={},
number={},
pages={1-1},
abstract={Summary form only given. Information visualization appears to be a promising technique for improving the business practices in today's electric power industry. The legacy power system visualization tools, however, restrict the visualization process to follow a limited number of pre-defined patterns created by human designers, thus hindering users' ability to discover. This paper proposes a data-driven approach to interactive visualization of power systems. The proposed approach relies on developing powerful data manipulation algorithms to create visualizations based on the characteristics of empirically or mathematically derived data. Based on this approach, a data-driven model exploratory tool has been developed to enable users to visualize the power system's physical/electrical configurations at various levels and from different perspectives. The conducted case studies have demonstrated that the data-driven approach could result in an interactive and user-driven power system visualization tool that fosters scientific understanding and insight, therefore unleashing the power of visualization.},
keywords={data visualisation;electricity supply industry;power engineering computing;data-driven approach;power system interactive visualization process;information visualization;legacy power system visualization tools;data manipulation algorithms;user-driven power system visualization tool;electric power industry;Power systems;Data visualization;Business;Industries;Humans;Algorithm design and analysis;Mathematical model},
doi={10.1109/PESGM.2012.6344595},
ISSN={1944-9925},
month={July},}
@INPROCEEDINGS{8849061,
author={T. {Cerquitelli} and E. {Di Corso} and S. {Proto} and A. {Capozzoli} and D. {Mazzarelli} and A. {Nasso} and E. {Baralis} and M. {Mellia} and S. {Casagrande} and M. {Tamburini}},
booktitle={2019 International Conference on Smart Energy Systems and Technologies (SEST)},
title={Visualising high-resolution energy maps through the exploratory analysis of energy performance certificates},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper presents a new data mining engine, named EXTREMA (EXploitation of Turin high Resolution Energy MAps), to automatically visualise high-resolution energy maps exploring interesting and human-readable knowledge items from large collections of EPCs. EXTREMA, developed in Python, generates geo-located maps to summarise the main relationships among variables affecting the energy efficiency of buildings at different spatial granularity levels. The visualised knowledge is discovered through a two-level data analytics methodology based on exploratory and unsupervised algorithms. First an unsupervised algorithm divides EPCs into homogeneous groups of buildings with similar thermo-physical characteristics. Each group is then locally characterised through interesting patterns to concisely represent each group. The experimental evaluation, performed on a real dataset collected in a major Italian city in North-West Italy, demonstrates the effectiveness of EXTREMA in extracting and graphically display on geo-located multivariate energy maps a manageable set of human-readable knowledge items.},
keywords={building management systems;data analysis;data mining;data visualisation;energy conservation;geophysical image processing;image resolution;high-resolution energy maps;energy performance certificates;data mining engine;human-readable knowledge items;geo-located maps;visualised knowledge;two-level data analytics methodology;geo-located multivariate energy maps;unsupervised algorithm;spatial granularity levels;EXTREMA;exploitation of Turin high resolution energy maps;visualisation;energy efficiency;buildings;thermo-physical characteristics;Buildings;Data visualization;Energy consumption;Energy resolution;Urban areas;Clustering algorithms;Engines;Energy-related data;visualisation techniques;geo-located maps;cluster analysis;pattern discovery},
doi={10.1109/SEST.2019.8849061},
ISSN={},
month={Sep.},}
@ARTICLE{8017597,
author={L. E. {Matzen} and M. J. {Haass} and K. M. {Divis} and Z. {Wang} and A. T. {Wilson}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations},
year={2018},
volume={24},
number={1},
pages={563-573},
abstract={Evaluating the effectiveness of data visualizations is a challenging undertaking and often relies on one-off studies that test a visualization in the context of one specific task. Researchers across the fields of data science, visualization, and human-computer interaction are calling for foundational tools and principles that could be applied to assessing the effectiveness of data visualizations in a more rapid and generalizable manner. One possibility for such a tool is a model of visual saliency for data visualizations. Visual saliency models are typically based on the properties of the human visual cortex and predict which areas of a scene have visual features (e.g. color, luminance, edges) that are likely to draw a viewer's attention. While these models can accurately predict where viewers will look in a natural scene, they typically do not perform well for abstract data visualizations. In this paper, we discuss the reasons for the poor performance of existing saliency models when applied to data visualizations. We introduce the Data Visualization Saliency (DVS) model, a saliency model tailored to address some of these weaknesses, and we test the performance of the DVS model and existing saliency models by comparing the saliency maps produced by the models to eye tracking data obtained from human viewers. Finally, we describe how modified saliency models could be used as general tools for assessing the effectiveness of visualizations, including the strengths and weaknesses of this approach.},
keywords={computer vision;data visualisation;feature extraction;image colour analysis;natural scenes;neurophysiology;object detection;saliency maps;DVS model;data visualization saliency model;human visual cortex;visual saliency models;modified saliency models;eye tracking data;abstract data visualizations;visual features;Data visualization;Visualization;Measurement;Data models;Brain modeling;Predictive models;Tools;Visual saliency;evaluation;eye tracking},
doi={10.1109/TVCG.2017.2743939},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{5613467,
author={S. {Gerber} and P. {Bremer} and V. {Pascucci} and R. {Whitaker}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Visual Exploration of High Dimensional Scalar Functions},
year={2010},
volume={16},
number={6},
pages={1271-1280},
abstract={An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.},
keywords={computational geometry;curve fitting;data visualisation;image processing;scientific information systems;topology;visual exploration;high dimensional scalar function;scientific data analysis;system behavior;energy landscape;optimization problem;image data analysis;biological parameter;medical parameter;data set visualization;topological technique;geometric technique;interactive visualization;parameter space segmentation;Morse-Smale complex;geometric representation;dimension reduction;geometric property;regression curve;climate simulation;global energy flux;chemical species;UCI;machine learning repository;Crystals;Manifolds;Approximation methods;Data visualization;Kernel;Geometry;Concrete;Morse theory;High-dimensional visualization;Morse-Smale complex;Brain;Computer Graphics;Computer Simulation;Data Display;Data Interpretation, Statistical;Humans;Magnetic Resonance Imaging},
doi={10.1109/TVCG.2010.213},
ISSN={1941-0506},
month={Nov},}
@INPROCEEDINGS{7431052,
author={A. {Kimura} and S. {Tanaka} and T. {Sasaki}},
booktitle={2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)},
title={Visualization software for multiple data in radiation simulations},
year={2014},
volume={},
number={},
pages={1-4},
abstract={Radiation simulations have been widely used in high energy physics, nuclear physics, accelerator physics, medical science, and space science. The simulations generate particle trajectories and physical quantities in detectors, equipment or a human body. Therefore, visualization system has to process and draw complex and huge data in such simulations. We have been developing visualization software for multiple data generated by radiation simulations. Techniques of the computer visualization are introduced in explaining such multiple and complex data. The visualization software is capable of drawing multiple data such as particle trajectories, physical quantities, detectors, equipment, and a human body data in a simulation. In order to draw them, it has functions of rendering various dimensional data simultaneously, which are point, line, plane, and volume data. It is standalone software for Windows, MacOS X, and Linux.},
keywords={data visualisation;digital simulation;Linux;MacOS X;Windows;dimensional data;human body data;equipment;detector;complex data;multiple data;computer visualization;visualization system;physical quantity;particle trajectory;space science;medical science;accelerator physics;nuclear physics;high energy physics;radiation simulation;visualization software;Data visualization;Software;Data models;DICOM;Computational modeling;Physics},
doi={10.1109/NSSMIC.2014.7431052},
ISSN={},
month={Nov},}
@ARTICLE{7534744,
author={R. J. {Crouser} and L. {Franklin} and A. {Endert} and K. {Cook}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems},
year={2017},
volume={23},
number={1},
pages={121-130},
abstract={Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity.},
keywords={data visualisation;human computer interaction;human factors;human effort;human-machine collaboration;machine computation;user tasks modeling;hybrid visual analytic systems;human oracle model;sensemaking;cybersecurity;Genomics;Bioinformatics;Biological cells;Visualization;Animals;Vegetation;Education;Theoretical models;human oracle;visual analytics;mixed initiative systems;semantic interaction;sensemaking},
doi={10.1109/TVCG.2016.2598460},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{6307237,
author={J. {Xing} and W. {Liu} and Q. {Liu} and Y. {Shi}},
booktitle={2012 Asia-Pacific Power and Energy Engineering Conference},
title={GDI and OpenGL-Based Implementation of Visualization for the Grid Maintenance Planning Support System},
year={2012},
volume={},
number={},
pages={1-4},
abstract={Intelligent Dispatching is an important part of the Smart Grid. As an important means of human-computer interaction, visualization does not only provide a new solution ideas and implementation methods for the Intelligent Dispatching, but also makes it more humane and friendly. This paper illustrates the functional design, implementation methods and program logic in terms of the visual implementation of grid maintenance planning support system in detail, with the Drawing Package program and the Power Flow Animation program as examples described and proven. The method discussed herein has a strong versatility and maintainability for the current needs of smart grid development.},
keywords={application program interfaces;computer animation;data visualisation;human computer interaction;load dispatching;load flow;maintenance engineering;power engineering computing;power system planning;smart power grids;GDI;OpenGL-based implementation;visualization;grid maintenance planning support system;intelligent dispatching;human-computer interaction;program logic;drawing package program;power flow animation program;smart grid development;graphics device interface;Maintenance engineering;Load flow;Animation;Visualization;Data visualization;Substations},
doi={10.1109/APPEEC.2012.6307237},
ISSN={2157-4847},
month={March},}
@INPROCEEDINGS{6060315,
author={R. {Takashide} and Y. {Chigusa} and S. {Takahira}},
booktitle={SICE Annual Conference 2011},
title={Approaching the measurement about human behavior and environmental behavior by "Guideware". ∼Application possibility of “Guideware” ∼ (Report 1)},
year={2011},
volume={},
number={},
pages={2084-2089},
abstract={This study explores influences and impacts of time, location and environmental information, to decision-making process in human behavior (at offices and houses), and examines the methodology to determine occurrence factors of such decision-makings. The study also reveals how to compile the analyzed data efficiently, how to visualize the results, and how to provide feedback of the results to the decision-making persons. Additionally, ICT in agricultural industry is also evaluated as one of the potential application of this methodology.},
keywords={behavioural sciences computing;computerised instrumentation;data analysis;data visualisation;decision making;environmental science computing;human computer interaction;human behavior measurement;environmental behavior measurement;Guideware;decision-making process;data analysis;result visualization;ICT;agricultural industry;Humans;Energy consumption;Sensors;Data visualization;Decision making;Buildings;Temperature measurement;Semantic WEB;Augmented reality;Environment assessment;DB;Guideware},
doi={},
ISSN={},
month={Sep.},}
@ARTICLE{8395068,
author={S. {Bruckner} and T. {Isenberg} and T. {Ropinski} and A. {Wiebel}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={A Model of Spatial Directness in Interactive Visualization},
year={2019},
volume={25},
number={8},
pages={2514-2528},
abstract={We discuss the concept of directness in the context of spatial interaction with visualization. In particular, we propose a model that allows practitioners to analyze and describe the spatial directness of interaction techniques, ultimately to be able to better understand interaction issues that may affect usability. To reach these goals, we distinguish between different types of directness. Each type of directness depends on a particular mapping between different spaces, for which we consider the data space, the visualization space, the output space, the user space, the manipulation space, and the interaction space. In addition to the introduction of the model itself, we also show how to apply it to several real-world interaction scenarios in visualization, and thus discuss the resulting types of spatial directness, without recommending either more direct or more indirect interaction techniques. In particular, we will demonstrate descriptive and evaluative usage of the proposed model, and also briefly discuss its generative usage.},
keywords={data visualisation;interactive systems;user interfaces;data space;visualization space;spatial directness model;direct interaction techniques;spatial interaction;interactive visualization;more indirect interaction techniques;interaction space;manipulation space;user space;output space;Data visualization;Three-dimensional displays;Visualization;Object oriented modeling;Two dimensional displays;Rendering (computer graphics);Computational modeling;Visualization;direct interaction;human-computer interaction (HCI)},
doi={10.1109/TVCG.2018.2848906},
ISSN={1941-0506},
month={Aug},}
@ARTICLE{6280549,
author={Y. {Yang} and X. {Guo} and J. {Vick} and L. G. {Torres} and T. F. {Campbell}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Physics-Based Deformable Tongue Visualization},
year={2013},
volume={19},
number={5},
pages={811-823},
abstract={In this paper, a physics-based framework is presented to visualize the human tongue deformation. The tongue is modeled with the Finite Element Method (FEM) and driven by the motion capture data gathered during speech production. Several novel deformation visualization techniques are presented for in-depth data analysis and exploration. To reveal the hidden semantic information of the tongue deformation, we present a novel physics-based volume segmentation algorithm. This is accomplished by decomposing the tongue model into segments based on its deformation pattern with the computation of deformation subspaces and fitting the target deformation locally at each segment. In addition, the strain energy is utilized to provide an intuitive low-dimensional visualization for the high-dimensional sequential motion. Energy-interpolation-based morphing is also equipped to effectively highlight the subtle differences of the 3D deformed shapes without any visual occlusion. Our experimental results and analysis demonstrate the effectiveness of this framework. The proposed methods, though originally designed for the exploration of the tongue deformation, are also valid for general deformation analysis of other shapes.},
keywords={data analysis;data visualisation;deformation;finite element analysis;image segmentation;interpolation;speech processing;physics-based deformable tongue visualization;physics-based framework;human tongue deformation visualization;finite element method;FEM;motion capture data;speech production;deformation visualization techniques;in-depth data analysis;hidden semantic information;physics-based volume segmentation algorithm;deformation subspace computation;local target deformation;strain energy;intuitive low-dimensional visualization;high-dimensional sequential motion;energy interpolation-based morphing;3D deformed shapes;visual occlusion;Tongue;Sensors;Speech;Production;Shape;Deformable models;Visualization;Deformable model;tongue;finite element method;modal analysis;Algorithms;Biophysics;Computer Graphics;Computer Simulation;Elastic Modulus;Humans;Imaging, Three-Dimensional;Models, Biological;Movement;Reproducibility of Results;Sensitivity and Specificity;Speech;Tongue;Tongue;User-Computer Interface},
doi={10.1109/TVCG.2012.174},
ISSN={1941-0506},
month={May},}
@INPROCEEDINGS{7961559,
author={V. {Ferrer} and A. {Perdomo} and H. R. {Ali} and C. {Fies} and J. {Quarles}},
booktitle={2017 IEEE Virtual Reality Workshop on K-12 Embodied Learning through Virtual Augmented Reality (KELVAR)},
title={Virtual humans for temperature visualization in a tangible augmented reality educational game},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Our primary objective is to enable effective game based learning approaches in tangible augmented reality. In game based learning there is often a tradeoff in motivation between the educational aspects and game aspects. For example, consider our previous work - a tangible augmented reality application for passive solar energy education (AR-SEE), in which users learn about the science behind architectural design by interacting with a tangible model house and an augmented reality-based visualization of energy transfer within the house. This research extends AR-SEE to begin to convert this educational simulation into an effective educational game by introducing gaming elements, such as interactive virtual humans. Although it is known that AR-SEE does enable learning, it is unknown how the addition of interactive virtual humans will affect user perception of temperature data and learning. In this paper, the goal was to compare user perception of two approaches to temperature data visualization in in tangible augmented reality on mobile phones: (1) the current particle-based visualization (i.e., based on the science of energy transfer) and (2) novel virtual human-based visualizations. The game was intended for high school students. However, as a preliminary study, we conducted a user study with 27 3rd and 4th year architecture students that compared these two visualization approaches and their impact on temperature estimation, motivation, and perceived learning effectiveness. In the future, we plan to integrate this game into high school curricula.},
keywords={augmented reality;computer aided instruction;computer games;data visualisation;educational courses;educational institutions;human factors;mobile computing;virtual humans;temperature visualization;tangible augmented reality educational game;educational aspects;game aspects;educational simulation;mobile phones;particle-based visualization;virtual human-based visualizations;high school curricula;Estimation;Education;Cameras;Measurement;Solar energy;Heating systems;Augmented reality;education;visualization},
doi={10.1109/KELVAR.2017.7961559},
ISSN={},
month={March},}
@ARTICLE{8281629,
author={T. {Blascheck} and L. M. {Vermeulen} and J. {Vermeulen} and C. {Perin} and W. {Willett} and T. {Ertl} and S. {Carpendale}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Exploration Strategies for Discovery of Interactivity in Visualizations},
year={2019},
volume={25},
number={2},
pages={1407-1420},
abstract={We investigate how people discover the functionality of an interactive visualization that was designed for the general public. While interactive visualizations are increasingly available for public use, we still know little about how the general public discovers what they can do with these visualizations and what interactions are available. Developing a better understanding of this discovery process can help inform the design of visualizations for the general public, which in turn can help make data more accessible. To unpack this problem, we conducted a lab study in which participants were free to use their own methods to discover the functionality of a connected set of interactive visualizations of public energy data. We collected eye movement data and interaction logs as well as video and audio recordings. By analyzing this combined data, we extract exploration strategies that the participants employed to discover the functionality in these interactive visualizations. These exploration strategies illuminate possible design directions for improving the discoverability of a visualization's functionality.},
keywords={audio recording;data visualisation;eye;human computer interaction;interactive systems;public administration;interactive visualization;public energy data;interaction logs;exploration strategies;general public;design directions;Data visualization;Tools;Visualization;Audio recording;Indexes;Government;Bars;Discovery;visualization;open data;evaluation;eye tracking;interaction logs;think-aloud},
doi={10.1109/TVCG.2018.2802520},
ISSN={1941-0506},
month={Feb},}
@ARTICLE{7539643,
author={X. {Tong} and C. {Li} and H. {Shen}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization},
year={2017},
volume={23},
number={1},
pages={891-900},
abstract={Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.},
keywords={data visualisation;interactive systems;solid modelling;GlyphLens;view-dependent occlusion management;interactive glyph visualization;multivariate visualization technique;visual channels;3D volumetric dataset;2D surface;slicing plane;feature surface;3D spatial structure;view-dependent interactive 3D lens;space deformation models;lens shape models;spatial distributions;user-interested region;context information;display-interaction techniques;Lenses;Three-dimensional displays;Context;Data visualization;Shape;Probes;Visualization;View-dependent visualization;focus + context techniques;manipulation and deformation;glyph-based techniques;human-computer interaction},
doi={10.1109/TVCG.2016.2599049},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{8260303,
author={A. {Khoshrou} and A. B. {Dorsman} and E. J. {Pauwels}},
booktitle={2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)},
title={SVD-based visualisation and approximation for time series data in smart energy systems},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Many time series in smart energy systems exhibit two different timescales. On the one hand there are patterns linked to daily human activities. On the other hand, there are relatively slow trends linked to seasonal variations. In this paper we interpret these time series as matrices, to be visualized as images. This approach has two advantages: First of all, interpreting such time series as images enables one to visually integrate across the image and makes it therefore easier to spot subtle or faint features. Second, the matrix interpretation also grants elucidation of the underlying structure using well-established matrix decomposition methods. We will illustrate both these aspects for data obtained from the German day-ahead market.},
keywords={data visualisation;matrix decomposition;power engineering computing;power markets;singular value decomposition;smart power grids;time series;time series data;smart energy systems;matrix interpretation;SVD-based visualisation;matrix decomposition methods;German day-ahead market;Time series analysis;Matrix decomposition;Data visualization;Electronic mail;Market research;Renewable energy sources;Power system stability;Data analysis;Data preprocessing;Renewable energy sources;Smart grids;Time series analysis},
doi={10.1109/ISGTEurope.2017.8260303},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6758771,
author={D. S. {Ebert} and T. {Ertl} and K. {Gaither}},
booktitle={2014 47th Hawaii International Conference on System Sciences},
title={Introduction to Visualization and Analytics for Decision Support, Operational Management, and Scientific Discovery Minitrack},
year={2014},
volume={},
number={},
pages={1353-1353},
abstract={The topic of this minitrack will have applications in a broad range of situations where human expertise must be brought to bear on problems characterized by massive datasets and data that are uncertain in fact, relevance, location in space and position in time. Examples include environmental science and technologies, natural resources and energy, health and related life sciences, safety and security (aircraft safety, law enforcement, antiterrorism, disaster relief) and business processes. This year we focused on extending the areas of use to include a broader range of analytic tasks such as science and technology, public health, business intelligence, financial analysis, and other domains where interactive visualization systems may be used to improve human decision making.},
keywords={data visualisation;decision support systems;interactive systems;decision support visualization;decision support analytics;operational management;scientific discovery;human expertise;massive datasets;environmental science;natural resources;energy;related life sciences;security;aircraft safety;law enforcement;antiterrorism;disaster relief;business processes;science and technology;public health;business intelligence;financial analysis;interactive visualization systems;human decision making;Visual analytics;Educational institutions;Safety;Data visualization;Decision making},
doi={10.1109/HICSS.2014.174},
ISSN={1530-1605},
month={Jan},}
@ARTICLE{7539391,
author={C. {Bryan} and G. {Guterman} and K. {Ma} and H. {Lewin} and D. {Larkin} and J. {Kim} and J. {Ma} and M. {Farré}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution},
year={2017},
volume={23},
number={1},
pages={711-720},
abstract={Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.},
keywords={bioinformatics;biomedical education;computer aided instruction;computer animation;data visualisation;DNA;educational institutions;further education;genomics;teaching;synteny explorer;interactive visualization application;genome evolution teaching;homologous DNA;karyogram based approach;color design;animation design;system usability testing;biology faculty;genomic facult;bioinformatics visualization;undergraduate-level genome evolution education;Genomics;Bioinformatics;Biological cells;Visualization;Animals;Vegetation;Education;Bioinformatic visualization;education;learning;genome evolution;chromosome;user study;Animals;Chromosome Mapping;Computer Graphics;Genomics;Humans;Image Processing, Computer-Assisted;Phylogeny;Synteny;User-Computer Interface},
doi={10.1109/TVCG.2016.2598789},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{5701846,
author={R. M. {Rasli} and R. M. {Rasli} and N. M. {Norwawi}},
booktitle={2010 Second International Conference on Computational Intelligence, Modelling and Simulation},
title={Implementation of Information Visualization in Reservoir Application},
year={2010},
volume={},
number={},
pages={205-210},
abstract={Reservoir provides many benefits to human life generally and public society specifically. It leads to the generalization of energy, supplying and irrigating water for human use, hence improving human daily basis activities and fulfilling human needs. Yet, everything has its own weaknesses. As for the reservoir situation, there is a possibility of the operation to be failed and will leads to the creation of flood that is very harmful for the area of the reservoir. This research had been conducted with the implementation of information visualization, data mining and case based reasoning techniques in order to help the process of generating visualization result in opening or closing the gate of the dam to channel out excessive water. As a conclusion, the process of visualizing numerical values is proven to be faster than the normal process. Using visualization, people tend to make fewer mistakes for a large quantity of data. However, for upcoming time-being, it is advised that some methods of calculating the similarity of these visualize cases is implemented since visualization alone is still not enough to provide precise results.},
keywords={case-based reasoning;dams;data mining;data visualisation;floods;health and safety;irrigation;reservoirs;information visualization;reservoir;water irrigation;human needs;data mining;case based reasoning techniques;dam;Data visualization;Reservoirs;Data mining;Delta modulation;Logic gates;Humans;Visualization;Information visualization;data mining;case based reasoning;reservoir;Timah Tasoh Dam},
doi={10.1109/CIMSiM.2010.81},
ISSN={2166-8531},
month={Sep.},}
@INPROCEEDINGS{8521625,
author={R. {Athira} and V. V. {Nair} and R. {Sunitha}},
booktitle={2018 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)},
title={Fault Detection and Visualization Technique for Hybrid Electric Vehicle Components},
year={2018},
volume={},
number={},
pages={165-169},
abstract={The aim of the paper is to efficiently distinguish the abnormalities in huge datasets by employing different mechanisms like visualization techniques and algorithms. These methods classify faulty data from available test data and represent it visually. In data visualization human interpretation is required to detect abnormalities while the algorithm classifies faulty and healthy data using rule-based algorithms. The parallel coordinates plot is developed in MATLAB. Fault diagnosis in Permanent Magnet Synchronous Motor (PMSM) was done by means of pattern recognition algorithm based on the Concordia transform. The algorithm is simulated in MATLAB with original vehicle test data. The proposed fault detection algorithm holds good for analysis of variable speed and variable torque drives.},
keywords={data visualisation;fault diagnosis;hybrid electric vehicles;knowledge based systems;motor drives;pattern classification;permanent magnet motors;power engineering computing;synchronous motors;torque;transforms;fault diagnosis;pattern recognition algorithm;MATLAB;fault detection algorithm;visualization technique;hybrid electric vehicle components;rule-based algorithms;parallel coordinates plot;permanent magnet synchronous motor;vehicle test data;faulty data classification;data visualization;Concordia transform;variable speed;variable torque drives;Transforms;Switches;Fault detection;Stators;Data visualization;Classification algorithms;Inverters;datavisualization;parallel-coordinates;PMSM;concordia transform},
doi={10.1109/ICPECTS.2018.8521625},
ISSN={},
month={Feb},}
@INPROCEEDINGS{7004342,
author={G. {Stavropoulos} and S. {Krinidis} and D. {Ioannidis} and K. {Moustakas} and D. {Tzovaras}},
booktitle={2014 IEEE International Conference on Big Data (Big Data)},
title={A building performance evaluation visualization system},
year={2014},
volume={},
number={},
pages={1077-1085},
abstract={A novel big data building performance evaluation knowledge processing and mining system utilizing visual analytics is going to be presented in this paper. A large dataset comprised of building information, energy consumption, environmental measurements, human presence and behavior and business processes is going to be exploited for the building performance evaluation. Building performance evaluation is one of the most important factors in engineering that leads to building renovation and construction with low energy consumption and gas emissions in conjunction with comfort, utility and durability. For this purpose, business processes occurring in the building are correlated with the energy consumption and the human flows in the spatiotemporal domain modeling the dynamic behavior of the building. These models lead to the extraction of useful semantic information and the detection of spatiotemporal patterns that are important for the evaluation of the building performance. Furthermore, a number of novel visual analytics techniques allow the end-users to process data in different temporal resolutions and with different temporal filters, assisting them to detect patterns that may be difficult to be detected otherwise. The proposed visual analytics techniques support design and energy management decisions by visualizing the building measurements regarding business and comfort aspects. To do so, the proposed system includes a variety of techniques and components, properly selected to offer quick identification of focal points and evaluation of the building performance. Considering the increasing interest and the green building goals of almost all world governments including EU, the suggested methodology and application could be rendered a very useful tool for the Architecture and Engineering Community working on Building Performance Simulation and Analysis, and all related communities in Architect, Engineering and Construction (AEC) industry.},
keywords={buildings (structures);data mining;data visualisation;design engineering;energy consumption;structural engineering computing;visualization system;big data building performance evaluation;knowledge mining system;visual analytics;building information;energy consumption;environmental measurement;building renovation;building construction;gas emission;durability;spatiotemporal domain modeling;semantic information;energy management;green building;Buildings;Energy consumption;Data visualization;Data mining;Energy measurement;Sensors;Business;Visual analytics;knowledge mining;building measurements;environmental measurements;business processes},
doi={10.1109/BigData.2014.7004342},
ISSN={},
month={Oct},}
@ARTICLE{9109317,
author={A. B. {Birchfield} and T. J. {Overbye}},
journal={IEEE Open Access Journal of Power and Energy},
title={Mosaic Packing to Visualize Large-Scale Electric Grid Data},
year={2020},
volume={7},
number={},
pages={212-221},
abstract={For large power systems, a continual challenge is to display wide-area data in a way that maximizes human users' situational awareness. This paper describes a new visualization technique that draws a mosaic of colored tiles to represent multiple data fields for electric grid objects, arranged to preserve geographic context. The key problem in creating these diagrams is packing the tiles onto the display space, minimizing the total displacement while forbidding overlaps. This paper formulates that problem and presents a horizontal-packing algorithm which is able to produce a feasible, quality solution at an interactive time scale. Illustrative examples are shown for using mosaics to monitor wide-area generator status and dispatch, bus voltages, and line and transformer limits. Mosaics can be customized in numerous ways to show different aspects of the system state, providing for human users a simultaneous sense of the wide-area summary, regional trends, and prominent outliers.},
keywords={data visualisation;power engineering computing;power grids;mosaic packing;wide-area summary;system state;generator dispatch;wide-area generator status;interactive time scale;quality solution;feasible solution;horizontal-packing algorithm;total displacement;display space;geographic context;electric grid objects;multiple data fields;colored tiles;visualization technique;human users;wide-area data;continual challenge;power systems;large-scale electric grid data;Data visualization;Power systems;Fuels;Open Access;Generators;Licenses;Image color analysis;Power system visualization;mosaic displays;wide-area data visualization;packing problem},
doi={10.1109/OAJPE.2020.3000464},
ISSN={2687-7910},
month={},}
@INPROCEEDINGS{6883045,
author={T. {Carção}},
booktitle={2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
title={Measuring and visualizing energy consumption within software code},
year={2014},
volume={},
number={},
pages={181-182},
abstract={The authors have begun to witness an exponential growth in the information and communication technologies (ICT) sector. While undoubtedly a milestone, all of this occurs at the expense of high energy costs needed to supply servers, data centers, and any use of computers. Associated with these high energy costs is the emission of greenhouse gases. These two issues have become major problems in society. The ICT sector contributes up to 8% of the overall energy consumption, with 50% of the energy costs of an organization being attributed to the IT departments.The paper discusses a tool which applies the proposed techniques on software code. This tool would guide the developer into programming more energy-aware software by alerting him/her of red smells, and offering green refactorings, all this in a simple visual layout to allow the software developer to become energy-aware. This application will also provide the ability to navigate between less energy efficient areas (packages, classes, modules, functions, methods, blocks and even lines), making its implementation more energy efficient.},
keywords={data visualisation;energy conservation;power aware computing;software engineering;energy consumption visualization;energy consumption measurement;software code;information and communication technologies;ICT sector growth;energy costs;greenhouse gas emission;energy consumption;energy-aware software;green refactorings;Software;Green products;Visualization;Energy consumption;Energy measurement;Hardware;Catalogs},
doi={10.1109/VLHCC.2014.6883045},
ISSN={1943-6106},
month={July},}
@INPROCEEDINGS{8823763,
author={D. A. B. {Hyde} and T. R. {Hall} and J. {Caers}},
booktitle={2018 IEEE Scientific Visualization Conference (SciVis)},
title={VRGE: An Immersive Visualization Application for the Geosciences},
year={2018},
volume={},
number={},
pages={1-5},
abstract={The rapid onset of inexpensive, portable virtual reality (VR) devices has created opportunities for scientific visualization tools that harness this new, immersive modality. Researchers in the geological sciences, in particular those focused on earth resources (energy, water, minerals), are faced with significant challenges in building and understanding increasingly complex geological models. In this paper, we address these joint opportunities by introducing the Virtual Reality Geomodeling Environment (VRGE): a scientific visualization tool leveraging the Oculus Rift VR system, specialized for users involved in geological modeling. VRGE offers a number of features for viewing and interacting with geological models in VR, including human-centric navigation and manipulation, implicit surface editing, visual conditioning, and uncertainty analysis. Moreover, we examine how the design of VRGE meets current needs of the earth resources industry, in the context of reviewing the state-of-the-art, conducting an expert survey, and discussing performance.},
keywords={data visualisation;geophysics computing;virtual reality;geological modeling;VRGE;visual conditioning;earth resources industry;immersive visualization application;scientific visualization tool;immersive modality;geological sciences;complex geological models;virtual reality geomodeling environment;virtual reality devices;surface editing;Oculus rift VR system;uncertainty analysis;human-centric navigation;Geology;Solid modeling;Three-dimensional displays;Data models;Uncertainty;Data visualization;Virtual reality;Virtual reality;scientific visualization;geological modeling;implicit surfaces},
doi={10.1109/SciVis.2018.8823763},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6945168,
author={A. {Foncubierta-Rodríguez} and A. {Widmer} and A. {Depeursinge} and H. {Müller}},
booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Enhanced visualization of pulmonary perfusion in 4D Dual Energy CT images},
year={2014},
volume={},
number={},
pages={6710-6713},
abstract={Pulmonary embolism (PE) affects up to 600,000 patients and contributes to at least 100,000 deaths every year in the United States alone. Diagnosis of PE can be difficult as most symptoms are unspecific. Computed Tomography (CT) angiography is the reference for diagnosing PE. CT angiography produces grayscale images with darker areas representing any mass filling defects, making the analysis of the images difficult. This article demonstrates a method using the combination of energy levels in Dual Energy CT images to highlight the presence of PE in the lung. The results show that pairing different energy levels from 40 to 140 keV can increase the contrast between well perfused areas and underperfused areas of the lung. In addition, the visualization used in the current study complies with the window/level settings usually employed by radiologists.},
keywords={computerised tomography;data visualisation;diseases;image enhancement;lung;medical image processing;radiologists;window/level settings;underperfused areas;well perfused areas;contrast;lung;energy levels;mass filling defects;darker areas;grayscale images;CT angiography;Computed Tomography angiography;PE diagnosis;pulmonary embolism;4D Dual Energy CT images;pulmonary perfusion;enhanced visualization;electron volt energy 40 keV to 140 keV;Energy states;Computed tomography;Lungs;Image color analysis;Indexes;Brain modeling;Materials;Angiography;Contrast Media;Four-Dimensional Computed Tomography;Humans;Lung;Perfusion;Pulmonary Embolism;Sensitivity and Specificity},
doi={10.1109/EMBC.2014.6945168},
ISSN={1558-4615},
month={Aug},}
@ARTICLE{7539331,
author={P. {Hermosilla} and J. {Estrada} and V. {Guallar} and T. {Ropinski} and À. {Vinacua} and P. {Vázquez}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Physics-Based Visual Characterization of Molecular Interaction Forces},
year={2017},
volume={23},
number={1},
pages={731-740},
abstract={Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.},
keywords={biotechnology;chemical engineering computing;data visualisation;design engineering;molecular dynamics method;Monte Carlo methods;pharmaceutical technology;physics-based visual characterization;molecular interaction forces;molecular simulations;biotechnology;enzyme engineering;automatic computational protocols;human comprehension;visualization algorithms;intermolecular contacts;molecular docking;energy functions;interaction forces;molecule-ligand distance;energy function;molecular dynamics;Monte Carlo simulations;time-dependent visualizations;particle resolutions;domain experts;enzyme design process;drug design process;Visualization;Three-dimensional displays;Computational modeling;Two dimensional displays;Proteins;Drugs;Data visualization;Molecular visualization;binding analysis},
doi={10.1109/TVCG.2016.2598825},
ISSN={1941-0506},
month={Jan},}
@INPROCEEDINGS{6502550,
author={G. {Ghidini} and S. K. {Das} and V. {Gupta}},
booktitle={2012 IEEE 9th International Conference on Mobile Ad-Hoc and Sensor Systems (MASS 2012)},
title={Fuseviz: A framework for web-based data fusion and visualization in smart environments},
year={2012},
volume={},
number={},
pages={468-472},
abstract={Recent advances in technology and algorithms for smart environments have made it possible to collect and store large amounts of data about many aspects of human life and the surrounding environment with limited effort and cost. However, such data become useful to lay users with no background in data analysis only if they are presented in a fashion that supports intuitive interaction to spot the patterns and trends, thus transforming the data into valuable information. In this paper, we introduce FuseViz, a framework for Web-based fusion and visualization of data in smart environments. FuseViz addresses the challenges posed by large, live, heterogeneous, and dynamic data streams from autonomous data sources, and lay users, with two basic features: fusion and visualization. CouchDB, a schemaless database with a ReSTful API and MapReduce support, is used to fuse data streams from multiple sources, while Web-based visualization is implemented on top of D3, a JavaScript library for manipulation of data-driven documents. We demonstrate the capabilities of FuseViz with E2Home, a case study application for energy-efficient smart home environments. We show how the precise information provided by E2Home can help the user easily improve the home energy efficiency by more than 10%.},
keywords={application program interfaces;data visualisation;database management systems;home computing;Internet;Java;sensor fusion;FuseViz;Web-based data fusion;data visualization;smart environments;human life;dynamic data streams;autonomous data sources;CouchDB;schemaless database;ReSTful API;MapReduce support;JavaScript library;data-driven documents;energy-efficient smart home environments;E2Home;home energy efficiency;data visualization;data fusion;smart environments;MapReduce;CouchDB;D3},
doi={10.1109/MASS.2012.6502550},
ISSN={2155-6814},
month={Oct},}
@ARTICLE{9117084,
author={A. {Bares} and D. F. {Keefe} and F. {Samsel}},
journal={IEEE Computer Graphics and Applications},
title={Close Reading for Visualization Evaluation},
year={2020},
volume={40},
number={4},
pages={84-95},
abstract={Visualizations produced by collaborations between artists, scientists, and visualization experts lay claim to being not only more effective in delivering information but also more effective in their abilities to elicit qualities like human connection. However, as prior work in the visualization community has demonstrated, it is difficult to evaluate these claims because characteristics associated with human connection are not easily measured quantitatively. In this Visualization Viewpoints piece, we address this problem in the context of our work to develop methods of evaluating visualizations created by Sculpting Visualization, a multidisciplinary project that incorporates art and design theory and practice into the process of scientific visualization. We present the design and results of a study in which we used close reading, a formal methodology used by humanities scholars, as a way to test reactions and analyses from evaluation participants related to an image created using Sculpting Visualization. In addition to specific suggestions about how to improve future iterations of the visualization, we discuss key findings of the evaluation related to contextual information, visual perspective, and associations that individual viewers brought to bear on their experience with the visualization.},
keywords={art;data visualisation;Visualization Viewpoints piece;design theory;scientific visualization;humanities scholars;evaluation participants;visualization evaluation;visualization experts;visualization community;sculpting visualization;Visualization;Data visualization;Art;Tools;Vocabulary;Climate change;Task analysis},
doi={10.1109/MCG.2020.2993889},
ISSN={1558-1756},
month={July},}
@ARTICLE{6276243,
author={Y. {Jeon} and J. {Won} and S. {Yoon}},
journal={IEEE Transactions on Biomedical Engineering},
title={Massively Parallel Energy Space Exploration for Uncluttered Visualization of Vascular Structures},
year={2013},
volume={60},
number={1},
pages={240-244},
abstract={Images captured using computed tomography and magnetic resonance angiography are used in the examination of the abdominal aorta and its branches. The examination of all clinically relevant branches simultaneously in a single 2-D image without any misleading overlaps facilitates the diagnosis of vascular abnormalities. This problem is called uncluttered single-image visualization (USIV). We can solve the USIV problem by assigning energy-based scores to visualization candidates and then finding the candidate that optimizes the score; this approach is similar to the manner in which the protein side-chain placement problem has been solved. To obtain near-optimum images, we need to explore the energy space extensively, which is often time consuming. This paper describes a method for exploring the energy space in a massively parallel fashion using graphics processing units. According to our experiments, in which we used 30 images obtained from five patients, the proposed method can reduce the total visualization time substantially. We believe that the proposed method can make a significant contribution to the effective visualization of abdominal vascular structures and precise diagnosis of related abnormalities.},
keywords={biomedical MRI;computerised tomography;data visualisation;medical disorders;medical image processing;proteins;massively parallel energy space exploration;uncluttered visualization;vascular structure;computed tomography;magnetic resonance angiography;abdominal aorta;vascular abnormalities diagnosis;USIV problem;protein side chain placement problem;Graphics processing unit;Optimization;Visualization;Instruction sets;Message systems;Libraries;Measurement;Abdominal aorta;energy-space exploration;GPGPU;parallelization;single-image visualization;Algorithms;Aorta, Abdominal;Aorta, Abdominal;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Angiography;Models, Cardiovascular;Tomography, X-Ray Computed},
doi={10.1109/TBME.2012.2214386},
ISSN={1558-2531},
month={Jan},}
@INPROCEEDINGS{8609816,
author={J. C. {Lorenzana-Gerardo} and J. L. {Díaz-Reséndiz} and E. A. {Rivas-Araiza}},
booktitle={2018 IEEE International Conference on Automation/XXIII Congress of the Chilean Association of Automatic Control (ICA-ACCA)},
title={IoT based robust electrical energy monitoring system with Programmable Logic Controller},
year={2018},
volume={},
number={},
pages={1-6},
abstract={This paper develops an energy monitoring system with IoT integration. The platform used is based in a programmable logic controller (PLC) s7-1200 connected to a distributed power monitoring module through profinet interface. PLC is a robust and reliable solution for distributed power monitoring and enables IoT integration by using the embedded webserver functionality. In Spite of their excellent webserver capabilities, data management and human to machine interface (HMI) are limited. For this reason, a single board computer (SBC) is used in order to enhance their capabilities, providing data base management and improved data visualization. In this work, the practical aspects of both hardware and software are discussed. Results obtained by the platform are compared with a power quality analyzer.},
keywords={computerised monitoring;data acquisition;data visualisation;database management systems;file servers;Internet;Internet of Things;man-machine systems;microcomputers;power engineering computing;power supply quality;programmable controllers;IoT integration;data management;machine interface;data base management;data visualization;power quality analyzer;robust electrical energy monitoring system;programmable logic controller;profinet interface;embedded webserver;distributed power monitoring;human-to-machine interface;HMI;single board computer;Monitoring;Biomedical monitoring;Artificial intelligence;Meters;Software;Portals;Manuals;PLC;Intelligent Building;Energy Monitoring System;SCADA},
doi={10.1109/ICA-ACCA.2018.8609816},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8430362,
author={A. {Leoni} and V. {Stornelli} and G. {Ferri} and V. {Errico} and M. {Ricci} and A. {Pallotti} and G. {Saggio}},
booktitle={2018 14th Conference on Ph.D. Research in Microelectronics and Electronics (PRIME)},
title={A human body powered sensory glove system based on multisource energy harvester},
year={2018},
volume={},
number={},
pages={113-116},
abstract={In this work we present and evaluate a multi-source power management system, based on human body energy harvesting, to extend the battery lasting of an electronic sensory glove, used to measure flexion/extension, abduction/adduction movements of fingers of the hand. The system exploits heat of the human forearm and pressure impressed by the foot heel during walking, so to gather additional energy. The aim is to allow hours of energy-autonomy for the user working with the sensory glove. Such a glove is equipped with a number of flex sensors which furnish data from finger movements, acquired and pre-processed by a microcontroller, and wireless sent to a Personal Computer for analysis, visualization and storage purposes. The multi-source harvester is based on vibrational and thermic sources. Prototype discrete element boards were designed and tested for the microelectronics integration. Measurement results demonstrate how the overall system extends the battery lasting time up to 20%.},
keywords={body sensor networks;data gloves;energy harvesting;power engineering computing;human body powered sensory glove system;battery lasting time;thermic sources;vibrational sources;multisource harvester;visualization;finger movements;foot heel;human forearm;flexion/extension;electronic sensory glove;human body energy harvesting;multisource power management system;multisource energy harvester;Energy harvesting;power management;Sensory glove},
doi={10.1109/PRIME.2018.8430362},
ISSN={},
month={July},}
@INPROCEEDINGS{8390171,
author={P. {Grandhe} and S. R. {Edara} and V. {Devara}},
booktitle={2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS)},
title={Adaptive ROI search for 3D visualization of MRI medical images},
year={2017},
volume={},
number={},
pages={3785-3788},
abstract={To smooth the progress of high point study of medical image data in research and in clinical medical environment, a covering for the 3D toolkit is developed to overcome the drawback of searching mechanism in medical images. The main aim of this application is to develop a scalable search engine for the three dimensional medical images. User can choose a Region of Interest (ROI) and repeatedly detect the equivalent region among all the return images. Magnetic resonance imaging (MRI) is an extremely developed medical imaging method used to extract information about the human soft tissue structure. So we propose a new algorithm, namely Cluster Based Image Search and Retrieve-CBISR is randomly reduce searching time and provide accuracy result for MRI Images.},
keywords={biological tissues;biomedical MRI;data visualisation;image retrieval;image segmentation;medical image processing;search engines;stereo image processing;adaptive ROI search;MRI medical images;medical image data;clinical medical environment;magnetic resonance imaging;MRI Images;search engine;three dimensional medical images;3D visualization;cluster based image search;retrieve-CBISR;region of interest;3D toolkit;Magnetic resonance imaging;Biomedical imaging;Three-dimensional displays;Tumors;Data analysis;Image segmentation;Clustering algorithms;Cluster Based Image Search and Retrieve (CBISR);Medical Imaging;Image retrieval;Region of Interest (ROI)},
doi={10.1109/ICECDS.2017.8390171},
ISSN={},
month={Aug},}
@ARTICLE{7153545,
author={T. J. {Tsai} and A. {Stolcke} and M. {Slaney}},
journal={IEEE Transactions on Multimedia},
title={A Study of Multimodal Addressee Detection in Human-Human-Computer Interaction},
year={2015},
volume={17},
number={9},
pages={1550-1561},
abstract={The goal of addressee detection is to answer the question , “Are you talking to me?” When a dialogue system interacts with multiple users, it is crucial to detect when a user is speaking to the system as opposed to another person. We study this problem in a multimodal scenario, using lexical, acoustic, visual, dialogue state, and beamforming information. Using data from a multiparty dialogue system, we quantify the benefits of using multiple modalities over using a single modality. We also assess the relative importance of the various modalities, as well as of key individual features, in estimating the addressee. We find that energy-based acoustic features are by far the most important, that information from speech recognition and system state is useful as well, and that visual and beamforming features provide little additional benefit. While we find that head pose is affected by whom the speaker is addressing, it yields little nonredundant information due to the system acting as a situational attractor. Our findings would be relevant to multiparty, open-world dialogue systems in which the agent plays an active, conversational role, such as an interactive assistant deployed in a public, open space. For these scenarios , our study suggests that acoustic, lexical, and system-state information is an effective and practical combination of modalities to use for addressee detection. We also consider how our analyses might be affected by the ongoing development of more realistic, natural dialogue systems.},
keywords={array signal processing;audio user interfaces;human computer interaction;interactive systems;speaker recognition;multimodal addressee detection;human-human-computer interaction;multimodal scenario;lexical state;acoustic state;visual state;dialogue state;beamforming information;multiple modalities;energy-based acoustic features;speech recognition;visual features;beamforming features;head pose;multiparty open-world dialogue systems;active conversational role;interactive assistant;Computers;Face;Speech;Computational modeling;Feature extraction;Acoustics;Visualization;Addressee detection;beamforming;dialogue system;head pose;human-human-computer;multimodal;multiparty;prosody;speech recognition},
doi={10.1109/TMM.2015.2454332},
ISSN={1941-0077},
month={Sep.},}
@INPROCEEDINGS{8397404,
author={E. {Dubois} and F. {Pittarello}},
booktitle={2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)},
title={Designing the engaging energy-box: Bridging the gap between energy control systems and users' energy awareness},
year={2017},
volume={},
number={},
pages={1-6},
abstract={This work describes a design experience focused on the theme of eco-feedback, a technology complementary to traditional energy control systems and meant to obtain additional savings by increasing the awareness of the users about the factors that determine energy consumption. This experience, held during a multidisciplinary ideation workshop and involving students and researchers at the University of Toulouse, was focused on the conceptual design of an Energy-Box, conceived as an artefact (or a set of artefacts) for making people inhabiting the University campus aware of energy issues and leading them to more energy conscious lifestyles. Three different proposals stemmed from this experience, that were evaluated first by the participants to the workshop themselves and then, some months later, by 80 undergraduate students of the University of Venice working on the same themes. We extracted interesting lesson learned from this evaluation, that should be taken into account for the development of user's centred eco-feedback systems in public contexts.},
keywords={educational administrative data processing;energy conservation;energy consumption;human factors;user centred design;engaging energy-box;design experience;traditional energy control systems;energy consumption;multidisciplinary ideation workshop;University campus aware;energy conscious lifestyles;undergraduate students;user centred eco-feedback system;University of Venice;Energy consumption;Prototypes;Control systems;Monitoring;Buildings;Data visualization;Proposals;control system;eco-feedback;prototyping;sketching},
doi={10.1109/UIC-ATC.2017.8397404},
ISSN={},
month={Aug},}
@ARTICLE{8624523,
author={J. {Cai} and W. {Hao} and W. {Chen} and Y. {Guo} and S. {Tang} and R. {Wen} and L. {Pan} and J. {Fan}},
journal={IEEE Access},
title={The Effect of Light Distribution of LED Luminaire on Human Ocular Physiological Characteristics},
year={2019},
volume={7},
number={},
pages={28478-28486},
abstract={Light-emitting Diode (LED) has been considered as one of the new generation lighting sources with several merits such as high efficiency, high reliability, long lifespan, high-speed response, and energy saving. The optical performances of an LED luminaire, such as illuminance, luminance, correlated color temperature, and spectra power distribution, determine the lighting environment which can affect the human ocular physiological characteristics. To investigate the effect of optical performances on human vision, previous studies have assessed the subjective perception based on questionnaires. In this paper, we propose a novel method based on the aberrations and accommodations data from 150 human factor measurements on a total of 25 participants. The results show that: 1) optical performances of the LED luminaire have an influence on ocular physiological characteristics during the visual task duration, which can be quantized by the variations of physiological parameters; 2) the desk illuminance and light distribution curve are selected in this study as the optical parameters. The variations of ocular physiological characteristics reach the minimum values when the desk illuminance is 550 lux and the light distribution curve is large beam angle; and 3) ocular physiological characteristics are more sensitive to the light spatial distribution compared to the light quality. Thus, the proposed assessment method based on variations of ocular physiological characteristics in this paper is promising as one of the guidelines for the design and optimization of the LED luminaires.},
keywords={human factors;light emitting diodes;light sources;vision;optical performances;LED luminaire;spectra power distribution;lighting environment;human ocular physiological characteristics;human vision;physiological parameters;desk illuminance;light distribution curve;optical parameters;light spatial distribution;light quality;lighting sources;light-emitting diode;human factor measurements;correlated color temperature;Lighting;Physiology;Visualization;Atmospheric measurements;Particle measurements;Fatigue;Light emitting diodes;LED luminaire;optical performance;human vision;ocular physiological characteristics;lighting environment assessment},
doi={10.1109/ACCESS.2019.2893914},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7313335,
author={N. {Petrovska} and A. {Stevanovic}},
booktitle={2015 IEEE 18th International Conference on Intelligent Transportation Systems},
title={Traffic Congestion Analysis Visualisation Tool},
year={2015},
volume={},
number={},
pages={1489-1494},
abstract={The rapid growth of urban population and numbers of private cars in this modern era, results in increasingly urgent transportation problem in cities throughout the world. Road traffic congestion is an omnipresent problem, which leads to delays, time loss, human stress, energy consumption, environmental pollution e.c.t. In order to decrease traffic congestion, there is a need for simulating and optimizing traffic control and improving traffic management. There are different ways for traffic congestion monitoring and analysis such as using video monitoring and surveillance systems, or static and dynamic sensors which allow traffic management in real time. There are also other methods using non real time analysis where traf?c congestion can be extracted from historical patterns of traf?c congestion. The historical patterns can be gained from the stored travel time and speed data. The goal of enhancing driver convenience is achieved by providing applications based on road traffic condition that mainly identifies congestion status. This paper presents a web application which uses live traffic congestion data from Google Maps traffic layer for real time congestion calculation. A technique utilized for estimating the level of congestion is image processing. The main objective is to provide an automated and yet interactive visualization tool for congestion analysis in real time. The aim is reducing the traffic congestion on roads which will lead to decrease in the number of accidents. It can provide important data which can help road traffic management. Thus, it is mainly dedicated to traffic managers, operators and analysts. Nevertheless it can be implemented also by road users. Unlike most sensor based applications, it makes quantified congestion data available even in regions with limited traffic data information.},
keywords={data visualisation;delays;energy consumption;geographic information systems;interactive systems;pollution control;real-time systems;road traffic control;traffic congestion analysis visualisation tool;urban population;private cars;urgent transportation problem;road traffic congestion;delays;time loss;human stress;energy consumption;environmental pollution;traffic control;historical patterns;Google Maps traffic layer;real time congestion calculation;interactive visualization tool;road traffic management;Roads;Google;Data visualization;Real-time systems;Vehicles;Sensors;Image color analysis;Road Traffic Congestion;Google Maps Traffic Layer;Visualization;Image Processing},
doi={10.1109/ITSC.2015.243},
ISSN={2153-0017},
month={Sep.},}
@INPROCEEDINGS{8938274,
author={V. {Rao} and M. {Singh} and P. {Mohapatra}},
booktitle={2019 IEEE 1st International Conference on Energy, Systems and Information Processing (ICESIP)},
title={SmartAIR: Smart energy efficient framework for large network of air quality monitoring systems},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Live street-level air quality monitoring is important application of sensor networks. Such application reveals human exposure to hazardous air pollutants. It assists general public, army troops, environment agencies and the Government in decision-making every day. Live data visualization and data fusion plays crucial role in presenting pollution updates effectively for end-users. We propose efficient interactive, live data visualization in our application. Our application efficiently renders pollution data fast in under 10ms. Users will be instantly aware of pollution levels in their desired location. Continuous data-logging at data centers from large-scale of sensor networks poses major challenges. We use policy based network management technique to reduce unwanted data-logging requests. We implement novel policies in identifying and rejecting numerous unwanted requests at data centers. Each data-logging involves computationally expensive database operations and with our policy specification we were able to cut down expensive operations significantly ( ≥ 83% reduction, especially in denser regions like traffic congested roads). Finally, we implement Lazy load scheme to make our application more energy efficient. With this scheme we save data and battery in end-users device over longer periods of time. We conducted several real-life trials and we observed negligible mobile data consumption ( ≤ 1MB for 1 - hour). Similarly, we observed negligible power consumption ( ≤ 4 % in 1- hour run) in end-users device. Our implementation of novel policies and schemes provide real-life benefits to data centers and end-users. Our end-users experience better, faster and lively pollution updates. Our data centers experience relatively lesser network load and less computation overheads on scaling up.},
keywords={air pollution control;computer centres;data visualisation;energy conservation;environmental monitoring (geophysics);environmental science computing;power consumption;road traffic;sensor fusion;telecommunication network management;telecommunication power management;wireless sensor networks;smart energy efficient framework;air quality monitoring systems;live street-level air quality monitoring;sensor networks;hazardous air pollutants;data fusion;efficient interactive data visualization;live data visualization;pollution data;pollution levels;continuous data-logging;data centers;policy based network management technique;unwanted data-logging requests;battery;end-users device;negligible mobile data consumption;lively pollution updates;relatively lesser network load;time 10.0 ms;memory size 1.0 MByte;Data visualization;Monitoring;Databases;Air pollution;Servers;Google;Sensor Networks;Large scale;Lazy load},
doi={10.1109/ICESIP46348.2019.8938274},
ISSN={},
month={July},}
@INPROCEEDINGS{6557837,
author={M. J. {Stokmaier} and A. G. {Class} and T. {Schulenberg}},
booktitle={2013 IEEE Congress on Evolutionary Computation},
title={A hard optimisation test function with symbolic solution visualisation for fast interpretation by the human eye},
year={2013},
volume={},
number={},
pages={2251-2258},
abstract={We propose a class of test problems for evaluating the performance of global function optimisers based on finding an optimal spatial distribution of nonidentical particles interacting with two different potential fields. Because of the possibility of intuitive solution visualisation it can be of particular benefit during development of optimisation algorithms. An ensemble of N particles is constrained to a low-dimensional space and each particle contributes in two ways to the total potential energy: by its position on a hilly track and through repulsive neighbour potentials. The task of minimising the ensemble's total potential energy corresponds to searching an N-dimensional space with many local minima separated through higher and lower barriers; hence, it can serve as a performance measure for evolutionary algorithms (EA). The search difficulty is scalable through the number of particles and the hilliness of the track. In particular, if the particles are made nonidentical by giving them different masses or charges, the search will become very challenging because of the introduced combinatorial aspect and the “curse of dimensionality”. Among many similarly challenging optimisation problems this test function class has the advantage that solution candidates can be plotted in ways which allow humans to estimate not only relative objective function values but also DNA vector relations upon a quick glance. For the EA developer this allows a fast feedback cycle between a modification to the EA and the observed change in optimisation history behaviour. This makes experimentation with EA elements at a fundamental level easier. Furthermore, this class of real-domain search offers a wide range of difficulty and complexity levels and can be split up into a two-objective optimisation.},
keywords={data visualisation;evolutionary computation;minimisation;search problems;hard optimisation test function;symbolic solution visualisation;fast interpretation;human eye;performance evaluation;global function optimisers;optimal spatial distribution;spatial nonidentical particle distribution;potential fields;optimisation algorithms;low-dimensional space;ensemble total potential energy minimisation;N-dimensional space search;local minima;performance measure;evolutionary algorithms;curse of dimensionality;fast feedback cycle;DNA vector relations;EA modification;real-domain search;two-objective optimisation;Optimization;Visualization;DNA;Linear programming;Vectors;Search problems;Lenses},
doi={10.1109/CEC.2013.6557837},
ISSN={1941-0026},
month={June},}
@INPROCEEDINGS{8711230,
author={T. {Luo} and K. {Chen} and M. {Liu} and K. {Sun} and J. {Xu} and Z. {Pan}},
booktitle={2018 International Conference on Virtual Reality and Visualization (ICVRV)},
title={Design and Implementation of Interactive VR Campus Roaming System},
year={2018},
volume={},
number={},
pages={122-123},
abstract={Virtual reality technology can be widely used in all aspects of virtual, and there are multiple successful cases. Jinan University was used as a research object in this project. The customers' natural requirements of spatial authenticity were analyzed in term of the natural guidance theory model, safety, comfort, motivation, and interaction efficiency in the VR campus experience. The Unity3D platform and the latest natural human-computer interaction technology were employed during the creation. By using the HTC Vive helmets and handles, we can collect human body data and scene motion data to drive virtual roaming actions, which can manipulate human motion behavior and allow virtual players to roam across land, water, and air, pick up rubbish to increase campus environmental protection values, make shots, play football, swim, and fight against negative campus energy with weapons. Tests have shown that the system is easy to use and widely praised by users.},
keywords={human computer interaction;solid modelling;virtual reality;human body data;scene motion data;virtual roaming actions;human motion behavior;virtual players;campus environmental protection values;negative campus energy;interactive VR campus roaming system;virtual reality technology;multiple successful cases;Jinan University;customers;spatial authenticity;natural guidance theory model;interaction efficiency;VR campus experience;Unity3D platform;natural human-computer interaction technology;Virtual reality;Visualization;virtual reality;real-time roaming;texture mapping;natural orientation;somatosensory interaction},
doi={10.1109/ICVRV.2018.00036},
ISSN={2375-141X},
month={Oct},}
@INPROCEEDINGS{7299363,
author={R. {Richer} and T. {Maiwald} and C. {Pasluosta} and B. {Hensel} and B. M. {Eskofier}},
booktitle={2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN)},
title={Novel human computer interaction principles for cardiac feedback using google glass and Android wear},
year={2015},
volume={},
number={},
pages={1-6},
abstract={This work presents a system for unobtrusive cardiac feedback in daily life. It addresses the whole pipeline from data acquisition over data processing to data visualization including wearable integration. ECG signals are recorded with a novel ECG sensor supporting Bluetooth Low Energy, which is able to transmit raw ECG data as well as estimated heart rate. ECG signals are processed in real-time on a mobile device to automatically classify the user's heart beats. A novel application for Android-based mobile devices was developed for data visualization. It offers several modes for cardiac feedback, from measuring the current heart rate to continuously monitoring the user's heart status. It also allows to store acquired data in an internal database as well as in the Google Fit platform. Further, the application provides extensions for wearables like Google Glass and smartwatches running on Android Wear. Hardware performance evaluation was performed by comparing the course of heart rate between the novel ECG sensor and a commercial ECG sensor. The mean absolute error between the two sensors was 4.83 bpm with a standard deviation of 4.46 bpm, and a Pearson correlation of 0.922. A qualitative evaluation was performed for the Android application with special emphasis on the daily usability and the wearable integration. When the Google Glass was integrated, the subjects rated the application as 2.8/5 (0 = Bad, 5 = Excellent), whereas when the application was integrated with a smartwatch the rating increased to 4.2/5.},
keywords={bioelectric potentials;Bluetooth;body sensor networks;data acquisition;data visualisation;electrocardiography;human computer interaction;medical signal detection;medical signal processing;signal classification;smart phones;statistical analysis;telemedicine;Pearson correlation;ECG sensor;hardware performance evaluation;smartwatches;Android-based mobile devices;automatic heart beat classification;real-time ECG signal processing;heart rate estimation;Bluetooth;wearable integration;data visualization;data processing;data acquisition;unobtrusive cardiac feedback;Android wear;Google glass;human computer interaction principles;Google;Electrocardiography;Glass;Biomedical monitoring;Androids;Humanoid robots;Heart rate;Body Sensor Networks;Electrocardiography;Wearable Computing;Android Application;Human Computer Interaction},
doi={10.1109/BSN.2015.7299363},
ISSN={2376-8894},
month={June},}
@INPROCEEDINGS{6981650,
author={T. {Sugiura} and S. {Nakatsuka} and J. {Yu} and Y. {Takeuchi} and M. {Imai}},
booktitle={2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings},
title={An efficient data compression method for artificial vision systems and its low energy implementation using ASIP technology},
year={2014},
volume={},
number={},
pages={81-84},
abstract={This paper proposes an efficient data compression method for artificial vision systems based on visual cortex stimulation. These systems require wireless communication between inside and outside of human body, which consumes large amount of energy for data transmission. In order to reduce the energy consumption, efficient and less power consuming data compression method is required. The proposed method takes advantage of the appearance frequency of stimulation data pattern. Experimental results show that the proposed compression method achieves more than 81% of data compression rate, and energy reduction ratios by an application specific instruction-set processor implementation is 85% in compression and 36% in decompression compared to its base processor, respectively.},
keywords={biomedical communication;computer vision;data compression;energy consumption;neurophysiology;ASIP technology;efficient data compression method;artificial vision systems;visual cortex stimulation;wireless communication;human body;data transmission;energy consumption;power consuming data compression method;data pattern;energy reduction ratios;specific instruction-set processor;Visualization;Data compression;Machine vision;Encoding;Registers;Energy consumption;Retina},
doi={10.1109/BioCAS.2014.6981650},
ISSN={2163-4025},
month={Oct},}
@INPROCEEDINGS{8227573,
author={C. {Snyder} and J. B. {Christen} and H. M. {Ross}},
booktitle={2017 IEEE Healthcare Innovations and Point of Care Technologies (HI-POCT)},
title={Human factors engineering for mobile health applications},
year={2017},
volume={},
number={},
pages={14-17},
abstract={Childhood asthma has effectively doubled since 1980 and currently affects about 8% of the U.S. childhood population. Efficiently analyzing quality of air data, which would ultimately improve the information available to parents with children suffering from asthma, is crucial to reduce the likelihood of a serious attack. In order to accomplish this task, the use of low-cost, wearable, environmental sensors contribute to construct a live “air-care” pollution map. Creating an alpha prototype application to gauge how well participants interact with and interpret healthcare information utilizing a “Wizard of Oz” paradigm becomes an important component in the research.},
keywords={air pollution;data analysis;diseases;health care;human factors;medical information systems;mobile computing;paediatrics;human factors engineering;mobile health applications;childhood asthma;childhood population;wearable sensors;environmental sensors;live air-care pollution map;alpha prototype application;healthcare information;air quality data analysis;Wizard of Oz paradigm;Respiratory system;Pediatrics;Gases;Sensors;Visualization;Image color analysis;Prototypes},
doi={10.1109/HIC.2017.8227573},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8699216,
author={P. {Knierim} and F. {Kiss} and A. {Schmidt}},
booktitle={2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
title={Look Inside: Understanding Thermal Flux Through Augmented Reality},
year={2018},
volume={},
number={},
pages={170-171},
abstract={The transition from high school to university is an exciting time for students including many new challenges. Particularly in the field of science, technology, engineering, and mathematics, the university dropout rate may reach up to 40%. The studies of physics rely on many abstract concepts and quantities that are not directly visible like energy or heat. We developed a mixed reality application for education, which augments the thermal conduction of metal by overlaying a representation of temperature as false-color visualization directly onto the object. This real-time augmentation avoids attention split and overcomes the perception gap by amplifying the human eye. Augmented and Virtual Reality environments allow students to perform experiments that were impossible to conduct for security or financial reasons. With the application, we try to foster a deeper understanding of the learning material and higher engagement during the studies.},
keywords={augmented reality;computer aided instruction;data visualisation;engineering education;physics computing;thermal flux;high school;university dropout rate;mixed reality application;false-color visualization;real-time augmentation;attention split;perception gap;augmented reality environment;virtual reality environment;science technology engineering mathematics field;learning material;Augmented reality;Data visualization;Physics;Prototypes;Heating systems;Real-time systems;H.5.m [Information Interfaces and Presentation]: Miscellaneous},
doi={10.1109/ISMAR-Adjunct.2018.00059},
ISSN={},
month={Oct},}
@ARTICLE{7536106,
author={A. {Dasgupta} and J. {Lee} and R. {Wilson} and R. A. {Lafrance} and N. {Cramer} and K. {Cook} and S. {Payne}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Familiarity Vs Trust: A Comparative Study of Domain Scientists' Trust in Visual Analytics and Conventional Analysis Methods},
year={2017},
volume={23},
number={1},
pages={271-280},
abstract={Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.},
keywords={data analysis;data mining;data visualisation;statistics;trusted computing;domain scientist trust;visual analytics;conventional analysis;interactive visualization;statistics;data mining;data-driven discovery;mixed-initiative systems;evidence gathering;decision-making;transparent analysis process;trust-augmented design;Visual analytics;Data visualization;Biology;Uncertainty;Data analysis;Bioinformatics;trust;transparency;familiarity;uncertainty;biological data analysis},
doi={10.1109/TVCG.2016.2598544},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{8390704,
author={C. {Lu}},
journal={IEEE Transactions on Human-Machine Systems},
title={IoT-Enabled Adaptive Context-Aware and Playful Cyber-Physical System for Everyday Energy Savings},
year={2018},
volume={48},
number={4},
pages={380-391},
abstract={Home energy savings via eco-feedback is often considered a serious, tedious, or even distracting task due to the need for frequent human intervention. In addition, most existing eco-feedback systems focus on providing energy usage information and ignore the users' contexts. This may render the systems incapable of capturing the users' changes when proenvironmental behaviors have been encouraged. To address this, our study leverages Internet of Things (IoT) enabled technologies to realize an adaptive, context-aware, and playful cyber-physical system (CPS) for everyday energy savings with the hope of facilitating collaboration between a person and a smart energy-saving (ES) system to the greatest extent possible. To leverage the benefits inherent in a CPS, bidirectionally interactive information visualization integrated with pet-raising gamification was incorporated into the adaptive CPS. This synchronized the information from the user's physical environment with its counterpart in the pet's virtual environment. In order to provide flexible services, all IoT devices were agentized to form reconfigurable agents. In our experimental evaluation, this bidirectional mapping empowered users to flexibly control remote appliances anywhere and anytime in a more natural way, which enabled users to embed interactions with the ES CPS into their daily routine. Furthermore, improvements to system adaptability (33% in precision; 21% in recall) along with the reconfigurable ES services (additionally saving energy about 16.21%) show the potential of the CPS to enhance the users' experience and prolong the users' engagement in everyday energy savings.},
keywords={behavioural sciences computing;computer games;data visualisation;domestic appliances;home automation;Internet;Internet of Things;home energy savings;energy usage information;smart energy-saving system;bidirectionally interactive information visualization;adaptive CPS;ES CPS;system adaptability;IoT-enabled adaptive context-aware;cyber-physical system;Internet of Things enabled technologies;flexibly control remote appliances;user experience;user engagement;pet-raising gamification;Sensors;Internet of Things;Adaptive systems;Cyber-physical systems;Visualization;Biological system modeling;Actuators;Adaptation;context-awareness;cyber-physical system (CPS);energy savings;gamification-based eco-automation (mixed reality);Internet of Things (IoT)},
doi={10.1109/THMS.2018.2844119},
ISSN={2168-2305},
month={Aug},}
@ARTICLE{8369345,
author={J. {Sreevalsan-Nair} and A. {Jindal} and B. {Kumari}},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
title={Contour Extraction in Buildings in Airborne LiDAR Point Clouds Using Multiscale Local Geometric Descriptors and Visual Analytics},
year={2018},
volume={11},
number={7},
pages={2320-2335},
abstract={Topographic Light Detection and Ranging (LiDAR) captures geometric information of the topography of a geographical region, often using airborne platforms. The research and practice of analysis of point clouds acquired using LiDAR is more recent in comparison to that of LiDAR imagery. Point clouds are unstructured datasets, where its geometric or structural classification labels the constituent points as belonging to line-, surface-, or point-type features. We focus on line-type features in the LiDAR point clouds of urban residential areas, which enables extraction of building outlines. We use a multiscale local geometric descriptor (LGD), computed using tensor voting and gradient energy tensor to enhance specific line-type features, e.g., gable roofs. Given that LGDs are positive-semidefinite second-order tensors, we propose a tensor-based data analytic workflow for extraction of boundaries in building roofs using the LGD. We use the tensor representation of the LGD to extract “tensorlines,” which are then postprocessed for extracting feature lines of the building roofs. Our proposed workflow provides the flexibility to the human-in-the-loop for exploration of point clouds for roof boundary tracing for selected buildings. We demonstrate the workflow for a two-plane gable roof.},
keywords={airborne radar;data visualisation;feature extraction;geophysical image processing;optical radar;topography (Earth);geometric information;topographic light detection and ranging;LiDAR imagery;airborne platforms;airborne LiDAR point clouds;contour extraction;feature lines;building roofs;tensor-based data analytic workflow;specific line-type features;gradient energy tensor;tensor voting;LGD;multiscale local geometric descriptor;building outlines;point-type features;structural classification;geometric classification;Three-dimensional displays;Laser radar;Feature extraction;Buildings;Tensile stress;Data visualization;Data mining;Contour extraction;gradient energy tensor;LiDAR point clouds;structure tensor;tensor voting;tensorlines},
doi={10.1109/JSTARS.2018.2833801},
ISSN={2151-1535},
month={July},}
@INPROCEEDINGS{5937383,
author={E. {Noyes} and L. {Deligiannidis}},
booktitle={2011 4th International Conference on Human System Interactions, HSI 2011},
title={Emergent: A knowledge discovery tool for understanding emerging industry structure},
year={2011},
volume={},
number={},
pages={305-310},
abstract={This paper presents a visual analytics tool to understand the emergence and structure of the nanotechnology industry. According to the U.S. National Science Foundation (NSF), the global nanotechnology industry is expected to grow to $1 trillion in 2010 and drive dramatic innovation and wealth creation in industries as diverse as energy, computing and biotechnology. Nanotech entrepreneurs, analysts and investors alike need tools to understand the emerging structure of the industry because firm competitive positions in the industry impact ventures' survival, growth and profitability. Particularly, nanotech ventures compete from different initial “strategic footprints” in the industry which ease or complicate entry into new growth businesses. In fact, the emergence of the nanotechnology industry is the story of interweaving with-and penetration into-different adjoining industries. Exploiting the world's largest database on consumer-focused nanotechnology products, this paper demonstrates a visual analytics tool, Emergent, that can show the emerging structure of the industry and ventures' varying strategic footprints within this forming multi-industry terrain. The tool is interactive, scalable, and adaptable to relational data from other industries. Business applications of Emergent include industry analysis, strategic planning and entrepreneurial opportunity identification.},
keywords={data mining;data visualisation;nanotechnology;strategic planning;knowledge discovery tool;emerging industry structure understanding;visual analytics tool;nanotechnology industry;strategic footprints;Emergent;strategic planning;entrepreneurial opportunity identification;Industries;Nanotechnology;Commercialization;Business;Visualization;Automotive engineering;Data visualization;information visualization;network visualization;visual analytics;entrepreneurship;industry evolution;innovation},
doi={10.1109/HSI.2011.5937383},
ISSN={2158-2254},
month={May},}
@INPROCEEDINGS{6307688,
author={X. {Zhang} and Q. {Zhu} and Z. {Zhang} and Z. {Zhu}},
booktitle={2012 Asia-Pacific Power and Energy Engineering Conference},
title={Study on the Coordinated Multi-View Technology of EMS},
year={2012},
volume={},
number={},
pages={1-4},
abstract={Multi-view technology, especially multi-screen display is widely used in Human-Computer Interface (HCI) of Energy Management System (EMS). This paper analyzes the necessity of multi-view in EMS through the presentation method and the functions. On this condition, the typical coordination patterns of multi-view in EMS are introduced. Moreover, the coordination pattern of the correlated multi-screen display and the coordinated multi-view is proposed and studied. The coordination pattern is instrumental in improving EMS interactive capabilities. The multi-screen based on adaptive mechanism is also disused.},
keywords={brain-computer interfaces;energy management systems;power engineering computing;screens (display);coordinated multiview technology;EMS;human-computer interface;HCI;energy management system;coordination pattern;adaptive mechanism-based multiscreen display;Collaboration;Energy management;Human computer interaction;Data visualization;Power systems;Monitoring;Visualization},
doi={10.1109/APPEEC.2012.6307688},
ISSN={2157-4847},
month={March},}
@INPROCEEDINGS{7273415,
author={P. {Khawsa-Ard} and C. {Aswakul}},
booktitle={2015 IEEE 39th Annual Computer Software and Applications Conference},
title={IEEE1888 Interactive Display as a Service (IDaaS): Example in Building Energy Management System},
year={2015},
volume={3},
number={},
pages={517-522},
abstract={In this paper, a new architecture of Interactive Display as a Service or IDaaS has been introduced and implemented as the application component in the open framework of IEEE1888 standard. The purpose is to integrate the interactive visualisation with natural human gesture controls and the back-end cloud enabled by the IEEE1888 data storage component and IEEE1888 FETCH/WRITE methods. The IDaaS architecture utilises Processing language as the interactive visualisation software platform and Microsoft Kinect as the gesture sensor. Measures of IDaaS effectiveness have been defined, namely, the number of hand swipes made by control users, the canvas numbers selected by control users, and the accumulated number of users waking up the IDaaS display. As an example proof of concept, IDaaS system has been deployed for the building energy management system scenario. Five canvases have been developed for the IDaaS display, namely, EE health pad, energy game, EE information and alarm & alert as well as a photo collection display implemented as a screen saver. Reported results herein highlight possible usage of IDaaS effectiveness measures to compare installation locations and displaying canvases quantitatively. And hence IDaaS is expectedly useful for interactive public data dissemination hot spots to raise people awareness on common issues of societal concern or for information advertising purposes.},
keywords={building management systems;cloud computing;data visualisation;display devices;gesture recognition;image segmentation;information dissemination;interactive systems;IEEE1888 interactive display as a service;building energy management system;application component;natural human gesture controls;back-end cloud;IEEE1888 data storage component;IEEE1888 FETCH-WRITE methods;processing language;interactive visualisation software platform;Microsoft Kinect;gesture sensor;IDaaS display;EE health pad;energy game;EE information;photo collection display;screen saver;installation locations;displaying canvases;interactive public data dissemination hot spots;people awareness;societal concern;information advertising purposes;Floors;Games;Computer architecture;Data visualization;Standards;Skeleton;Interactive Display as a Service;IEEE1888;building energy management system;gesture sensor},
doi={10.1109/COMPSAC.2015.262},
ISSN={0730-3157},
month={July},}
@ARTICLE{6226392,
author={L. {Zheng} and Y. {Wu} and K. {Ma}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Perceptually-Based Depth-Ordering Enhancement for Direct Volume Rendering},
year={2013},
volume={19},
number={3},
pages={446-459},
abstract={Visualizing complex volume data usually renders selected parts of the volume semitransparently to see inner structures of the volume or provide a context. This presents a challenge for volume rendering methods to produce images with unambiguous depth-ordering perception. Existing methods use visual cues such as halos and shadows to enhance depth perception. Along with other limitations, these methods introduce redundant information and require additional overhead. This paper presents a new approach to enhancing depth-ordering perception of volume rendered images without using additional visual cues. We set up an energy function based on quantitative perception models to measure the quality of the images in terms of the effectiveness of depth-ordering and transparency perception as well as the faithfulness of the information revealed. Guided by the function, we use a conjugate gradient method to iteratively and judiciously enhance the results. Our method can complement existing systems for enhancing volume rendering results. The experimental results demonstrate the usefulness and effectiveness of our approach.},
keywords={conjugate gradient methods;data visualisation;rendering (computer graphics);perceptually based depth ordering enhancement;direct volume rendering;visualizing complex volume data;energy function;volume rendered images;quantitative perception models;transparency perception;conjugate gradient method;Rendering (computer graphics);Junctions;Image color analysis;Transfer functions;Visualization;Optimization;Solid modeling;Volume rendering;depth ordering;depth perception;transparency;visualization;Algorithms;Computer Graphics;Depth Perception;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;User-Computer Interface},
doi={10.1109/TVCG.2012.144},
ISSN={1941-0506},
month={March},}
@INPROCEEDINGS{7061028,
author={ {Jeungmin Oh} and U. {Lee}},
booktitle={2015 Eighth International Conference on Mobile Computing and Ubiquitous Networking (ICMU)},
title={Exploring UX issues in Quantified Self technologies},
year={2015},
volume={},
number={},
pages={53-59},
abstract={The Quantified Self is a movement that promotes the use of technology for self-tracking various kinds of personal information, such as physical activities and energy consumption. In this paper, we study the user reviews of quantified self tools, as reported on a quantified self community website. We perform a content analysis to categorize tracking tools, and to explore user experience (UX) issues related to quantified self technologies. From this analysis, we find various tracking categories, including body state (e.g., physical and physiological), psychological state and traits, activities (e.g., exercise, eating, sleep), social interactions, and environmental and property states. Furthermore, we find the key UX issues associated with quantified self technologies, which include data controllability, data integration, data accuracy, data visualization, input complexity, sharing/privacy, design/aesthetics, and engagement. The UX issues reported in this paper have significant implications for the design of quantified self technologies.},
keywords={behavioural sciences computing;data integration;data visualisation;human computer interaction;information analysis;mobile computing;wearable computers;Web sites;input complexity;data visualization;data accuracy;data integration;data controllability;Quantified Self community Web site;Quantified Self tool;user experience;UX;Data visualization;Google;Communities;Data integration;Mood;Twitter},
doi={10.1109/ICMU.2015.7061028},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8638195,
author={A. R. {Ajayan} and F. {Al-Doghman} and Z. {Chaczko}},
booktitle={2018 26th International Conference on Systems Engineering (ICSEng)},
title={Visualizing Multimodal Big Data Anomaly Patterns in Higher-Order Feature Spaces},
year={2018},
volume={},
number={},
pages={1-9},
abstract={The world today, as we know it, is profuse with information about humans and objects. Datasets generated by cyber-physical systems are orders of magnitude larger than their current information processing capabilities. Tapping into these big data flows to uncover much deeper perceptions into the functioning, operational logic and smartness levels attainable has been investigated for quite a while. Knowledge Discovery & Representation capabilities across mutiple modalities holds much scope in this direction, with regards to their information holding potential. This paper investigates the applicability of an arithmetic tool Tensor Decompositions and Factorizations in this scenario. Higher order datasets are decomposed for Anomaly Pattern capture which encases intelligence along multiple modes of data flow. Preliminary investigations based on data derived from Smart Grid Smart City Project are compliant with our hypothesis. The results proved that Abnormal patterns detected in decomposed Tensor factors encompass deep information energy content from Big Data as efficiently as other Pattern Extraction and Knowledge Discovery frameworks, while salvaging time and resources.},
keywords={Big Data;cyber-physical systems;data analysis;data mining;data visualisation;feature extraction;knowledge representation;matrix decomposition;tensors;higher-order feature spaces;objects;cyber-physical systems;tensor decompositions;pattern extraction;knowledge discovery;knowledge representation;multimodal Big Data anomaly pattern visualization;anomaly pattern capture;Big Data;Data visualization;Data mining;Market research;Feature extraction;Ecosystems;Multimodality;Big Data Processing;Knowledge Representations;Intelligent systems;Multimodal Big Data;Spatio-Temporal dependencies;Feature annotations.},
doi={10.1109/ICSENG.2018.8638195},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7058084,
author={A. {Ridi} and C. {Gisler} and J. {Hennebert}},
booktitle={2014 International Conference on Data Science and Advanced Analytics (DSAA)},
title={Appliance and state recognition using Hidden Markov Models},
year={2014},
volume={},
number={},
pages={270-276},
abstract={We asset about the analysis of electrical appliance consumption signatures for the identification task. We apply Hidden Markov Models to appliance signatures for the identification of their category and of the most probable sequence of states. The electrical signatures are measured at low frequency (10-1 Hz) and are sourced from a specific database. We follow two predefined protocols for providing comparable results. Recovering information on the actual appliance state permits to potentially adopt energy saving measures, as switching off stand-by appliances or, generally speaking, changing their state. Moreover, in most of the cases appliance states are related to user activities: the user interaction usually involves a transition of the appliance state. Information about the state transition could be useful in Smart Home / Building Systems to reduce energy consumption and increase human comfort.We report the results of the classification tasks in terms of confusion matrices and accuracy rates. Finally, we present our application for a real-time data visualization and the recognition of the appliance category with its actual state.},
keywords={data visualisation;domestic appliances;energy conservation;hidden Markov models;home automation;state recognition;hidden Markov models;appliance recognition;electrical appliance consumption signatures;identification task;electrical signatures;energy saving measures;stand-by appliances;appliance states;user activities;user interaction;smart home-building systems;energy consumption reduction;human comfort;confusion matrices;real-time data visualization;appliance category recognition;Home appliances;Hidden Markov models;Protocols;Accuracy;Computational modeling;Databases;Monitoring;Intrusive Load Monitoring (ILM);Appliance Identification;Appliance State Recognition},
doi={10.1109/DSAA.2014.7058084},
ISSN={},
month={Oct},}
@ARTICLE{8805443,
author={J. {Zhao} and M. {Karimzadeh} and L. S. {Snyder} and C. {Surakitbanharn} and Z. C. {Qian} and D. S. {Ebert}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={MetricsVis: A Visual Analytics System for Evaluating Employee Performance in Public Safety Agencies},
year={2020},
volume={26},
number={1},
pages={1193-1203},
abstract={Evaluating employee performance in organizations with varying workloads and tasks is challenging. Specifically, it is important to understand how quantitative measurements of employee achievements relate to supervisor expectations, what the main drivers of good performance are, and how to combine these complex and flexible performance evaluation metrics into an accurate portrayal of organizational performance in order to identify shortcomings and improve overall productivity. To facilitate this process, we summarize common organizational performance analyses into four visual exploration task categories. Additionally, we develop MetricsVis, a visual analytics system composed of multiple coordinated views to support the dynamic evaluation and comparison of individual, team, and organizational performance in public safety organizations. MetricsVis provides four primary visual components to expedite performance evaluation: (1) a priority adjustment view to support direct manipulation on evaluation metrics; (2) a reorderable performance matrix to demonstrate the details of individual employees; (3) a group performance view that highlights aggregate performance and individual contributions for each group; and (4) a projection view illustrating employees with similar specialties to facilitate shift assignments and training. We demonstrate the usability of our framework with two case studies from medium-sized law enforcement agencies and highlight its broader applicability to other domains.},
keywords={business data processing;data analysis;data visualisation;human resource management;organisational aspects;personnel;organizational performance analyses;dynamic evaluation;multiple coordinated views;visual exploration task categories;flexible performance evaluation metrics;complex performance evaluation metrics;employee achievements;public safety agencies;employee performance;visual analytics system;group performance view;individual employees;reorderable performance matrix;priority adjustment view;MetricsVis;public safety organizations;Organizations;Task analysis;Data visualization;Performance evaluation;Visual analytics;Organizational performance analysis;multi-dimensional data;hierarchical relationships;visual analytics},
doi={10.1109/TVCG.2019.2934603},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{7865902,
author={C. {Ahlstrom} and K. {Kircher}},
journal={IEEE Transactions on Intelligent Transportation Systems},
title={A Generalized Method to Extract Visual Time-Sharing Sequences From Naturalistic Driving Data},
year={2017},
volume={18},
number={11},
pages={2929-2938},
abstract={Indicators based on visual time-sharing have been used to investigate drivers' visual behaviour during additional task execution. However, visual time-sharing analyses have been restricted to additional tasks with well-defined temporal start and end points and a dedicated visual target area. We introduce a method to automatically extract visual time-sharing sequences directly from eye tracking data. This facilitates investigations of systems, providing continuous information without well-defined start and end points. Furthermore, it becomes possible to investigate time-sharing behavior with other types of glance targets such as the mirrors. Time-sharing sequences are here extracted based on between-glance durations. If glances to a particular target are separated by less than a time-based threshold value, we assume that they belong to the same information intake event. Our results indicate that a 4-s threshold is appropriate. Examples derived from 12 drivers (about 100 hours of eye tracking data), collected in an on-road investigation of an in-vehicle information system, are provided to illustrate sequence-based analyses. This includes the possibility to investigate human-machine interface designs based on the number of glances in the extracted sequences, and to increase the legibility of transition matrices by deriving them from time-sharing sequences instead of single glances. More object-oriented glance behavior analyses, based on additional sensor and information fusion, are identified as the next future step. This would enable automated extraction of time-sharing sequences not only for targets fixed in the vehicle's coordinate system, but also for environmental and traffic targets that move independently of the driver's vehicle.},
keywords={data visualisation;driver information systems;feature extraction;human computer interaction;road traffic;traffic engineering computing;user interfaces;time-based threshold value;eye tracking data;glance behavior analyses;visual time-sharing sequence extraction;driver visual behaviour;naturalistic driving data;in-vehicle information system;human-machine interface designs;transition matrices;Visualization;Vehicles;Gaze tracking;Roads;Data mining;Mirrors;Uncertainty;Driver behaviour;glance analysis;visual time-sharing},
doi={10.1109/TITS.2017.2658945},
ISSN={1558-0016},
month={Nov},}
@INPROCEEDINGS{6945175,
author={M. {Mueller-Holtz} and H. {Seker} and G. {Smith}},
booktitle={2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Wavelet denoising and reconstruction of a microneedle embedded in human skin ex-vivo using terahertz pulsed reflectance},
year={2014},
volume={},
number={},
pages={6740-6743},
abstract={Biological tissue can show promising features in the terahertz region of the electro-magnetic spectrum but face the problem that the signal to noise ratio can be poor due to the low energy output from the measurement instrument coupled with the high absorbance of water in biological tissue. Wavelet denoising and reconstruction are known to be suitable digital signal processing filters for reflected terahertz energy when appropriate thresholds, scales and mother-wavelets are chosen. In this article, we therefore describe a Wavelet transform-based method for denoising reflections of THz energy from ex-vivo human skin with an embedded microneedle. The wavelet reconstruction was then successfully used to identify the microneedle from the reflected waveform. This technique is potentially useful to enhance in-depth analysis and visualisation of underlying skin layers, lesions and penetration depth for targeted drug delivery.},
keywords={data visualisation;drug delivery systems;image denoising;image reconstruction;medical image processing;needles;skin;terahertz wave imaging;wavelet transforms;targeted drug delivery;penetration depth;lesions;skin layer visualisation;in-depth analysis;reflected waveform;embedded microneedle;ex-vivo human skin;THz energy;reflection denoising;wavelet transform-based method;mother-wavelets;reflected terahertz energy;digital signal processing filters;wavelet reconstruction;water;measurement instrument;low energy output;signal to noise ratio;electro-magnetic spectrum;terahertz region;biological tissue;terahertz pulsed reflectance;wavelet denoising;Algorithms;Histological Techniques;Humans;Signal Processing, Computer-Assisted;Signal-To-Noise Ratio;Skin;Wavelet Analysis},
doi={10.1109/EMBC.2014.6945175},
ISSN={1558-4615},
month={Aug},}
@INPROCEEDINGS{7591800,
author={X. {Li} and H. {Huang} and Y. {Sun}},
booktitle={2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
title={TriboWalk: Triboelectric dual functional wireless system for gait monitoring and energy harvesting},
year={2016},
volume={},
number={},
pages={4796-4799},
abstract={In this paper, we report the design and validation of a novel wearable wireless system, TriboWalk, for gait monitoring and motion energy harvesting based on triboelectrification. Gait analysis is an important diagnostic method for medical rehabilitation. The TriboWalk system is capable of gait monitoring and analysis by capturing gait timing parameters and ground contact force (GCF) pattern based on four tribo-elements on each shoe sole. The tribo-elements are removable and easily placed on different shoes. A visualization tool is also developed for data analysis. The tribo-elements can generate high output voltage over 20 V during random and low frequency motion, acting as good motion energy harvesters. The experiments were conducted with normal and fast walking speed. The results showed that the TriboWalk system can provide dual functions of gait monitoring and energy harvesting, enabling remote monitoring of patients in daily life at very low cost.},
keywords={biomedical communication;biomedical equipment;data analysis;data visualisation;energy harvesting;gait analysis;medical computing;patient monitoring;triboelectricity;wearable computers;wireless sensor networks;Zigbee;triboelectric dual functional wireless system;gait monitoring;TriboWalk wearable wireless system;motion energy harvesting;gait timing parameters;ground contact force pattern;triboelements;visualization tool;data analysis;high-output voltage;Legged locomotion;Foot;Monitoring;Energy harvesting;Wireless communication;Sensors;Wireless sensor networks;Gait Monitoring;Wireless Sensor Network;Motion Energy Harvesting;Wearable Device;Calibration;Equipment Design;Foot;Gait;Humans;Mechanical Phenomena;Motion;Remote Consultation;Shoes;Signal Processing, Computer-Assisted;Walking},
doi={10.1109/EMBC.2016.7591800},
ISSN={1558-4615},
month={Aug},}
@INPROCEEDINGS{8589560,
author={P. {Hirani} and S. {Balivada} and R. {Chauhan} and G. {Shaikh} and L. {Murthy} and A. {Balhara} and R. C. {Ponduru} and H. {Sharma} and S. {Chary} and G. B. {Subramanyam} and S. {Randhawa} and T. {Dutta} and H. P. {Gupta} and A. {Gupta} and A. {Haldar} and A. {Sarkar} and I. {Khan} and S. {Guha}},
booktitle={2018 IEEE SENSORS},
title={Using Cyber Physical Systems to Map Water Quality Over Large Water Bodies},
year={2018},
volume={},
number={},
pages={1-4},
abstract={The world faces a grave water risk that affects all aspects of human life and ecology with implications for food security, energy production, industrial activity and human health. India is particularly affected as it has 16% of the world's population but access to less than 4% of global freshwater resources. In this study, we use mobile (moving) sensors to spatially and temporally map river water quality based on in-situ data gathered in some of India's major rivers. Data visualizations generated are intended to pinpoint sources of pollution, ensure regulatory compliance and examine health of the water body. We show that such cyber physical sensing techniques can be a powerful and more practical (or cost-effective) way to dynamically monitor, predict and regulate the quality of large bodies of water.},
keywords={data visualisation;ecology;hydrological techniques;rivers;water quality;cyber physical systems;water body;grave water risk;human life;ecology;food security;energy production;industrial activity;human health;India;global freshwater resources;map river water quality;data visualizations;cyber physical sensing techniques;Rivers;Water pollution;Water resources;Sensors;Monitoring;Pollution measurement;Heatmaps;Water quality;Internet of Things(IoT)},
doi={10.1109/ICSENS.2018.8589560},
ISSN={2168-9229},
month={Oct},}
@ARTICLE{6064960,
author={M. {Haidacher} and S. {Bruckner} and E. {Groller}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Volume Analysis Using Multimodal Surface Similarity},
year={2011},
volume={17},
number={12},
pages={1969-1978},
abstract={The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.},
keywords={computerised tomography;data visualisation;pattern classification;volume analysis;multimodal surface similarity;classification space;information theoretic measure;isosurface similarity;multimodal classification;data value combinations;dual energy computed tomography;industrial manufacturing;Isosurfaces;Histograms;Computed tomography;Transfer functions;Mutual information;Multimodal data;volume visualization;surface similarity.;Angiography;Brain;Brain;Computer Graphics;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Tomography, X-Ray Computed},
doi={10.1109/TVCG.2011.258},
ISSN={1941-0506},
month={Dec},}
@INPROCEEDINGS{8949613,
author={A. {Fensel}},
booktitle={2019 International Conference on Computer, Control, Informatics and its Applications (IC3INA)},
title={Keynote: Building Smart Cities with Knowledge Graphs},
year={2019},
volume={},
number={},
pages={1-1},
abstract={Smart city systems are increasingly built with data analytics and machine learning techniques, basing on massive data sets. They have a heavy impact on human behavior and quality of life, and thus need to deliver a controllable and sufficiently transparent experience for the users.The aim of my work is to make smart city systems more interoperable and explainable, involving data visualization and communication techniques, sensor data processing, as well as the associated intelligent data value chain production and consumption. Here, the data and the information are shared employing Knowledge Graphs, that are becoming a key enabler for large-scale processing of massive collections of interrelated facts. Examples include the Google Knowledge Graph with dozens of billion facts, dataCommons, DBPedia, YAGO, and Knowledge Vault, a very large scale probabilistic knowledge graph created with information extraction methods for unstructured or semi-structured information. Specifically, Knowledge Graphs provide the means of development of the newest methods for data management, data fusion, data merging, and graph and network optimization and modeling, serving as a source of high quality data and a base for information integration.In particular, Knowledge Graphs help to infer new relationships out of existing facts, giving context and meaning to the content, and can be used in applications. For example, the data generated by a computer vision system could be semantically represented and shared across numerous systems, taking into account the needs and requirements of these systems, as well as the context, provenance, licensing and consent aspects of the generated data. I demonstrate Knowledge Graphs-based methods in advanced smart city applications from the domains such as automation and construction of buildings, energy efficiency, tourism, transport.},
keywords={buildings (structures);data analysis;data mining;data visualisation;graph theory;inference mechanisms;knowledge based systems;learning (artificial intelligence);probability;sensor fusion;smart cities;town and country planning;smart city systems;data analytics;machine learning techniques;data visualization;communication techniques;sensor data processing;Google knowledge graph;Knowledge Vault;information extraction methods;data management;data fusion;network optimization;graph optimization;computer vision system;advanced smart city applications;knowledge graphs-based methods;probabilistic knowledge graph;intelligent data value chain production;building automation;DBPedia;dataCommons;YAGO;Smart cities;Semantic technology;Computer science;Google;Europe;Informatics},
doi={10.1109/IC3INA48034.2019.8949613},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6344510,
author={J. {Lung} and S. {Easterbrook}},
booktitle={2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
title={Augmenting flow diagrams created by end-user programs},
year={2012},
volume={},
number={},
pages={175-178},
abstract={Flow and causal loop diagrams can be used by content creators to illustrate how variables in a system impact one another. Such diagrams are used in educational settings to illustrate concepts like food cycles in an ecosystem and energy flows in climate models. We demonstrate how our tool, InfloGraphic, can produce interactive diagrams either by augmenting existing static diagrams produced using common tools users may already be familiar and have available such as the Gimp or Adobe Photoshop or by using a preexisting image or web page. Content consumers can use these interactive diagrams to visualize how changes to one part of a system can ripple through a system.},
keywords={data visualisation;flowcharting;interactive systems;personal computing;Web sites;flow diagram augmentation;end-user programs;causal loop diagrams;educational settings;food cycles;ecosystem;energy flows;climate models;InfloGraphic tool;interactive diagrams;static diagram augmentation;Gimp;Adobe Photoshop;Web page;content consumers;data visualisation;static image;HTML;Libraries;Mathematical model;Earth;Visualization;Browsers;Software},
doi={10.1109/VLHCC.2012.6344510},
ISSN={1943-6106},
month={Sep.},}
@INPROCEEDINGS{9076555,
author={A. K. {Singh} and S. {Mittal} and P. {Malhotra} and Y. V. {Srivastava}},
booktitle={2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC)},
title={Clustering Evaluation by Davies-Bouldin Index(DBI) in Cereal data using K-Means},
year={2020},
volume={},
number={},
pages={306-310},
abstract={Cereals grains have been used as a principle ingredient of human diet for hundreds of years. Indian cereal crops provide vital nutrients and energy to the human diet. The motivation behind this research paper is to distribute the research discoveries of applying K-Means clustering, on a cereal dataset and to differentiate the outcomes found on the number of bunches to identify whether the ideal or best number of groups to be 3 or 5. This speculation is achieved by applying distinctive clustering tests (likewise reordered in the paper), and visualizations. The aforementioned resolution by doing exploratory analysis, at that point modeled fitting followed by result testing, driving us to a definite end. The language utilized for our exploration is R.},
keywords={crops;data visualisation;food products;pattern clustering;production engineering computing;vital nutrients;human diet;k-means clustering;cereal dataset;clustering evaluation;cereals grains;clustering tests;Indian cereal crops;Davies-Bouldin index;visualizations;Clustering;K-Means;Cereals;DBI},
doi={10.1109/ICCMC48092.2020.ICCMC-00057},
ISSN={},
month={March},}
@INPROCEEDINGS{6295878,
author={S. {Iaconesi} and O. {Persico}},
booktitle={2012 16th International Conference on Information Visualisation},
title={VersuS, The Digital Lives of Cities Transforms into Usable Interconnective Intelligence},
year={2012},
volume={},
number={},
pages={602-606},
abstract={While we perform our daily tasks we reinterpret space and personalize it, according to tactics which reveal significant information about ourselves. We are now able to fill and stratify space/time with digital information layers, completely wrapping cities in a membrane of information and of opportunities for interaction and communication. Mobile devices, smartphones, wearables, digital tags, near field communication devices, location based services and mixed/augmented reality have turned the world into an essentially read/write, ubiquitous publishing surface. The usage of mobile devices and ubiquitous technologies alters the understanding of place. The scenario described in this paper sees urban spaces progressively filling with multiple layers of real-time, ubiquitous, digital information, creating usage cases in which urban narratives are read in different ways, highlighting how cities express points of view on the environment, culture, economy, transports, energy and politics. The research presented in this paper analyses multiple opportunities to capture, understand and visualize the real-time digital lives of cities, from a variety of points of view and objectives, dedicated to the needs of administrations, citizens and organizations, and to the possibility to transform these representations into a form of disseminated, ubiquitous, interconnective intelligence.},
keywords={augmented reality;cultural aspects;data visualisation;environmental factors;politics;social aspects of automation;social networking (online);town and country planning;ubiquitous computing;VersuS;usable interconnective intelligence;space reinterpretation;digital information layers;space-time stratification;mobile devices;smartphones;digital tags;near field communication devices;wearable devices;location based services;mixed reality;augmented reality;urban spaces;digital information;environmental aspects;culture;economy;energy aspects;politics;real-time digital lives visualization;digital cities;administration needs;organizations;disseminated intelligence;ubiquitous intelligence;social networks;urban planning;citizenship;Cities and towns;Visualization;Real time systems;Presses;Humans;Educational institutions;Mobile handsets;social networks;ubiquitous technologies;real-time information;urban contexts;urban planning;citizenship},
doi={10.1109/IV.2012.101},
ISSN={2375-0138},
month={July},}
@ARTICLE{8454905,
author={J. {Wang} and L. {Gou} and H. {Shen} and H. {Yang}},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks},
year={2019},
volume={25},
number={1},
pages={288-298},
abstract={Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis. As an initial attempt in visualizing DQN models, our work focuses more on Atari games with a simple action space, most notably the Breakout game. From our visual analytics of the agent's experiences, we extract useful action/reward patterns that help to interpret the model and control the training. Through multiple case studies conducted together with deep learning experts, we demonstrate that DQNViz can effectively help domain experts to understand, diagnose, and potentially improve DQN models.},
keywords={computer games;data visualisation;learning (artificial intelligence);neural nets;DQNViz;deep Q-Network;deep reinforcement learning model;intelligent agent;optimal actions;professional human players;superhuman performance;sophisticated behaviors;DQN agent;visual analytics system;blind training process;experience space;DQN models;Atari games;deep learning experts;breakout game;reward patterns;action space;model training process;Training;Games;Visual analytics;Data visualization;Analytical models;Learning (artificial intelligence);Machine learning;Deep Q-Network (DQN);reinforcement learning;model interpretation;visual analytics},
doi={10.1109/TVCG.2018.2864504},
ISSN={1941-0506},
month={Jan},}
@ARTICLE{7040668,
author={A. {Valerio Netto}},
journal={IEEE Latin America Transactions},
title={Planning of network system for the distribution and transmission areas of electric energy},
year={2015},
volume={13},
number={1},
pages={345-352},
abstract={In this project, we developed a computational system based on a framework of geo-referenced data that uses Google Maps technology. The focus is on improving the modeling of information for viewing and embedding technology, human-computer interface (HCI) which includes visualization environments synchronized. The first environment allows you to have the vision of the network elements in the form of electrical single line diagram, representing a consolidated technique in the field of electricity. The second environment called GIS is a map-based navigation with Google Maps that allows the physical location of where it is represented the elements present in the electrical line diagram. This integrated system is capable of supporting the planning of network expansion works in the areas of distribution and transmission of electricity.},
keywords={geographic information systems;human computer interaction;power distribution planning;power engineering computing;power transmission planning;synchronisation;network system;distribution areas;transmission areas;electric energy;computational system;georeferenced data;Google Maps technology;embedding technology;human-computer interface;HCI;electrical single line diagram;GIS;map-based navigation;network expansion works;Software;Google;Visualization;Unified modeling language;Planning;Computational modeling;Electricity;distribution;GIS;google maps;planning;system of decision making;transmission;visualization system},
doi={10.1109/TLA.2015.7040668},
ISSN={1548-0992},
month={Jan},}
@INPROCEEDINGS{7169375,
author={G. {C} and C. {J} and D. S. {V} and D. {S}},
booktitle={2015 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON)},
title={A full-reference stereoscopic image quality metric based on binocular energy and regression analysis},
year={2015},
volume={},
number={},
pages={1-5},
abstract={The recent developments of 3D media technology have brought to life numerous applications of interactive entertainment such as 3D cinema, 3DTV and gaming. However, due to the data intensive nature of 3D visual content, a number of research challenges have emerged. In order to optimise the end-to-end content life-cycle, from capture to processing and delivery, Quality of Experience (QoE) has become a major driving factor. This paper presents a human-centric approach to quality estimation of 3D visual content. A fullreference quality assessment method for stereoscopic images is proposed. It is based on a Human Visual System (HVS) model to estimate subjective scores of registered stereoscopic images subjected to compression losses. The model has been trained with four publicly available registered stereoscopic image databases and a fixed relationship between subjective scores and the model has been determined. The high correlation of the relationship over a large number of stimuli has proven its consistency over the state-of-the-art.},
keywords={computer vision;entertainment;image registration;man-machine systems;quality of experience;regression analysis;stereo image processing;compression loss;human visual system;registered stereoscopic image;full-reference quality assessment method;3D visual content quality estimation;human centric approach;QoE;quality of experience;interactive entertainment application;3D media technology;regression analysis;binocular energy;full-reference stereoscopic image quality metric;Measurement;Stereo image processing;Three-dimensional displays;Visualization;Analytical models;Image quality;Quality assessment;Human Visual System;Binocular vision;Stereoscopic image quality metric},
doi={10.1109/3DTV.2015.7169375},
ISSN={2161-203X},
month={July},}
@ARTICLE{8049349,
author={D. {Liu} and A. K. {Khambampati} and J. {Du}},
journal={IEEE Transactions on Medical Imaging},
title={A Parametric Level Set Method for Electrical Impedance Tomography},
year={2018},
volume={37},
number={2},
pages={451-460},
abstract={This paper presents an image reconstruction method based on parametric level set (PLS) method using electrical impedance tomography. The conductivity to be reconstructed was assumed to be piecewise constant and the geometry of the anomaly was represented by a shape-based PLS function, which we represent using Gaussian radial basis functions (GRBF). The representation of the PLS function significantly reduces the number of unknowns, and circumvents many difficulties that are associated with traditional level set (TLS) methods, such as regularization, re-initialization and use of signed distance function. PLS reconstruction results shown in this article are some of the first ones using experimental EIT data. The performance of the PLS method was tested with water tank data for two-phase visualization and with simulations which demonstrate the most popular biomedical application of EIT: lung imaging. In addition, robustness studies of the PLS method w.r.t width of the Gaussian function and GRBF centers were performed on simulated lung imaging data. The experimental and simulation results show that PLS method has significant improvement in image quality compared with the TLS reconstruction.},
keywords={computerised tomography;electric impedance imaging;image reconstruction;least squares approximations;lung;medical image processing;radial basis function networks;experimental EIT data;two-phase visualization;lung imaging;GRBF centers;simulated lung imaging data;Gaussian function;PLS reconstruction results;signed distance function;Gaussian radial basis functions;PLS function;image reconstruction method;electrical impedance tomography;parametric level set method;TLS reconstruction;PLS method;Tomography;Image reconstruction;Level set;Conductivity;Inverse problems;Lungs;Shape;Electrical impedance tomography;parametric level set method;lung imaging;inverse problems;Computer Simulation;Electric Impedance;Humans;Image Processing, Computer-Assisted;Lung;Thorax;Tomography},
doi={10.1109/TMI.2017.2756078},
ISSN={1558-254X},
month={Feb},}
@ARTICLE{8752446,
author={D. {Seebacher} and M. {Miller} and T. {Polk} and J. {Fuchs} and D. A. {Keim}},
journal={IEEE Computer Graphics and Applications},
title={Visual Analytics of Volunteered Geographic Information: Detection and Investigation of Urban Heat Islands},
year={2019},
volume={39},
number={5},
pages={83-95},
abstract={Urban heat islands are local areas where the temperature is much higher than in the vicinity and are a modern phenomenon that occurs mainly in highly developed areas, such as large cities. This effect has a negative impact on energy management in buildings, and also has a direct impact on human health, especially for elderly people. With the advent of volunteered geographic information from private weather station networks, more high-resolution data are now available within cities to better analyze this effect. However, such datasets are large and have heterogeneous characteristics requiring visual-interactive applications to support further analysis. We use machine learning methods to predict urban heat islands occurrences and utilize temporal and spatio-temporal visualizations to contextualize the emergence of urban heat islands to comprehend the influencing causes and their effects. Subsequently, we demonstrate the analysis capabilities of our application by presenting two use cases.},
keywords={atmospheric temperature;data analysis;data visualisation;geographic information systems;geriatrics;learning (artificial intelligence);urban heat islands occurrences;spatio-temporal visualizations;visual analytics;volunteered geographic information;private weather station networks;high-resolution data;visual-interactive applications;machine learning methods;Thermal pollution;Urban areas;Data visualization;Meteorology;Buildings;Heating systems;Visualization},
doi={10.1109/MCG.2019.2926242},
ISSN={1558-1756},
month={Sep.},}
@ARTICLE{9094630,
author={J. {Zhou} and T. {Xu} and S. {Ren} and K. {Guo}},
journal={IEEE Access},
title={Two-Stage Spatial Mapping for Multimodal Data Fusion in Mobile Crowd Sensing},
year={2020},
volume={8},
number={},
pages={96727-96737},
abstract={Human-driven Edge Computing (HEC) integrates the elements of humans, devices, Internet and information, and mobile crowd sensing become an important means of data collection. In HEC, the data collected from large-scale sensing usually includes a variety of modalities. These different modality data contain unique information and attributes, which can be complementary. Combining data from many different modalities will get more information. However, current deep learning is usually only for bimodal data. In order for artificial intelligence to make further breakthroughs in understanding our real world, it needs to be able to process data in different modalities together. The key step is to be able to map these different modalities data into the same space. In order to process multimodal data better, we propose a fusion and classification method for multimodal data. First, a multimodal data space is constructed, and data of different modalities are mapped into the multimodal data space to obtain a unified representation of different modalities data. Then, through bilinear pooling, the representations of different modality are fused, and the fused vectors are used in the classification task. Through the experimental verification on the multi-modal data set, it proves that the multi-modal fusion representation is effective, and the classification effect is more accurate than the single-modal data.},
keywords={learning (artificial intelligence);mobile computing;neural nets;pattern classification;sensor fusion;multimodal fusion representation;single-modal data;multimodal data fusion;mobile crowd sensing;bimodal data;multimodal data space;two-stage spatial mapping;human-driven edge computing;artificial intelligence;classification method;bilinear pooling;Sensors;Fuses;Semantics;Correlation;Visualization;Neural networks;Edge computing;Multimodal data;unified representation;mobile crowd sensing;human-driven edge computing},
doi={10.1109/ACCESS.2020.2995268},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7566767,
author={P. {Swami} and T. {Gandhi} and B. K. {Panigrahi} and M. {Bhatia} and S. {Anand}},
booktitle={2016 3rd International Conference on Signal Processing and Integrated Networks (SPIN)},
title={Locating ictal activities over human scalp with automated detection using EEG signals},
year={2016},
volume={},
number={},
pages={600-604},
abstract={Epilepsy is one of the most common brain disorder which affects more than sixty-five million people worldwide. Its diagnosis is usually performed using electroencephalography technique. Since, electroencephalogram (EEG) signals are highly susceptible to artifacts, epilepsy diagnosis is often challenging task. In addition, locating the origin of seizure patterns is even more tedious due to the non-linear nature of EEG signals. Therefore, automated seizure detection systems are highly important to overcome the said challenges. In this study, we have designed a procedure which integrates the seizure detection and localization process with ceiling level of efficiency. Here, we evaluated the energy and standard features using `coiflets' wavelet packets. Then, the feature matrix was reduced by applying fast correlation based filter. Application of 5-Nearest Neighbour classifier resulted in mean accuracy of 99.3515±0.2518 % taking only 0.152±0.0344 seconds for execution. Later, independent component analysis over the ictal segments was applied and subsequently topographic scalps maps were plotted. The results successfully implied automated detection and visualization of ictal activities over the human scalp.},
keywords={correlation methods;data visualisation;electroencephalography;filtering theory;independent component analysis;matrix algebra;medical signal detection;medical signal processing;signal classification;wavelet transforms;ictal activities localization;human scalp;EEG signals;brain disorder;electroencephalography technique;electroencephalogram signals;epilepsy diagnosis;automated seizure detection systems;seizure localization process;efficiency ceiling level;coiflets wavelet packets;feature matrix;fast correlation based filter;5-nearest neighbour classifier;independent component analysis;topographic scalps maps;ictal activities visualization;Electroencephalography;Epilepsy;Brain models;Feature extraction;Standards;Electrodes;Electroencephalogram (EEG);Ictal activities;topographic maps;k-Nearest Neighbor (k-NN) classifier},
doi={10.1109/SPIN.2016.7566767},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8210574,
author={A. {Petropoulos} and D. {Sikeridis} and T. {Antonakopoulos}},
booktitle={2017 IEEE 7th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)},
title={SPoMo: IMU-based real-time sitting posture monitoring},
year={2017},
volume={},
number={},
pages={5-9},
abstract={Improper sitting posture can lead to a number of serious health disorders connected to the musculoskeletal system. Especially nowadays sitting periods at work or at home are increasing, and therefore consistent stance monitoring can help users improve their sitting habits and avoid related complications. In this work, we present SPoMo a real-time, practical, wearable system that automatically tracks the user's sitting posture, through wireless sensors attached to his back. Our prototype is based on Inertial Measurement Units (IMUs) that monitor the angle deviation from the optimal position. We have also developed a cloud-assisted mobile application able to continuously visualize the user's stance, archive his performance over time and provide insight for future development of proper posture. We focus on presenting SPoMo functionality and experimentally evaluate its performance. Our results prove our system to be accurate and therefore a good every-day solution that helps the consumer to avoid chronic improper posture.},
keywords={cloud computing;data visualisation;diseases;feature extraction;health care;human computer interaction;medical computing;medical disorders;mobile computing;sensor fusion;sitting habits;health disorders;SPoMo functionality;user stance visualization;ergonomic suggestions;data stream fusion;data extraction;consistent stance monitoring;musculoskeletal system;real-time sitting posture monitoring;chronic improper posture;cloud-assisted mobile application;Inertial Measurement Units;wireless sensors;wearable system;Sensors;Accelerometers;Monitoring;Gyroscopes;Quaternions;Back;Calibration;Sitting posture monitoring;Wearables;Bluetooth Low Energy;IMU},
doi={10.1109/ICCE-Berlin.2017.8210574},
ISSN={2166-6822},
month={Sep.},}
@INPROCEEDINGS{7047970,
author={S. {Mann}},
booktitle={2014 IEEE Games Media Entertainment},
title={“SELF-HII”: Strength + endurance + longevity through gameplay with humanistic intelligence by Fieldary Human Information Interaction},
year={2014},
volume={},
number={},
pages={1-8},
abstract={In 1995 Gershon founded the field of HII (Human Information Interaction). I build upon his seminal work by creating a new multiscale framework for (1) sensing, and (2) being sensed by, any measurable or generable classical or quantum scalar, vector, spinor, or tensor field, such as being able to sense and be sensed by water, sound, light (real or virtual) - and in some cases even being able to sense sensing itself (i.e. the sightfield of a camera-visualizing vision and seeing sight itself). I call this FHII (Fieldary Human Information Interaction) and apply it to physical fitness by way of serious games. Physical fitness training normally builds strength or endurance. Strength usually deals with a short-term (short time period), and is somewhat related to power, as measured in Watts (Joules per second). Endurance usually deals with a longer-term, and is more closely related to energy, as measured in Joules (Watt seconds). I argue that the time-scale of endurance is really only medium-term, when considering an average human lifespan. Therefore I present a third category of physical fitness I call Longevity, along with a new quantity I call "actergy" ("total action"). Actergy has units of Joule seconds, the same units as Plank's constant, angular momentum, and action. These three units: (1) Joules per second, (2) Joules, and (3) Joule seconds, suggest (1) Differential, (2) Proportional, and (3) Integral, forms of kinesology. Their three related forms of fitness training: Strength + Endurance + Longevity (SEL), can operate within the Fieldary Human Information Interaction space. I present a unified framework for this: SEL-FHII ("O Φ", pronounced "sel Φ ", i.e. either "selfeye" or "selfie") training that combines all three time scales (differential, proportional, and integral) with ideas in HI (Humanistic Intelligence). Combining wearable computing and IoT (Internet of Things), we can contextualize the otherwise disparate fields of/in Serious Games, SELFHII, Sonelization, Entertainment, and Media, across these multiple scales, as a form of urban design, whether at the environmental scale of countries, cities, and streets, or the invironmental scale of Digital Eye Glass and the individual body (e.g. clothing as a building built for a single occupant). In particular, thinking beyond traditional gaming consoles, we can achieve longevity through gameplay at the intersection of cyberspace and the real world.},
keywords={computer games;data visualisation;human computer interaction;Internet of Things;wearable computing;media;entertainment;sonelization;IoT;Internet of Things;Joule seconds;Joules;Watt seconds;Joules per second;serious games;FHII;camera-visualizing vision;Digital Eye Glass;Watts;Fieldary Human Information Interaction;humanistic intelligence;SELF-HII},
doi={10.1109/GEM.2014.7047970},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7377217,
author={R. {Janzen} and S. {Mann}},
booktitle={2015 IEEE Games Entertainment Media Conference (GEM)},
title={Sensory flux from the eye: Biological sensing-of-sensing (veillametrics) for 3D augmented-reality environments},
year={2015},
volume={},
number={},
pages={1-9},
abstract={We measure and visualize the ability-to-see, from the human eye, as that ability-to-see propagates through space. "Biological veillance flux" is a metric of sensory precision emitted from the eyes and falling on objects, with much greater detail than merely tracking the center of the eye's field of view. This work makes it possible to "see sight" and "measure sight" as the "sight" travels through three-dimensional space. In earlier work we measured veillance flux from electronic sensors and cameras. Now, we examine biological veillance flux. The result is a method to detect radiation of information-bearing optical sensitivity, as opposed to radiation of ordinary light energy in the opposite direction. These measurements can be used as an augmented-reality visualization of human sight. They can serve as an interactive score tracking how much a target is seen. Additionally, they could serve as a data-rich metric of visual precision directed by human eyes toward control panels in industrial applications, or as a metric of visual precision directed by human eyes towards printed material or digital media, for advertising, arts or entertainment applications. Extramissive optics, as a new field of research, is thus expanded into the biological realm.},
keywords={augmented reality;cameras;data visualisation;sensory flux;biological sensing-of-sensing;veillametrics;3D augmented-reality environment;biological veillance flux;human eye;electronic sensors;cameras;information-bearing optical sensitivity;ordinary light energy radiation;augmented-reality visualization;Cameras;Three-dimensional displays;Optical sensors;Visualization;Extraterrestrial measurements},
doi={10.1109/GEM.2015.7377217},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7045792,
author={S. {Boddhu} and R. {Flagg} and P. {Grzebala} and R. {Bodduluri} and R. {Williams}},
booktitle={NAECON 2014 - IEEE National Aerospace and Electronics Conference},
title={A generic sensor fusion architecture for enhancing situational awareness},
year={2014},
volume={},
number={},
pages={143-148},
abstract={The advancements of mobile technology and its widespread availability have redefined many computing paradigms including Human-centric sensing. Human-centric sensing has already been successfully implemented as integrated network architecture component in many operational intelligent systems in various industry areas such as defense, healthcare, energy or disaster management. The process of integration of Human-centric sensing into the system can be lengthy and complicated because of disparate data formats, modality and connectivity interfaces. Extending an existing system by new, and possibly future, sensors may result in low-level integration issues. There is a need for a generic architecture that will be able to dynamically accommodate new sensors and to provide fusion of all sensed data. In this paper, we extend our previous work of developing an architecture that supports seamless integration and development of platforms to enhance situational awareness in the context of Human-centric sensing.},
keywords={human factors;intelligent sensors;mobile computing;sensor fusion;mobile technology;human-centric sensing;generic sensor fusion architecture;situational awareness enhancement;operational intelligent system;data fusion;Sensors;Computer architecture;Collaboration;Real-time systems;Data visualization;Software;Surveillance;event collaboration architecture;sensor fusion;situational awareness;mongodb},
doi={10.1109/NAECON.2014.7045792},
ISSN={2379-2027},
month={June},}
@INPROCEEDINGS{6017803,
author={A. {Kongthon} and C. {Haruechaiyasak} and C. {Sangkeettrakarn} and P. {Palingoon} and W. {Wunnasri}},
booktitle={2011 Proceedings of PICMET '11: Technology Management in the Energy Smart World (PICMET)},
title={HotelOpinion: An opinion mining system on hotel reviews in Thailand},
year={2011},
volume={},
number={},
pages={1-6},
abstract={This paper reports on the extension of our previous work on feature-based opinion mining for Thai language. In this paper, we present an approach for automatically constructing two main lexicons: features and polar words based on syntactic pattern analysis. The evaluation is performed with a case study on hotel reviews. The experimental results show that our approach is effective in performing its task. To illustrate the potential application, we implement a system called HotelOpinion for summarizing the hotel reviews written in the Thai language. Our system can also generate a comparison between hotels based upon the user's preferred features and then present the results in a user-friendly visualization. Results from our system can be used to determine public perceptions regarding selected hotels in order to allow the business to improve their customer intimacy and satisfaction.},
keywords={data mining;hotel industry;natural language processing;reviews;opinion mining system;hotel reviews;Thailand;polar words;syntactic pattern analysis;HotelOpinion;Thai language;customer intimacy;customer satisfaction;Feature extraction;Pattern analysis;Data mining;Syntactics;Companies;User-generated content;Cities and towns},
doi={},
ISSN={2159-5100},
month={July},}
@INPROCEEDINGS{7942694,
author={ {Minh Nghia Le} and H. {Inuzuka} and T. {Nakanishi} and {Quang Vy Nguyen} and Y. {Morita} and M. {Sakai}},
booktitle={2017 3rd International Conference on Control, Automation and Robotics (ICCAR)},
title={Graphical simulator for teaching robot with parallel wire type teaching device},
year={2017},
volume={},
number={},
pages={233-236},
abstract={In order to enable operators to teach the desired motion to a robot directly and easily, we are developing a parallel wire type device (PAWTED) which is attached to an end-effector of a robot. However, practical experiments and researching so far shows that there still exists a problem of singular points in which the robot moves fast unstably and out of limitation range in energy aspect. Therefore, we have to analyze movement of a robot in both teaching and playing-back modes as well as the pulling forces and moments which are felt by operators during process of teaching. This paper presents two simulators to simulate those problems. One is used to analyze movement of a 6-dof serial manipulator in both modes. The other one is used to analyze the forces and moments in teaching mode. The movements of the robot and the PAWTED are visualized graphically using Open Graphics Library (OpenGL). These simulators will be combined and used to design control algorithms of avoidance of singular postures.},
keywords={control engineering computing;data visualisation;digital simulation;end effectors;human-robot interaction;teaching;graphical simulator;teaching robot;parallel wire type teaching device;PAWTED;end-effector;teaching mode;playing-back mode;pulling forces;6-DoF serial manipulator;graphical visualization;Open Graphics Library;OpenGL;singular posture avoidance;Robots;Graphics;Wires;Computational modeling;Standards;Manuals;teaching robot;parallel wire;stewart platform;OpenGL;C++;Simulation},
doi={10.1109/ICCAR.2017.7942694},
ISSN={},
month={April},}
@INPROCEEDINGS{9121446,
author={D. {Li} and Y. {Gong} and S. {Shen} and M. {Zhang}},
booktitle={2020 Asia Energy and Electrical Engineering Symposium (AEEES)},
title={Research and Design of Power Equipment Operation and Maintenance System Based on Big Data Technology},
year={2020},
volume={},
number={},
pages={323-327},
abstract={With the passage of time, especially the arrival of the information age, the impact of electricity in human society is more and more huge. Not only production and scientific research rely on electricity, but also people's daily life, work and various activities depend on electricity. Therefore, the power security work becomes particularly important, and the power equipment substation is an important part of the power grid. The inspection and operation and maintenance of power equipment is the basic way to ensure the safety and normal work of power equipment. The traditional planned operation and maintenance method of power equipment can significantly reduce the failure rate of power equipment, but there are problems such as insufficient or excessive maintenance, blind maintenance and so on. In order to improve the efficiency of power equipment maintenance, this paper designs a set of power equipment maintenance system based on big data analysis technology of power operation and maintenance. According to a large number of operation data of power system accumulated by power equipment, including various equipment status monitoring, maintenance and other data, the system can diagnose, optimize and predict the operation of the whole power grid equipment through key technology of big data analysis, which can reduce the maintenance cost, improve the actual effect of maintenance, improve the intelligent level of operation and maintenance of power equipment, and provide guarantee for the safe, reliable, economic and efficient operation of the network.},
keywords={Big Data;data analysis;electrical safety;failure analysis;inspection;maintenance engineering;power apparatus;power engineering computing;power grids;power system reliability;power system security;substations;power security;power equipment substation;power equipment maintenance system;power grid equipment;failure analysis;big data analysis;power equipment;operation and maintenance;big data technology;visualization technology},
doi={10.1109/AEEES48850.2020.9121446},
ISSN={},
month={May},}
@ARTICLE{8565958,
author={M. {Koyuncu} and A. {Yazici} and M. {Civelek} and A. {Cosar} and M. {Sert}},
journal={IEEE Sensors Journal},
title={Visual and Auditory Data Fusion for Energy-Efficient and Improved Object Recognition in Wireless Multimedia Sensor Networks},
year={2019},
volume={19},
number={5},
pages={1839-1849},
abstract={Automatic threat classification without human intervention is a popular research topic in wireless multimedia sensor networks (WMSNs) especially within the context of surveillance applications. This paper explores the effect of fusing audio-visual multimedia and scalar data collected by the sensor nodes in a WMSN for the purpose of energy-efficient and accurate object detection and classification. In order to do that, we implemented a wireless multimedia sensor node with video and audio capturing and processing capabilities in addition to traditional/ordinary scalar sensors. The multimedia sensors are kept in sleep mode in order to save energy until they are activated by the scalar sensors which are always active. The object recognition results obtained from video and audio applications are fused to increase the object recognition performance of the sensor node. Final results are forwarded to the sink in text format, and this greatly reduces the size of data transmitted in network. Performance test results of the implemented prototype system show that the fusing audio data with visual data improves automatic object recognition capability of a sensor node significantly. Since auditory data requires less processing power compared to visual data, the overhead of processing the auditory data is not high, and it helps to extend network lifetime of WMSNs.},
keywords={data visualisation;multimedia systems;object detection;object recognition;sensor fusion;wireless sensor networks;wireless multimedia sensor networks;automatic threat classification;fusing audio-visual multimedia;wireless multimedia sensor node;multimedia sensors;audio applications;object detection;visual data fusion;auditory data fusion;automatic object recognition;Sensors;Wireless sensor networks;Streaming media;Visualization;Cameras;Wireless communication;Image coding;Wireless multimedia sensor;object detection;visual and auditory data fusion;WMSN},
doi={10.1109/JSEN.2018.2885281},
ISSN={1558-1748},
month={March},}
@ARTICLE{6541974,
author={H. {Lu} and X. {Shao} and Y. {Xiao}},
journal={IEEE Transactions on Image Processing},
title={Pose Estimation With Segmentation Consistency},
year={2013},
volume={22},
number={10},
pages={4040-4048},
abstract={In this paper, we propose a novel method that treats pose estimation as a problem with the constraints of human segmentation consistency from single images. Different from the previous paper, we integrate pose estimation and object segmentation into a joint optimization. With the support of segmentation consistency, we can obtain more reliable pose results. Through analyzing the energy function of pose estimation and human segmentation, we convert the pose estimation into a binary optimization problem that has the same formation as segmentation. The top-down pose shape cues, bottom-up visual cues, and the consistency constraints that penalize the mismatching of pose and human foreground are incorporated into our final objective function. Qualitative and quantitative experimental results demonstrate the merits of our method in pose estimation on Ramanan benchmark and Buffy data sets.},
keywords={image segmentation;integer programming;linear programming;pose estimation;pose estimation;human segmentation consistency;object segmentation;joint optimization;energy function;binary optimization problem;top-down pose shape cues;bottom-up visual cues;consistency constraints;Ramanan benchmark;Buffy data sets;Image segmentation;Pose estimation;Optimization;Shape;Detectors;Motion segmentation;Visualization;Human Segmentation;Pose Estimation;Segmentation Consistency;Integer Linear Program;Databases, Factual;Extremities;Head;Humans;Image Processing, Computer-Assisted;Posture;Torso},
doi={10.1109/TIP.2013.2268975},
ISSN={1941-0042},
month={Oct},}
@INPROCEEDINGS{8798180,
author={O. {Ergün} and Ş. {Akın} and İ. G. {Dino} and E. {Surer}},
booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
title={Architectural Design in Virtual Reality and Mixed Reality Environments: A Comparative Analysis},
year={2019},
volume={},
number={},
pages={914-915},
abstract={Virtual reality (VR) provides a completely digital world of interaction which enables the users to modify, edit, and transform digital elements in a responsive way. Mixed reality (MR), which is the result of blending the digital world and the physical world together, brings new advancements and challenges to human, computer and environment interactions. This paper focuses on adapting the already-existing methods and tools in architecture to both VR and MR environments under sustainable architectural design domain. For this purpose, we benefit from the semantically enriched data platforms of Building information modelling (BIM) tools, the performance calculation functions of building energy simulation tools while transcending these data into VR and MR environments. In this way, we were able to merge these diverse data for the virtual design activity. Nine participants have already tested the initial prototype of MR-based only interaction environment in our previous study [1]. According to the feedbacks, the user interface and interaction mechanisms were updated and the environment was made accessible also in VR. These updates made four types of interactions possible in MR and VR: 1) MR environment using HoloLens with gestures, 2) MR environment using HoloLens with a clicker, 3) VR environment using HTC Vive with two controllers, and 4) HoloLens emulator with a mouse. All these interaction cases were tested by 21 architecture students in an in-house workshop. In this workshop, we collected data on presence, usability, and technology acceptance of these cases. Our results show that interaction in a VR environment is the most natural interaction type and the participants were eager to use both MR and VR environments instead of an emulator. To our best of knowledge, this is the first comparative study of a BIM-based architectural design medium in both VR and MR environments.},
keywords={architectural CAD;augmented reality;building management systems;buildings (structures);virtual reality;physical world;sustainable architectural design domain;semantically enriched data platforms;performance calculation functions;building energy simulation tools;virtual design activity;interaction environment;user interface;HoloLens;VR environment;natural interaction type;BIM-based architectural design medium;mixed reality environments;building information modelling tools;architecture students;Virtual reality;Solid modeling;Tools;Buildings;Usability;Data models;Data visualization;Mixed Reality;Virtual Reality;Building Information Modelling;J [Computer Applications]: J.6. Computer-Aided Engineering},
doi={10.1109/VR.2019.8798180},
ISSN={2642-5254},
month={March},}
@INPROCEEDINGS{7532868,
author={M. S. {Gide} and S. F. {Dodge} and L. J. {Karam}},
booktitle={2016 IEEE International Conference on Image Processing (ICIP)},
title={Visual attention quality database for benchmarking performance evaluation metrics},
year={2016},
volume={},
number={},
pages={2792-2796},
abstract={With the increased focus on visual attention (VA) in the last decade, a large number of computational visual saliency methods have been developed. These models are evaluated by using performance evaluation metrics that measure how well a predicted map matches eye-tracking data obtained from human observers. Though there are a number of existing performance evaluation metrics, there is no clear consensus on which evaluation metric is the best. This work proposes a subjective study that uses ratings from human observers to evaluate saliency maps computed by existing VA models based on comparing the maps visually with ground-truth maps obtained from eye-tracking data. The subjective ratings are correlated with the scores obtained from existing as well as a proposed objective VA performance evaluation metric using several correlation measures. The correlation results show that the proposed objective VA metric outperforms the existing metrics.},
keywords={computer vision;gaze tracking;image enhancement;visual databases;visual attention quality database;VA quality database;performance evaluation metric;visual saliency method;eye-tracking data;human observer;human visual system;HVS;Visualization;Correlation;Databases;Benchmark testing;Performance evaluation;Gold;Visual Attention;Subjective Study;VA Performance Metrics;VA Models},
doi={10.1109/ICIP.2016.7532868},
ISSN={2381-8549},
month={Sep.},}
@INPROCEEDINGS{5584709,
author={S. {Inoue} and J. {Dai} and M. {Shiba} and S. {Aoki} and H. {Tsuji}},
booktitle={International Conference on Fuzzy Systems},
title={Knowledge management approach for saving home energy consumption},
year={2010},
volume={},
number={},
pages={1-6},
abstract={In order to save home energy consumption, this paper proposes an indirect control method. “Indirect” in this paper means that the system notifies users to control their life style and usage of home equipments. The basic idea is as follows: (1) Collect home energy consumption data with personal property including their life style by Web-based questionnaire, (2) Notify consumers their status of energy consumption in the same category homes when they disclose their consumed energy data, (3) Advise action for saving energy if one consumes energy much. This paper introduces how to implement the idea in a knowledge management system and discusses the issues to implement the idea. The feasibility test has also shown the possibility of the proposed method.},
keywords={building management systems;energy consumption;home automation;intelligent control;Internet;knowledge management;load flow control;power aware computing;power engineering computing;home energy consumption;Web-based questionnaire;knowledge management system;indirect energy load control method;Energy consumption;Knowledge management;Humans;Internet;Probabilistic logic;Data visualization;Dispersion},
doi={10.1109/FUZZY.2010.5584709},
ISSN={1098-7584},
month={July},}
@INPROCEEDINGS{7298934,
author={R. {Anirudh} and P. {Turaga} and J. {Su} and A. {Srivastava}},
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Elastic functional coding of human actions: From vector-fields to latent variables},
year={2015},
volume={},
number={},
pages={3147-3155},
abstract={Human activities observed from visual sensors often give rise to a sequence of smoothly varying features. In many cases, the space of features can be formally defined as a manifold, where the action becomes a trajectory on the manifold. Such trajectories are high dimensional in addition to being non-linear, which can severely limit computations on them. We also argue that by their nature, human actions themselves lie on a much lower dimensional manifold compared to the high dimensional feature space. Learning an accurate low dimensional embedding for actions could have a huge impact in the areas of efficient search and retrieval, visualization, learning, and recognition. Traditional manifold learning addresses this problem for static points in ℝn, but its extension to trajectories on Riemannian manifolds is non-trivial and has remained unexplored. The challenge arises due to the inherent non-linearity, and temporal variability that can significantly distort the distance metric between trajectories. To address these issues we use the transport square-root velocity function (TSRVF) space, a recently proposed representation that provides a metric which has favorable theoretical properties such as invariance to group action. We propose to learn the low dimensional embedding with a manifold functional variant of principal component analysis (mfPCA). We show that mf-PCA effectively models the manifold trajectories in several applications such as action recognition, clustering and diverse sequence sampling while reducing the dimensionality by a factor of ~ 250×. The mfPCA features can also be reconstructed back to the original manifold to allow for easy visualization of the latent variable space.},
keywords={data reduction;functions;image motion analysis;image recognition;image sequences;principal component analysis;human actions elastic functional coding;transport square-root velocity function;TSRVF space;low dimensional embedding;manifold functional principal component analysis;mfPCA;dimensionality reduction;statistics;action sequences;action recognition;Manifolds;Trajectory;Shape;Measurement;Principal component analysis;Visualization;Joints},
doi={10.1109/CVPR.2015.7298934},
ISSN={1063-6919},
month={June},}
@ARTICLE{7930375,
author={J. {Baek} and H. {Jeon} and G. {Kim} and S. {Han}},
journal={IEEE Access},
title={Visualizing Quaternion Multiplication},
year={2017},
volume={5},
number={},
pages={8948-8955},
abstract={Quaternion rotation is a powerful tool for rotating vectors in 3-D; as a result, it has been used in various engineering fields, such as navigations, robotics, and computer graphics. However, understanding it geometrically remains challenging, because it requires visualizing 4-D spaces, which makes exploiting its physical meaning intractable. In this paper, we provide a new geometric interpretation of quaternion multiplication using a movable 3-D space model, which is useful for describing quaternion algebra in a visual way. By interpreting the axis for the scalar part of quaternion as a 1-D translation axis of 3-D vector space, we visualize quaternion multiplication and describe it as a combined effect of translation, scaling, and rotation of a 3-D vector space. We then present how quaternion rotation formulas and the derivative of quaternions can be formulated and described under the proposed approach.},
keywords={data visualisation;mathematics computing;number theory;vectors;quaternion multiplication visualization;quaternion rotation;rotating vectors;4D space visualization;geometric interpretation;movable 3D space model;quaternion algebra;1D translation axis;3D vector space translation;3D vector space scaling;3D vector space rotation;quaternion rotation formulas;Quaternions;Visualization;Space vehicles;Algebra;Robots;Computational modeling;4-dimensional spaces;geometry;scaling;quaternion rotation},
doi={10.1109/ACCESS.2017.2705196},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8279979,
author={D. {Arena} and D. {Kiritsis} and C. {Ziogou} and S. {Voutetakis}},
booktitle={2017 International Conference on Engineering, Technology and Innovation (ICE/ITMC)},
title={Semantics-driven knowledge representation for decision support and status awareness at process plant floors},
year={2017},
volume={},
number={},
pages={902-908},
abstract={The aim of this work is to demonstrate the potential of introducing ontologies for an appropriate visual status signaling at industrial process units. The need for safe operation and maintenance, either preventive or condition-based, drives the proposed approach, which supports operators and technical team utilizing knowledge from the workers, combined with reasoning techniques. As a consequence, the traditional Human Machine Interfaces (HMIs) are able to provide appropriate information to the workers about the status of a plant's subsystems. As far as the overall proposed approach is concerned, the adoption of semantics in this framework is not to say that all of the data integration issues and increasingly less distributed ontologies, are solved. Here, semantics modelling and semantics-driven (or semantic rules-based) analysis methods are exploited to conceptualize a semantically-enriched platform, and test it in terms of feasibility at a chemical pilot plant of CERTH/CPERI, showing some interesting preliminary results.},
keywords={data integration;decision support systems;human computer interaction;knowledge representation;ontologies (artificial intelligence);preventive maintenance;Human Machine Interfaces;data integration;Semantics-driven knowledge representation;visual status signaling;distributed ontologies;semantically-enriched platform;semantic rules;reasoning techniques;preventive condition;maintenance;safe operation;industrial process units;process plant floors;status awareness;decision support;Semantics;Ontologies;Maintenance engineering;Topology;Data mining;Floors;Monitoring;Ontologies;Industrial Semantics;Information Visualisation;Smart Plant Floor},
doi={10.1109/ICE.2017.8279979},
ISSN={},
month={June},}
@ARTICLE{9102991,
author={M. F. {Hashmi} and B. K. K. {Ashish} and A. G. {Keskar} and N. D. {Bokde} and J. H. {Yoon} and Z. W. {Geem}},
journal={IEEE Access},
title={An Exploratory Analysis on Visual Counterfeits Using Conv-LSTM Hybrid Architecture},
year={2020},
volume={8},
number={},
pages={101293-101308},
abstract={In recent years, with the advancements in the Deep Learning realm, it has been easy to create and generate synthetically the face swaps from GANs and other tools, which are very realistic, leaving few traces which are unclassifiable by human eyes. These are known as `DeepFakes' and most of them are anchored in video formats. Such realistic fake videos and images are used to create a ruckus and affect the quality of public discourse on sensitive issues; defaming one's profile, political distress, blackmailing and many more fake cyber terrorisms are envisioned. This work proposes a microscopic-typo comparison of video frames. This temporal-detection pipeline compares very minute visual traces on the faces of real and fake frames using Convolutional Neural Network (CNN) and stores the abnormal features for training. A total of 512 facial landmarks were extracted and compared. Parameters such as eye-blinking lip-synch; eyebrows movement, and position, are few main deciding factors that classify into real or counterfeit visual data. The Recurrent Neural Network (RNN) pipeline learns based on these features-fed inputs and then evaluates the visual data. The model was trained with the network of videos consisting of their real and fake, collected from multiple websites. The proposed algorithm and designed network set a new benchmark for detecting the visual counterfeits and show how this system can achieve competitive results on any fake generated video or image.},
keywords={face recognition;feature extraction;image classification;image motion analysis;learning (artificial intelligence);recurrent neural nets;video signal processing;visual counterfeits;fake generated video;exploratory analysis;conv-LSTM hybrid architecture;synthetically the face swaps;GAN;human eyes;DeepFakes;video formats;realistic fake videos;public discourse;sensitive issues;political distress;blackmailing cyber terrorisms;microscopic-typo comparison;video frames;temporal-detection pipeline;minute visual traces;fake frames;abnormal features;eye-blinking lip-synch;eyebrow movement;counterfeit visual data;feature-fed inputs;recurrent neural network pipeline;facial landmarks;fake cyber terrorisms;Face;Training;Visualization;Decoding;Gallium nitride;Machine learning;Recurrent neural networks;DeepFakes;generative adversarial network (GANs);facial landmarks;convolutional neural networks (CNN);recurrent neural network (RNN);visual counterfeits},
doi={10.1109/ACCESS.2020.2998330},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8340693,
author={E. M. {Stewart} and P. {Top} and M. {Chertkov} and D. {Deka} and S. {Backhaus} and A. {Lokhov} and C. {Roberts} and V. {Hendrix} and S. {Peisert} and A. {Florita} and T. J. {King} and M. J. {Reno}},
booktitle={2017 IEEE International Conference on Smart Grid Communications (SmartGridComm)},
title={Integrated multi-scale data analytics and machine learning for the distribution grid},
year={2017},
volume={},
number={},
pages={423-429},
abstract={We consider the field of machine learning and where it is both useful, and not useful, for the distribution grid and buildings interface. While analytics, in general, is a growing field of interest, and often seen as the golden goose in the burgeoning distribution grid industry, its application is often limited by communications infrastructure, or lack of a focused technical application. Overall, the linkage of analytics to purposeful application in the grid space has been limited. In this paper we consider the field of machine learning as a subset of analytical techniques, and discuss its ability and limitations to enable the future distribution grid. To that end, we also consider the potential for mixing distributed and centralized analytics and the pros and cons of these approaches. There is an exponentially expanding volume of measured data being generated on the distribution grid, which, with appropriate application of analytics, may be transformed into intelligible, actionable information that can be provided to the right actors - such as grid and building operators, at the appropriate time to enhance grid or building resilience, efficiency, and operations against various metrics or goals - such as total carbon reduction or other economic benefit to customers. While some basic analysis into these data streams can provide a wealth of information, computational and human boundaries on performing the analysis are becoming significant, with more data and multi-objective concerns. Efficient applications of analysis and the machine learning field are being considered in the loop. This paper describes benefits and limits of present machine-learning applications for use on the grid and presents a series of case studies that illustrate the potential benefits of developing advanced local multi-variate analytics machine-learning-based applications.},
keywords={data analysis;data visualisation;learning (artificial intelligence);power distribution;power engineering computing;power grids;integrated multiscale data analytics;machine-learning applications;multivariate analytics;distribution grid industry;Machine learning;Buildings;Reliability;Machine learning algorithms;Conferences;Smart grids;Analytics;Machine Learning;Distribution Grid;DER;validation;verification;prediction;incipient failure},
doi={10.1109/SmartGridComm.2017.8340693},
ISSN={},
month={Oct},}
@ARTICLE{7466117,
author={R. {Anirudh} and P. {Turaga} and J. {Su} and A. {Srivastava}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Elastic Functional Coding of Riemannian Trajectories},
year={2017},
volume={39},
number={5},
pages={922-936},
abstract={Visual observations of dynamic phenomena, such as human actions, are often represented as sequences of smoothly-varying features. In cases where the feature spaces can be structured as Riemannian manifolds, the corresponding representations become trajectories on manifolds. Analysis of these trajectories is challenging due to non-linearity of underlying spaces and high-dimensionality of trajectories. In vision problems, given the nature of physical systems involved, these phenomena are better characterized on a low-dimensional manifold compared to the space of Riemannian trajectories. For instance, if one does not impose physical constraints of the human body, in data involving human action analysis, the resulting representation space will have highly redundant features. Learning an effective, low-dimensional embedding for action representations will have a huge impact in the areas of search and retrieval, visualization, learning, and recognition. Traditional manifold learning addresses this problem for static points in the euclidean space, but its extension to Riemannian trajectories is non-trivial and remains unexplored. The difficulty lies in inherent non-linearity of the domain and temporal variability of actions that can distort any traditional metric between trajectories. To overcome these issues, we use the framework based on transported square-root velocity fields (TSRVF); this framework has several desirable properties, including a rate-invariant metric and vector space representations. We propose to learn an embedding such that each action trajectory is mapped to a single point in a low-dimensional euclidean space, and the trajectories that differ only in temporal rates map to the same point. We utilize the TSRVF representation, and accompanying statistical summaries of Riemannian trajectories, to extend existing coding methods such as PCA, KSVD and Label Consistent KSVD to Riemannian trajectories or more generally to Riemannian functions. We show that such coding efficiently captures trajectories in applications such as action recognition, stroke rehabilitation, visual speech recognition, clustering and diverse sequence sampling. Using this framework, we obtain state-of-the-art recognition results, while reducing the dimensionality/ complexity by a factor of 100-250x. Since these mappings and codes are invertible, they can also be used to interactively-visualize Riemannian trajectories and synthesize actions.},
keywords={computer vision;image coding;vector space representations;rate invariant metric;TSRVF;transported square-root velocity fields;temporal variability;action representations;human action analysis;physical constraints;Riemannian manifolds;smoothly-varying features;visual observations;Riemannian trajectories;elastic functional coding;Trajectory;Manifolds;Encoding;Visualization;Measurement;Speech recognition;Principal component analysis;Riemannian geometry;activity recognition;dimensionality reduction;visualization},
doi={10.1109/TPAMI.2016.2564409},
ISSN={1939-3539},
month={May},}
@INPROCEEDINGS{6610415,
author={A. {Foncubierta-Rodríguez} and Ó. A. {Jiménez del Toro} and A. {Platon} and P. {Poletti} and H. {Müller} and A. {Depeursinge}},
booktitle={2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
title={Benefits of texture analysis of dual energy CT for Computer-Aided pulmonary embolism detection},
year={2013},
volume={},
number={},
pages={3973-3976},
abstract={Pulmonary embolism is an avoidable cause of death if treated immediately but delays in diagnosis and treatment lead to an increased risk. Computer-assisted image analysis of both unenhanced and contrast-enhanced computed tomography (CT) have proven useful for diagnosis of pulmonary embolism. Dual energy CT provides additional information over the standard single energy scan by generating four-dimensional (4D) data, in our case with 11 energy levels in 3D. In this paper a 4D texture analysis method capable of detecting pulmonary embolism in dual energy CT is presented. The method uses wavelet-based visual words together with an automatic geodesic-based region of interest detection algorithm to characterize the texture properties of each lung lobe. Results show an increase in performance with respect to the single energy CT analysis, as well as an accuracy gain compared to preliminary work on a small dataset.},
keywords={computer aided analysis;computerised tomography;diseases;image texture;lung;medical image processing;wavelet transforms;dual energy CT;computer-aided pulmonary embolism detection;computer-assisted image analysis;contrast-enhanced computed tomography;pulmonary embolism diagnosis;standard single energy scan;four-dimensional data;energy levels;4D texture analysis method;wavelet-based visual words;automatic geodesic-based region of interest detection algorithm;lung lobe;single energy CT analysis;Visualization;Computed tomography;Energy states;Lungs;Accuracy;Three-dimensional displays;Radiology;Texture analysis;pulmonary embolism;dual energy CT;visual words;4D image analysis;Algorithms;Humans;Lung;Pulmonary Embolism;Radiographic Image Interpretation, Computer-Assisted;Tomography, X-Ray Computed;Wavelet Analysis},
doi={10.1109/EMBC.2013.6610415},
ISSN={1558-4615},
month={July},}
@ARTICLE{8723476,
author={G. {Zhang} and K. {Li} and D. {Gu} and X. {Wang} and X. {Yang} and K. {Zhu} and G. {Liang}},
journal={IEEE Access},
title={Visualizing Knowledge Evolution and Hotspots of Rural Environment and Health: A Systematic Review and Research Direction},
year={2019},
volume={7},
number={},
pages={72538-72550},
abstract={With global warming, energy scarcity, water shortages, and air, soil, and water pollution, the situation of environments in countries around the world is getting more and more serious and in some countries, rural environmental issues are more prominent. Health problems in rural areas also cannot be ignored, chronic diseases and infectious diseases have become the greatest threat to human life, while good environment and human health are the foundation of social and economic sustainable development. This paper adopts the bibliometrics method to conduct a visual analysis of 6,971 studies in the field of the rural environment and health published on the Web of Science between 2000 and 2017, including time knowledge map analysis, space knowledge map analysis, knowledge base analysis, and research focus analysis. This paper reveals the development status of research in the field of rural environment and health, analyzes, and discusses the research hotspots and future development trends in this field, and provides important knowledge support for researchers to carry out follow-up research.},
keywords={data visualisation;diseases;environmental science computing;global warming;health care;knowledge based systems;sustainable development;water pollution;knowledge evolution visualization;research hotspots;knowledge base analysis;space knowledge map analysis;visual analysis;economic sustainable development;social development;human health;infectious diseases;chronic diseases;health problems;water pollution;water shortages;energy scarcity;global warming;rural environment;Bibliometrics;Market research;Knowledge engineering;Visualization;Water pollution;Diseases;Knowledge based systems;Rural;health;environment;pollution;bibliometric analysis},
doi={10.1109/ACCESS.2019.2919549},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8327022,
author={C. {Xie} and X. {Fu} and S. {Song}},
booktitle={2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
title={Perception-Oriented 3D Rendering Approximation for Modern Graphics Processors},
year={2018},
volume={},
number={},
pages={362-374},
abstract={Anisotropic filtering enabled by modern rasterization-based GPUs provides users with extremely authentic visualization experience, but significantly limits the performance and energy efficiency of 3D rendering process due to its large texture data requirement. To improve 3D rendering efficiency, we build a bridge between anisotropic filtering process and human visual system by analyzing users' perception on image quality. We discover that anisotropic filtering does not impact user perceived image quality on every pixel. This motives us to approximate the anisotropic filtering process for non-perceivable pixels in order to improve the overall 3D rendering performance without damaging user experience. To achieve this goal, we propose a perceptionoriented runtime approximation model for 3D rendering by leveraging the inner-relationship between anisotropic and isotropic filtering. We also provide a low-cost texture unit design for enabling this approximation. Extensive evaluation on modern 3D games demonstrates that, under a conservative tuning point, our design achieves a significant average speedup of 17% for the overall 3D rendering along with 11% total GPU energy reduction, without visible image quality loss from users' perception. It also reduces the texture filtering latency by an average of 29%. Additionally, it creates a unique perception-based tuning space for performance-quality tradeoffs on graphics processors.},
keywords={approximation theory;computer games;computer graphics;graphics processing units;human factors;image texture;rendering (computer graphics);visual perception;isotropic filtering;low-cost texture unit design;modern 3D games;perception-oriented 3D rendering approximation;texture data requirement;3D rendering efficiency;anisotropic filtering process;human visual system;3D rendering performance;user experience;image quality loss;modern graphics processors;authentic visualization experience;perception-oriented runtime approximation model;Three-dimensional displays;Rendering (computer graphics);Image quality;Image color analysis;Computer architecture;Runtime;Graphics processing units;GPU;Approximate Computing;3D Rendering;User-Oriented Study},
doi={10.1109/HPCA.2018.00039},
ISSN={2378-203X},
month={Feb},}
@INPROCEEDINGS{7286304,
author={B. {Falahati} and A. {Kargarian}},
booktitle={2015 IEEE Power Energy Society General Meeting},
title={Power system reliability enhancement considering smart monitoring},
year={2015},
volume={},
number={},
pages={1-5},
abstract={With improvements in smart sensing and digital instrumentation technologies, small, low-cost sensors have been installed in power networks, thus providing new opportunities for smart monitoring. Smart monitoring consists of analog/digital sensors, measurement units, control devices, and protective relays inside a digital communication network working together to gather local information about the power grid, to be recorded in the servers and to demonstrate human machine interfaces (HMI). To keep a power system operating reliably, it is necessary to continuously monitor and indicate crucial points of the power network. This paper introduces various aspects of power system monitoring and indication and proposes a mathematic model to numerically assess the positive effects of smart monitoring on the power system's reliability. Based on the Markov model, the formulation used to calculate the updated failure and repair rates of the power equipment is extracted.},
keywords={computerised monitoring;digital instrumentation;human computer interaction;Markov processes;power apparatus;power engineering computing;power system measurement;power system reliability;power system reliability enhancement;smart monitoring;smart sensing;digital instrumentation technology;power network;human machine interface;power system monitoring;mathematical model;Markov model;failure rate calculation;repair rate estimation;power equipment;Monitoring;Power system reliability;Maintenance engineering;Reliability;Markov processes;Substations;Smart grid;power system reliability;monitoring;visualization;data manipulation;indication;Markov chain},
doi={10.1109/PESGM.2015.7286304},
ISSN={1932-5517},
month={July},}
@ARTICLE{7571172,
author={C. {Spampinato} and S. {Palazzo} and D. {Giordano}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Gamifying Video Object Segmentation},
year={2017},
volume={39},
number={10},
pages={1942-1958},
abstract={Video object segmentation can be considered as one of the most challenging computer vision problems. Indeed, so far, no existing solution is able to effectively deal with the peculiarities of real-world videos, especially in cases of articulated motion and object occlusions; limitations that appear more evident when we compare the performance of automated methods with the human one. However, manually segmenting objects in videos is largely impractical as it requires a lot of time and concentration. To address this problem, in this paper we propose an interactive video object segmentation method, which exploits, on one hand, the capability of humans to identify correctly objects in visual scenes, and on the other hand, the collective human brainpower to solve challenging and large-scale tasks. In particular, our method relies on a game with a purpose to collect human inputs on object locations, followed by an accurate segmentation phase achieved by optimizing an energy function encoding spatial and temporal constraints between object regions as well as human-provided location priors. Performance analysis carried out on complex video benchmarks, and exploiting data provided by over 60 users, demonstrated that our method shows a better trade-off between annotation times and segmentation accuracy than interactive video annotation and automated video object segmentation approaches.},
keywords={computer games;computer vision;image segmentation;interactive systems;video signal processing;interactive video annotation;collective human brainpower;visual scenes;computer vision;video object segmentation;gamification;Games;Object segmentation;Visualization;Motion segmentation;Data mining;Computers;Computer vision;Interactive video annotation;games with a purpose;human in the loop;spatio-temporal superpixel segmentation},
doi={10.1109/TPAMI.2016.2610973},
ISSN={1939-3539},
month={Oct},}
@ARTICLE{6209406,
author={L. {Ma} and S. {Li} and K. N. {Ngan}},
journal={IEEE Transactions on Circuits and Systems for Video Technology},
title={Reduced-Reference Video Quality Assessment of Compressed Video Sequences},
year={2012},
volume={22},
number={10},
pages={1441-1456},
abstract={In this paper, a novel reduced-reference (RR) video quality assessment (VQA) is proposed by exploiting the spatial information loss and the temporal statistical characteristics of the interframe histogram. From the spatial perspective, an energy variation descriptor (EVD) is proposed to measure the energy change of each individual encoded frame, which results from the quantization process. Besides depicting the energy change, EVD can further simulate the texture masking property of the human visual system (HVS). From the temporal perspective, the generalized Gaussian density (GGD) function is employed to capture the natural statistics of the interframe histogram distribution. The city-block distance (CBD) is used to calculate the histogram distance between the original video sequence and the encoded one. For simplicity, the difference image between adjacent frames is employed to characterize the temporal interframe relationship. By combining the spatial EVD together with the temporal CBD, an efficient RR VQA is developed. Evaluation on the subjective quality video database demonstrates that the proposed method outperforms the representative RR video quality metric and the full-reference VQAs, such as peak signal-to-noise ratio and structure similarity index in matching subjective ratings. This means that the proposed metric is more consistent with the HVS perception. Furthermore, as only a small number of RR features are extracted for representing the original video sequence (each frame requires only one parameter for describing EVD and three parameters for recording GGD), the RR features can be embedded into the video sequences or transmitted through the ancillary data channel, which can be used in the video quality monitoring system.},
keywords={data compression;encoding;Gaussian processes;image matching;image representation;image sequences;video coding;reduced-reference video quality assessment;compressed video sequences;RR VQA;spatial information loss;temporal statistical characteristics;energy variation descriptor;EVD;individual encoded frame;quantization process;human visual system;HVS;generalized Gaussian density function;GGD function;natural statistics;interframe histogram distribution;city-block distance;CBD;adjacent frames;temporal interframe relationship;subjective quality video database;representative RR video quality metric;full-reference VQA;signal-to-noise ratio;structure similarity index;subjective rating matching;HVS perception;video sequence representation;ancillary data channel;video quality monitoring system;Feature extraction;Measurement;Video sequences;Discrete cosine transforms;Visualization;Histograms;Quantization;Energy variation descriptor (EVD);generalized Gaussian density (GGD);human visual system (HVS);reduced-reference (RR);video quality assessment (VQA)},
doi={10.1109/TCSVT.2012.2202049},
ISSN={1558-2205},
month={Oct},}
@INPROCEEDINGS{8577080,
author={F. {Morawitz}},
booktitle={2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments (SIVE)},
title={Quantum: An art-science case study on sonification and sound design in virtual reality},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Molecular sonification is the transformation of chemical data into sound and has been used to gain insight into chemical systems and for the creation of contemporary music compositions. The combination of sonification with a virtual reality environment offers potential benefits such as providing a visual frame of reference, an increased sense of immersion, nuanced spatial information through binaural audio cues and ease of interactivity. To explore how strategies developed in sonification research and contemporary electroacoustic music composition can be adapted to virtual reality, the art-science installation 'Quantum' was created. The multi-media work consists of computer-generated molecules in a virtual space producing sound created via the sonification of nuclear magnetic resonance data. Upon user interaction with different molecules, the overall composition and complexity of the sound world develop. The binaural sound material can migrate back and forth from the molecules to the non-binaural background composition and, depending on user input, develop in terms of timbre, spectral complexity, and gestural content. `Quantum' is an exploration of the combination of sonification and virtual reality and offers first points of discussion that can be elaborated upon in future artworks, games or educational content.},
keywords={art;audio signal processing;audio user interfaces;chemistry computing;human computer interaction;multimedia computing;music;nuclear magnetic resonance;virtual reality;nuclear magnetic resonance data;user interaction;sound world;binaural sound material;nonbinaural background composition;art-science case study;sound design;molecular sonification;chemical data;chemical systems;contemporary music compositions;virtual reality environment;binaural audio cues;sonification research;contemporary electroacoustic music composition;computer-generated molecules;virtual space;Quantum;art-science installation;multimedia work;Sonification;Energy states;Visualization;Nuclear magnetic resonance;Virtual reality;Chemicals;Sonification;Molecular Sonification;Virtual Reality},
doi={10.1109/SIVE.2018.8577080},
ISSN={},
month={March},}
@INPROCEEDINGS{9069763,
author={H. Y. {El Sayed} and M. {Al-Kady} and Y. {Siddik}},
booktitle={2019 International Conference on Smart Applications, Communications and Networking (SmartNets)},
title={Management of Smart Water Treatment Plant using IoT Cloud Services},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Water Treatment Plant (WTP) is an important infrastructure to ensure human health and the environment. In its development, aspects of environmental safety and health are of great importance. Smart WTP is a water station that is managed using software-based tools such as data analytics, visualization, and predictive analytics. WTP smart management system is developed to manage Big Data information flows from many sensors and smart devices that allow for real-time responses and connectivity to Internet of Things (IoT) Cloud platforms services. The performance of the Smart WTP operations should be consistently evaluated to ensure that the plant is operating efficiently, thus minimizing energy costs and improving water purity and quality conservation parameters. Our proposed solution is based on sensors monitoring and Big Data analysis of Smart Water Treatment Plant (SWTP) using IoT hardware devices that have an internet connection to an IoT Cloud platform. The Cloud platform such as Thing Speak has the capability to analyze, visualize and react based on the Big Data analytics to send risk alarms and operate risk management plans to overcome the failure scenarios and minimize the downtime operation of the Smart WTP.},
keywords={Big Data;cloud computing;data analysis;Internet;Internet of Things;public utilities;risk management;water treatment;IoT cloud services;human health;environmental safety;water station;software-based tools;WTP smart management system;Big Data information;smart devices;Smart WTP operations;energy costs;improving water purity;quality conservation parameters;IoT hardware devices;Big Data analytics;risk management;smart water treatment plant;Internet of Things cloud platforms services;internet connection;Cloud computing;Internet of Things;Intelligent sensors;Big Data;Monitoring;Hardware;Internet of Things (IoT);Artificial Intelligence (AI);Cloud Platforms;Big Data;Big Data Analytics;Water Treatment Plant;Risk Management},
doi={10.1109/SmartNets48225.2019.9069763},
ISSN={},
month={Dec},}
